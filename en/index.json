[{"categories":null,"content":"Introduction to Kubernetes Kubernetes is a popular and powerful container orchestration system that has become the de facto standard for managing containerized workloads. However, managing Kubernetes clusters can be complex and challenging, especially if you are new to the technology. In this post, we’ll cover 15 best practices for working with Kubernetes that can help you optimize your clusters and improve the performance and reliability of your applications. ","date":"2023-02-21","objectID":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/:0:1","tags":["Kubernetes","Best Practices","AIGC"],"title":"15 Best Practices for Working with Kubernetes","uri":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"15 Best Practices Keep Your Clusters Up-to-Date Kubernetes is a rapidly evolving technology, with new features and bug fixes released regularly. It’s important to keep your clusters up-to-date with the latest stable release to ensure you have access to the latest features, security patches, and bug fixes. Use a Declarative Approach Kubernetes resources, such as deployments, services, and config maps, can be defined in YAML manifests or Helm charts. Use a declarative approach to managing your resources, which means you define the desired state of your resources and let Kubernetes handle the implementation details. Define Resource Requests and Limits To ensure that your applications have the necessary resources to run properly and to prevent resource contention on your nodes, define resource requests and limits for your containers. This allows Kubernetes to schedule your workloads more efficiently and prevent performance issues. Use Namespaces to Organize Your Resources Use namespaces to organize your resources and provide a level of isolation and resource quota for different teams or applications. This helps you manage your clusters more effectively and provides better visibility into your resources. Use RBAC to Control Access to Your Resources Use RBAC (Role-Based Access Control) to control access to your Kubernetes resources, and grant only the necessary privileges to each user or group. This helps you enforce security policies and prevent unauthorized access. Enable Auditing Enabling auditing helps you keep track of changes to your Kubernetes resources, and to monitor and detect unauthorized access or behavior. This helps you maintain the integrity of your clusters and data. Use ConfigMaps and Secrets to Manage Configuration Data Use ConfigMaps and Secrets to manage configuration data and sensitive information, such as passwords or API keys, separately from your application code. This makes it easier to manage and update your configuration data, and provides a more secure way to handle sensitive information. Use Liveness and Readiness Probes Use liveness and readiness probes to monitor the health of your applications and to enable Kubernetes to restart or reschedule containers automatically in case of failures. This helps you ensure that your applications are always available and responsive. Use Horizontal Pod Autoscaling Use horizontal pod autoscaling to automatically adjust the number of replicas of your application based on resource utilization or custom metrics. This helps you optimize the performance of your applications and reduce costs by scaling up or down as needed. Use Node Taints and Tolerations Use node taints and tolerations to schedule workloads only on nodes that meet certain criteria, such as having specific hardware or software configurations. This helps you optimize your cluster resources and prevent performance issues. Use Node Affinity and Anti-Affinity Use node affinity and anti-affinity to schedule workloads based on node labels, such as geographic location or availability zone, or to spread workloads across multiple nodes. This helps you optimize your cluster resources and prevent performance issues. Use Network Policies Use network policies to control traffic between pods or namespaces and to enforce security rules. This helps you ensure the security and integrity of your data and applications. Use Helm to Manage Your Kubernetes Applications Use Helm to manage your Kubernetes applications and to simplify the deployment and management of complex applications or clusters. Helm provides a packaging system and deployment tool that makes it easier to manage your Kubernetes applications and to share them with the community. Use Prometheus and Grafana to Monitor and Visualize Your Clusters and Applications Use Prometheus and Grafana to monitor and visualize your Kubernetes clusters and applications, and to detect and troubleshoot issues. Prometheus is a popular monitoring system that collects metrics from yo","date":"2023-02-21","objectID":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/:0:2","tags":["Kubernetes","Best Practices","AIGC"],"title":"15 Best Practices for Working with Kubernetes","uri":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"Conclusion These 15 best practices can help you optimize your Kubernetes clusters and improve the performance and reliability of your applications. By following these practices, you can better manage your clusters, enhance the security of your applications, and ensure that your applications are always available and responsive. ","date":"2023-02-21","objectID":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/:0:3","tags":["Kubernetes","Best Practices","AIGC"],"title":"15 Best Practices for Working with Kubernetes","uri":"/en/2023-02-22-15%E4%B8%AA%E5%85%B3%E4%BA%8Ekubernetes%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"Overview This topic can be found under Lab2 instruction. Modifying Raft to cooperate with services that persistently store a “snapshot” of their state from time to time, at which point Raft discards log entries that precede the snapshot. It’s now possible for a follower to fall so far behind that the leader has discarded the log entries it needs to catch up; the leader must then send a snapshot plus the log starting at the time of the snapshot. diagram of Raft interactions KeyValue-Store Server Architecture\" KeyValue-Store Server Architecture Raft must provide the following function that the service can call with a serialized snapshot of its state. In this way, Raft can discard the log entries safely preceding this Snapshot() Snapshot(index int, snapshot []byte) The index argument indicates the highest log entry that’s reflected in the snapshot. Raft should discard its log entries before that point. You’ll need to revise your Raft code to operate while storing only the tail of the log. You’ll need to implement the InstallSnapshot RPC discussed in the paper that allows a Raft leader to tell a lagging Raft peer to replace its state with a snapshot. You will likely need to think through how InstallSnapshot should interact with the state and rules in Figure 2. Changing original Code to adopt the new requirements in Part2D. This happens in making condition judgments when you determine whether it is the correct time to change Raft State. When a follower’s Raft code receives an InstallSnapshot RPC, it can use the applyCh to send the snapshot to the service in an ApplyMsg. Your Raft should persist both Raft state and the corresponding snapshot. Use persister. SaveStateAndSnapshot(), which takes separate arguments for the Raft state and the corresponding snapshot. If there’s no snapshot, pass nil as the snapshot argument. Previously, this lab recommended that you implement a function called CondInstallSnapshot to avoid the requirement that snapshots and log entries sent on applyCh are coordinated. This vestigial API interface remains, but you are discouraged from implementing it: instead, we suggest that you simply have it return true. Tips: A good place to start is to modify your code so that it is able to store just the part of the log starting at some index X. Initially you can set X to zero and run the 2B/2C tests. Then make Snapshot(index) discard the log before index, and set X equal to index. If all goes well you should now pass the first 2D test. You won’t be able to store the log in a Go slice and use Go slice indices interchangeably with Raft log indices; you’ll need to index the slice in a way that accounts for the discarded portion of the log. Next: have the leader send an InstallSnapshot RPC if it doesn’t have the log entries required to bring a follower up to date. Send the entire snapshot in a single InstallSnapshot RPC. Don’t implement Figure 13’s offset mechanism for splitting up the snapshot. Raft must discard old log entries in a way that allows the Go garbage collector to free and re-use the memory; this requires that there be no reachable references (pointers) to the discarded log entries. Even when the log is trimmed, your implementation still needs to properly send the term and index of the entry prior to new entries in AppendEntries RPCs; this may require saving and referencing the latest snapshot’s lastIncludedTerm/lastIncludedIndex (consider whether this should be persisted). A reasonable amount of time to consume for the full set of Lab 2 tests (2A+2B+2C+2D) without -race is 6 minutes of real-time and one minute of CPU time. When running with -race, it is about 10 minutes of real-time and two minutes of CPU time. Figure13 shows the parameters that you may be used in implementing InstallSnapshotRPCs Figure 13\" Figure 13 ","date":"2022-03-18","objectID":"/en/2022-03-18-raft-part2d/:0:1","tags":["Developing Notes"],"title":"6.824-RaftLab-Part2D-Development Quicknotes","uri":"/en/2022-03-18-raft-part2d/"},{"categories":null,"content":"Implementation 😭 So many concurrency problems, headaches. Modify Apply() in the form of receiving a signal via notifyApply channel Implement Snapshot but Not installSnapshotRPC and that should pass the First Test Modify the apis.go in order to add some helpful function to maintain the state of Snapshot Modify the getRangeEntries()/getEntry() which should be take offset into consideration when adding snapshot functionality. getRangeEntries() takes fromidx and toidx as its parameters, which should be minus lastSnapshotIndex to get the correct position in the log array index. (I should carefully check whether this modification will lead to disaster🥲) Separate the implementation in persist() and create a new function to retrieve serialization data of raftState Add lastSnapshotIndex and lastSnapshotTerm to persist() and readPersist() Modify the logReplicate() . When sending appendentriesRPC call, we should check the nextIndex[peerIdx] whether is smaller than lastSnapshotIdx. If yes, we should send IntallSnapshotRPC rather than sending appendEntriesRPC. Moreover, we update the nextIndex[peerIdx] based on the peer’s reply which contains the conflict Index, and it will reach the condition that we need to send InstallSnapshotRPC. There are two approaches to handle this situation: 1) Send InstallSnapshotRPC whenever it reaches the condition in peer’s reply OR 2) Send InstallSnapshotRPC in the next logReplicate() procedure. logReplicate is called when the leader’s heartBeat timer is a timeout and sending RPCs are in parallel, thus the logReplicate() may be called during the previous one still keep running. That may be problematic. Whatever, I add a synchronized mechanism to avoid potential bugs here. 😫 InstallSnapshot RPC Implement installSnapshot() and define the data structure of request/response using in this call. Implement InstallSnapshotRPC ` Symptoms: failed to reach an agreement, one server can not catch up with others. And it tries to become a leader but the remote server r has a more up-to-date log, so it fails to be elected. Diagnosis: 1) Reading What TestSnapshotInstall2D do The test tries to reconnect the server which has been disconnected in the past time, so this server is far behind the current cluster’s agreement. What we expect is that the current leader will send InstallSnapshot to this server and brings it to come back to normal. But it seems to not work correctly. 🥲 I found one problem is that I forget to Unlock the Mutex Lock. 🤣 It seems that I can pass the PART2D Test in a high probability when reducing iterations times down to 10, which is set in the previous test. getRangeEntries will lead the program into disaster in a very small probability (some corner cases). Due to some concurrent problems, it’s hard to figure out what has happened. So Everything goes well. 🖖 Hopefully, no one will be hurt by this mistake. 🥲 TestSnapshotBasic2D ok 6.824/raft 3.201s TestSnapshotInstall2D ok 6.824/raft 34.506s TestSnapshotInstallUnreliable2D ok 6.824/raft 36.091s TestSnapshotInstallCrash2D ok 6.824/raft 13.126s TestSnapshotInstallUnCrash2D ok 6.824/raft 14.324s ","date":"2022-03-18","objectID":"/en/2022-03-18-raft-part2d/:0:2","tags":["Developing Notes"],"title":"6.824-RaftLab-Part2D-Development Quicknotes","uri":"/en/2022-03-18-raft-part2d/"},{"categories":null,"content":"Origin: http://aes.cryptohack.org/forbidden_fruit/ ","date":"2021-10-20","objectID":"/en/2021-10-20-forbbiden-fruit/:0:0","tags":["Crypto","CryptoHack"],"title":"Forbbiden Fruit","uri":"/en/2021-10-20-forbbiden-fruit/"},{"categories":null,"content":"0x1 DESCRIPTION Galois Counter Mode (GCM) is the most widely used block cipher mode in TLS today. It’s an “authenticated encryption with associated data” cipher mode (AEAD), yet not resistant to misuse. See here for a great resource on the inner workings of GCM, as well as this attack. Source from Crypto.Cipher import AES import os IV = ? KEY = ? FLAG = ? @chal.route('/forbidden_fruit/decrypt/\u003cnonce\u003e/\u003cciphertext\u003e/\u003ctag\u003e/\u003cassociated_data\u003e/') def decrypt(nonce, ciphertext, tag, associated_data): ciphertext = bytes.fromhex(ciphertext) tag = bytes.fromhex(tag) header = bytes.fromhex(associated_data) nonce = bytes.fromhex(nonce) if header != b'CryptoHack': return {\"error\": \"Don't understand this message type\"} cipher = AES.new(KEY, AES.MODE_GCM, nonce=nonce) encrypted = cipher.update(header) try: decrypted = cipher.decrypt_and_verify(ciphertext, tag) except ValueError as e: return {\"error\": \"Invalid authentication tag\"} if b'give me the flag' in decrypted: return {\"plaintext\": FLAG.encode().hex()} return {\"plaintext\": decrypted.hex()} @chal.route('/forbidden_fruit/encrypt/\u003cplaintext\u003e/') def encrypt(plaintext): plaintext = bytes.fromhex(plaintext) header = b\"CryptoHack\" cipher = AES.new(KEY, AES.MODE_GCM, nonce=IV) encrypted = cipher.update(header) ciphertext, tag = cipher.encrypt_and_digest(plaintext) if b'flag' in plaintext: return { \"error\": \"Invalid plaintext, not authenticating\", \"ciphertext\": ciphertext.hex(), } return { \"nonce\": IV.hex(), \"ciphertext\": ciphertext.hex(), \"tag\": tag.hex(), \"associated_data\": header.hex(), } ","date":"2021-10-20","objectID":"/en/2021-10-20-forbbiden-fruit/:1:0","tags":["Crypto","CryptoHack"],"title":"Forbbiden Fruit","uri":"/en/2021-10-20-forbbiden-fruit/"},{"categories":null,"content":"0x2 ANALYSIS Given cryptosystem implements AES (Advanced Encryption Standar) GCM (Galois Counter Mode) Mode. Here’s the detail of AES_GCM. The basic idea of GCM mode is to compute the GHASH attaching to the ciphertext to validate the authentication of the information. Notice that in this challenge, IV is reusing, which may be equal to a constant IV = ? It’s a dangerous behavior, which is possible to be exploited by the attacker. It is easy to compute the $H = E_k(IV||0^{32})$ and $E_k(IV||0^{31}1)$ , which are critical in computing the GHASH and MAC (Mesaage Autentication Code). $$ \\text{GHASH}(H,A,C)=X_{m+n+1} $$ We can compute the tag using these formula: $$ Tag = AAD * H^3 + C_1*H^2 + L*H + E_k(IV||0^{31}1) $$ $L=len(AAD)||len(ciphertext)$ Notice that the len of text is the bit lengths. In this challenge we need to forge the tag of the ciphertext, which is encrypted by the plaintext of give me the flag. It’s just 16 bytes here, Perfect ! We can get some oracles from the server and then compute the things we don’t know by solving the linear equation. $$ T_1 = AAD*H^3 + C_1*H^2 + L*H + E_k(IV||0^{31}1) $$ $$ T_2 = AAD*H^3 + C_2*H^2 + L*H + E_k(IV||0^{31}1) $$ Because the IV is reusing, the $H$ and $E_k(IV||0^{31}1)$ here are equal in these two equation. And all arithmetic operations are based on $GF(2^{128})$, we can add these two equations to get: $$ T_1 \\oplus T_2 = (C_1 \\oplus C_2)H^2 $$ And the subsequent works are going to be simple. But I go through a dark age since I am searching a way to implement polynomial factorization over $GF(2^{128})$ I used the package called galois in Python but I didn’t figure it out. I feel so weird to do some simple arithmetic operation in the finite field. (Maybe I never know its correct way to use) Anyway, I tried some other mathmatics tools and found SageMath finally. (I wonder whether I have once heard about sage in the lecture): I spent a nice time on reading the documents to learn how to write the code in sage. It’s quite like Python but has its own special syntax. Like F.\u003cx\u003e = GF(2)[] I stuck in this syntax in python scripts, beacuse it will be error when you execute your scripts with F.\u003cx\u003e = GF(2)[] (Obviously) :( So after googling, I found the solution in https://stackoverflow.com/questions/53045500/sage-syntax-a-x. Sage has its parser to interpret invaild Python input as valid Python. Great! We can go back for our F.\u003cx\u003e = GF(2)[] code , and turn it into F = GF(Integer(2))['x']; (x,) = F._first_ngens(1) Bomb! We can finish our task now. :) 0x3 EXPLOITED #!/usr/bin/env sage import binascii from pwn import xor from Cryptodome.Util.number import long_to_bytes from bitstring import BitArray from sage.all import * import requests from curtsies.fmtfuncs import red # ! construct the galois field F = GF(Integer(2))['X'] (X,) = F._first_ngens(1) G = GF(Integer(2)**Integer(128), modulus=X**Integer(128)+X ** Integer(7)+X**Integer(2)+X+Integer(1), names=('x',)) (x,) = G._first_ngens(1) K = G['y'] (y,) = K._first_ngens(1) def retrieve_oracle(plaintext): resp = requests.get( 'http://aes.cryptohack.org/forbidden_fruit/encrypt/' + plaintext).json() if 'tag' in resp: return resp['ciphertext'], resp['tag'], resp['nonce'] else: return resp['ciphertext'] def hex_list_2_bytes_list(hex_list): return [binascii.unhexlify(v) for v in hex_list] def to_gf(long_bytes): ''' arithmetic operation over galois field GF(2^128) ''' return G([int(v) for v in BitArray(long_bytes).bin.zfill(128)]) def compute_mask(AD, c, H, L, t): ''' mask computes based on this equation over GF(2^128) T = AAD * H^3 + C_1 * H^2 + L * H + MASK In AES_GCM MODE MASK = E_k(IV||0*31||1) ''' return t + AD * (H**3) + c * (H**2) + L*H def compute_tag(AD, c, H, L, mask): return AD * (H**3) + c * (H**2) + L * H + mask def poly_2_hex(poly): ''' e.g. 00010000 the first bit (from left to right) is the coefficient of x^0 the last bit is the coefficient of x^7 ''' return binascii.hexlify(long_to_bytes( int(''.join([str(v) for v in poly.polynomial().l","date":"2021-10-20","objectID":"/en/2021-10-20-forbbiden-fruit/:2:0","tags":["Crypto","CryptoHack"],"title":"Forbbiden Fruit","uri":"/en/2021-10-20-forbbiden-fruit/"},{"categories":null,"content":"😏Introduction Greetings From p1nant0m 🖖 !! I am a Junior student majoring in Information Security. Currently, I am learning about Kubernetes architecture and security issues related to Cloud Native. It’s an interesting area that I want to dive into deeply. But I am confused about how I can do more real practices in the specific domain. Also, I used to be a CTF player solving cryptographic challenges, but now I focus more on Web Security and engineering problems. (Mathematics is so sophisticated to me :crying_cat_face: ) But I still do endeavor to post some introduction of cryptography based on what I have learned in the lecture —— Principle of Cryptography (Using the textbook Introduction To Modern Cryptography by Jonathan Katz ) Besides doing my professional, I am curious about philosophy, history, and sociology. These topics are meaningful since we all humanity are under an unprecedentedly pandemic. We may observe the historical turning or it is exactly happening. By the way, I am working on lab3 from MIT 6.824 Distributed System, in which I have learned a lot of knowledge about design and principles in building highly available distributed systems. What’s more, I take this lecture with some perspectives from Security. ","date":"0001-01-01","objectID":"/en/about/:0:1","tags":null,"title":"","uri":"/en/about/"},{"categories":null,"content":"😉Where To “Catch” me 📨 wgblike@outlook.com; wgblike@gmail.com Github: P1nant0m ","date":"0001-01-01","objectID":"/en/about/:0:2","tags":null,"title":"","uri":"/en/about/"},{"categories":null,"content":"Badges ","date":"0001-01-01","objectID":"/en/about/:0:3","tags":null,"title":"","uri":"/en/about/"},{"categories":null,"content":"撩月 ","date":"0001-01-01","objectID":"/en/friends/:0:0","tags":null,"title":"","uri":"/en/friends/"}]